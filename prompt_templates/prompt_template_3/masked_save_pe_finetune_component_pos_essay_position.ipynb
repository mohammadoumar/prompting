{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79ecd4a",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 1,
     "id": "031a2430-7ba4-431f-8e42-e31baf9ce991",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pandas==1.3.4 in /opt/conda/lib/python3.8/site-packages (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas==1.3.4) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.8/site-packages (from pandas==1.3.4) (1.21.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas==1.3.4) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.3.4) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers==4.12.5 in /opt/conda/lib/python3.8/site-packages (4.12.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (4.62.3)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (0.10.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (5.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (2.26.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (3.3.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (0.0.46)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (2021.10.8)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (1.21.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (0.9.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.12.5) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers==4.12.5) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (2.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (2021.5.30)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.12.5) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.12.5) (8.0.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.12.5) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets==1.15.1 in /opt/conda/lib/python3.8/site-packages (1.15.1)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (9.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (1.21.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (2.26.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (0.3.5.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (0.70.13)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (3.8.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (0.9.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (21.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (1.3.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (2022.7.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (4.62.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.15.1) (3.10.0.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.15.1) (5.4.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.15.1) (3.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets==1.15.1) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.15.1) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.15.1) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.15.1) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.15.1) (2.0.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (1.8.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (21.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets==1.15.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets==1.15.1) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets==1.15.1) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.0.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.28.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.2)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (58.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas==1.3.4\n",
    "!pip install transformers==4.12.5\n",
    "!pip install datasets==1.15.1\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d90072f",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "db736e14-03fb-4438-938d-c705d6786666",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "from transformers import Trainer\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from datasets import ClassLabel\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0135cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f36f2f75",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "37286c02-6bf4-41f5-ab70-51515a054e7b",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce834259",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 2,
     "id": "0c699094-439f-4dda-85a9-815e7948540c",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = '/notebooks/Data/bert_sequence_classification'\n",
    "DATA_FILE = '/notebooks/linguistic_features/data/hf_datasets/pe_dataset_w_essay_position_pos_tags.pt'\n",
    "RESULTS_FOLDER = '/notebooks/Results/bert_sequence_classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00fbf82c",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "35aada91-232a-421e-a28f-94b359c6d65d",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "739bc429",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "dc52e71e-65fa-4946-acdf-e4fffe9d0f79",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b83550b",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d352c1cd-abff-4b1e-b5e2-611288e4fddb",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aac755ef",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "013a6d64-65e7-4189-a468-40ecfd8a6736",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea0b1eea",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 5,
     "id": "626737f9-ff56-4992-b72b-60750375e455",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "dataset = torch.load(DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "941de917",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 6,
     "id": "4fbfcc7b-55fb-456e-ab02-2ae975803046",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['essay_nr', 'component_id', 'label_and_comp_idxs', 'text', 'label_x', 'label_ComponentType', 'relation_SupportAttack', 'label_RelationType', 'label_LinkedNotLinked', 'split', 'essay', 'argument_bound_1', 'argument_bound_2', 'argument_id', 'sentence', 'paragraph', 'para_nr', 'total_paras', 'token_count', 'token_count_covering_para', 'tokens_count_covering_sentence', 'preceeding_tokens_in_sentence_count', 'succeeding_tokens_in_sentence_count', 'token_ratio', 'relative_position_in_para_char', 'is_in_intro', 'relative_position_in_para_token', 'is_in_conclusion', 'is_first_in_para', 'is_last_in_para', 'nr_preceeding_comps_in_para', 'nr_following_comps_in_para', 'structural_fts_as_text', 'structural_fts_as_text_combined', 'para_ratio', 'first_or_last', 'strct_fts_w_position_in_essay', 'component_pos_tags', 'strct_fts_essay_position_pos_tags'],\n",
       "        num_rows: 3770\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['essay_nr', 'component_id', 'label_and_comp_idxs', 'text', 'label_x', 'label_ComponentType', 'relation_SupportAttack', 'label_RelationType', 'label_LinkedNotLinked', 'split', 'essay', 'argument_bound_1', 'argument_bound_2', 'argument_id', 'sentence', 'paragraph', 'para_nr', 'total_paras', 'token_count', 'token_count_covering_para', 'tokens_count_covering_sentence', 'preceeding_tokens_in_sentence_count', 'succeeding_tokens_in_sentence_count', 'token_ratio', 'relative_position_in_para_char', 'is_in_intro', 'relative_position_in_para_token', 'is_in_conclusion', 'is_first_in_para', 'is_last_in_para', 'nr_preceeding_comps_in_para', 'nr_following_comps_in_para', 'structural_fts_as_text', 'structural_fts_as_text_combined', 'para_ratio', 'first_or_last', 'strct_fts_w_position_in_essay', 'component_pos_tags', 'strct_fts_essay_position_pos_tags'],\n",
       "        num_rows: 1260\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['essay_nr', 'component_id', 'label_and_comp_idxs', 'text', 'label_x', 'label_ComponentType', 'relation_SupportAttack', 'label_RelationType', 'label_LinkedNotLinked', 'split', 'essay', 'argument_bound_1', 'argument_bound_2', 'argument_id', 'sentence', 'paragraph', 'para_nr', 'total_paras', 'token_count', 'token_count_covering_para', 'tokens_count_covering_sentence', 'preceeding_tokens_in_sentence_count', 'succeeding_tokens_in_sentence_count', 'token_ratio', 'relative_position_in_para_char', 'is_in_intro', 'relative_position_in_para_token', 'is_in_conclusion', 'is_first_in_para', 'is_last_in_para', 'nr_preceeding_comps_in_para', 'nr_following_comps_in_para', 'structural_fts_as_text', 'structural_fts_as_text_combined', 'para_ratio', 'first_or_last', 'strct_fts_w_position_in_essay', 'component_pos_tags', 'strct_fts_essay_position_pos_tags'],\n",
       "        num_rows: 943\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed528a65",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 7,
     "id": "57c21a2e-83cd-4f4b-a19a-0bae29eb4794",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Topic: Gender Equality at university admission, Sentence: Therefore, universities follow the requirement of job providers and decide subject suitable for particular gender., First or last in essay: No, First in paragraph: No, Last in paragraph: Yes, In in introduction: No, Is in conclusion: No. Part Of Speech tags: NOUN, VERB, DET, NOUN, ADP, NOUN, NOUN, CCONJ, VERB, NOUN, ADJ, ADP, ADJ, NOUN'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['strct_fts_essay_position_pos_tags'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17ec2213",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "492e0415-2634-47bb-88bf-665c130d032c",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "371cb1a3",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 9,
     "id": "ba2c9132-d013-4b26-be96-146cf024a45e",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "label_names = set(dataset['train']['label_ComponentType'])\n",
    "label_nb = len(label_names)\n",
    "labels = ClassLabel(num_classes=label_nb, names=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cfaa6f5",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 10,
     "id": "2f1ce51b-18bc-40db-983f-3434b8651e45",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(num_classes=3, names={'Premise', 'Claim', 'MajorClaim'}, names_file=None, id=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8934648d",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 11,
     "id": "5438b78c-249c-48ac-98e8-a87a2cc0c86d",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    tokens = tokenizer(batch['strct_fts_essay_position_pos_tags'], truncation=True, padding=True, max_length=512)\n",
    "    tokens['labels'] = labels.str2int(batch['label_ComponentType'])\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c6a570b",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 12,
     "id": "cb8d8c9a-7539-4d02-9dc5-98bade787549",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize at 0x7f04640504c0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02132582664489746,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d708b50208d4136bf15f75b12f88530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016724109649658203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821bd1ac241641eea05fda626e97b112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017401456832885742,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4a1927e370483fa1223e30936a9822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5312743",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 13,
     "id": "84abf830-f842-4e91-8d5c-7fcd9ea2942e",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4935c40",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 14,
     "id": "c7d70e98-c2e0-4055-9d52-74c67c199c72",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['argument_bound_1', 'argument_bound_2', 'argument_id', 'attention_mask', 'component_id', 'component_pos_tags', 'essay', 'essay_nr', 'first_or_last', 'input_ids', 'is_first_in_para', 'is_in_conclusion', 'is_in_intro', 'is_last_in_para', 'label_ComponentType', 'label_LinkedNotLinked', 'label_RelationType', 'label_and_comp_idxs', 'label_x', 'labels', 'nr_following_comps_in_para', 'nr_preceeding_comps_in_para', 'para_nr', 'para_ratio', 'paragraph', 'preceeding_tokens_in_sentence_count', 'relation_SupportAttack', 'relative_position_in_para_char', 'relative_position_in_para_token', 'sentence', 'split', 'strct_fts_essay_position_pos_tags', 'strct_fts_w_position_in_essay', 'structural_fts_as_text', 'structural_fts_as_text_combined', 'succeeding_tokens_in_sentence_count', 'text', 'token_count', 'token_count_covering_para', 'token_ratio', 'token_type_ids', 'tokens_count_covering_sentence', 'total_paras'],\n",
       "        num_rows: 3770\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['argument_bound_1', 'argument_bound_2', 'argument_id', 'attention_mask', 'component_id', 'component_pos_tags', 'essay', 'essay_nr', 'first_or_last', 'input_ids', 'is_first_in_para', 'is_in_conclusion', 'is_in_intro', 'is_last_in_para', 'label_ComponentType', 'label_LinkedNotLinked', 'label_RelationType', 'label_and_comp_idxs', 'label_x', 'labels', 'nr_following_comps_in_para', 'nr_preceeding_comps_in_para', 'para_nr', 'para_ratio', 'paragraph', 'preceeding_tokens_in_sentence_count', 'relation_SupportAttack', 'relative_position_in_para_char', 'relative_position_in_para_token', 'sentence', 'split', 'strct_fts_essay_position_pos_tags', 'strct_fts_w_position_in_essay', 'structural_fts_as_text', 'structural_fts_as_text_combined', 'succeeding_tokens_in_sentence_count', 'text', 'token_count', 'token_count_covering_para', 'token_ratio', 'token_type_ids', 'tokens_count_covering_sentence', 'total_paras'],\n",
       "        num_rows: 1260\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['argument_bound_1', 'argument_bound_2', 'argument_id', 'attention_mask', 'component_id', 'component_pos_tags', 'essay', 'essay_nr', 'first_or_last', 'input_ids', 'is_first_in_para', 'is_in_conclusion', 'is_in_intro', 'is_last_in_para', 'label_ComponentType', 'label_LinkedNotLinked', 'label_RelationType', 'label_and_comp_idxs', 'label_x', 'labels', 'nr_following_comps_in_para', 'nr_preceeding_comps_in_para', 'para_nr', 'para_ratio', 'paragraph', 'preceeding_tokens_in_sentence_count', 'relation_SupportAttack', 'relative_position_in_para_char', 'relative_position_in_para_token', 'sentence', 'split', 'strct_fts_essay_position_pos_tags', 'strct_fts_w_position_in_essay', 'structural_fts_as_text', 'structural_fts_as_text_combined', 'succeeding_tokens_in_sentence_count', 'text', 'token_count', 'token_count_covering_para', 'token_ratio', 'token_type_ids', 'tokens_count_covering_sentence', 'total_paras'],\n",
       "        num_rows: 943\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6944f5fe",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 15,
     "id": "e825c71a-23f8-4794-b114-729819def9ab",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']#.shuffle(seed=42)\n",
    "test_dataset = dataset['test']#.shuffle(seed=42)\n",
    "\n",
    "# train_val_datasets = dataset['train'].train_test_split(train_size=0.8, seed=42)\n",
    "# train_dataset = train_val_datasets['train']\n",
    "val_dataset = dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eed3129f",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 16,
     "id": "e13433b1-343d-417d-bfbd-8bacb4c57d23",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "dataset_d = {}\n",
    "dataset_d['train'] = train_dataset\n",
    "dataset_d['test'] = test_dataset\n",
    "dataset_d['val'] = val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83a00bc2",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 17,
     "id": "a298a871-1a0d-4ed8-9a1c-1ed3795f1d74",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] topic : zoos have no useful purpose?, sentence : in the zoo you can see an animal and their different variations, the male and the female or the baby and the adult, first or last in essay : no, first in paragraph : no, last in paragraph : no, in in introduction : no, is in conclusion : no. part of speech tags : adp, det, noun, pron, verb, verb, det, noun, cconj, det, adj, noun, punct, det, noun, cconj, det, noun, cconj, det, noun, cconj, det, noun [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dataset['train'][2945]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfecf5c2",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 18,
     "id": "aa1384b3-bd47-41a3-86b1-9cf814d47cdf",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRAIN'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "set(dataset_d['train']['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b938a6a3",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 19,
     "id": "84df366a-6334-4e3a-902b-deb1c99491fb",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRAIN'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "set(dataset_d['val']['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e6b3417",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 20,
     "id": "406ad783-a570-4c26-8aa6-243e866b6fbf",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TEST'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "set(dataset_d['test']['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14a43277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "NUM_LABELS = labels.num_classes\n",
    "BATCH_SIZE = 48\n",
    "NB_EPOCHS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcc2b7b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /notebooks/Prompting/notebooks/prompt_template_3/pe_mask_model_prompted_rep_3 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /notebooks/Prompting/notebooks/prompt_template_3/pe_mask_model_prompted_rep_3 and are newly initialized: ['bert.pooler.dense.bias', 'classifier.weight', 'bert.pooler.dense.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"/notebooks/Prompting/notebooks/prompt_template_3/pe_mask_model_prompted_rep_3\", num_labels=NUM_LABELS)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4babd4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(dataset_d['train']['labels'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfe7d203",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = [max(counter.values()) / counter[k] for k in sorted(counter.keys())]\n",
    "class_weights = torch.FloatTensor(class_weights)#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73aafef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 2.5645, 5.2418])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc3f730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9afc36f2",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 27,
     "id": "521987db-56d5-4e71-95af-7d1fb4a06e3f",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "# https://huggingface.co/transformers/main_classes/trainer.html\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        loss_fct = nn.CrossEntropyLoss() #(weight=class_weights)\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "220931aa",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 28,
     "id": "06697293-0ef4-4d24-95a9-6ca0ed569b51",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "metric = load_metric('f1')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    return metric.compute(predictions=predictions, references=labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c657741",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 29,
     "id": "956f8a45-f8bd-42a5-b829-5e2b0e82cf42",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \n",
    "    # output\n",
    "    output_dir=RESULTS_FOLDER,          \n",
    "    \n",
    "    #params\n",
    "    num_train_epochs=NB_EPOCHS,               # nb of epochs\n",
    "    per_device_train_batch_size=BATCH_SIZE,   # batch size per device during training\n",
    "    per_device_eval_batch_size=BATCH_SIZE,    # cf. paper Sun et al.\n",
    "    learning_rate=1e-5,#2e-5,                 # cf. paper Sun et al.\n",
    "#     warmup_steps=500,                         # number of warmup steps for learning rate scheduler\n",
    "    warmup_ratio=0.1,                         # cf. paper Sun et al.\n",
    "    weight_decay=0.01,                        # strength of weight decay\n",
    "    \n",
    "    #eval\n",
    "    evaluation_strategy=\"steps\",              # cf. paper Sun et al.\n",
    "    eval_steps=20,                            # cf. paper Sun et al.\n",
    "    \n",
    "    # log\n",
    "    logging_dir=\"/notebooks/Results/bert_sequence_classification/tb_logs\",  \n",
    "    logging_strategy='steps',\n",
    "    logging_steps=20,\n",
    "    \n",
    "    # save\n",
    "    save_strategy='steps',\n",
    "    save_total_limit=2,\n",
    "    #save_steps=20, # default 500\n",
    "    load_best_model_at_end=True,              # cf. paper Sun et al.\n",
    "    # metric_for_best_model='eval_loss' \n",
    "    metric_for_best_model='f1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfb298b3",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 30,
     "id": "219545f7-5aff-4d0c-87e2-4ca28a6e7acc",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "trainer = CustomTrainer( # Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c906fe41",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 31,
     "id": "b524a80a-ccf0-41f4-a015-e4ba2913fdc4",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running training *****\n",
      "  Num examples = 3770\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 474\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='474' max='474' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [474/474 13:21, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.990500</td>\n",
       "      <td>0.916574</td>\n",
       "      <td>0.251979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.863500</td>\n",
       "      <td>0.766583</td>\n",
       "      <td>0.292528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.629000</td>\n",
       "      <td>0.537245</td>\n",
       "      <td>0.707833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.511500</td>\n",
       "      <td>0.511376</td>\n",
       "      <td>0.717875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.483700</td>\n",
       "      <td>0.556836</td>\n",
       "      <td>0.710166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.442000</td>\n",
       "      <td>0.495707</td>\n",
       "      <td>0.734983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.479500</td>\n",
       "      <td>0.479303</td>\n",
       "      <td>0.730767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.472800</td>\n",
       "      <td>0.451631</td>\n",
       "      <td>0.754287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.471100</td>\n",
       "      <td>0.447004</td>\n",
       "      <td>0.777472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.471793</td>\n",
       "      <td>0.747132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.488427</td>\n",
       "      <td>0.766231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.469600</td>\n",
       "      <td>0.451071</td>\n",
       "      <td>0.768440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.433900</td>\n",
       "      <td>0.444905</td>\n",
       "      <td>0.750601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.422500</td>\n",
       "      <td>0.451325</td>\n",
       "      <td>0.766409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.410300</td>\n",
       "      <td>0.447179</td>\n",
       "      <td>0.761586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.392700</td>\n",
       "      <td>0.454888</td>\n",
       "      <td>0.770428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.413900</td>\n",
       "      <td>0.459585</td>\n",
       "      <td>0.772935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.418200</td>\n",
       "      <td>0.450263</td>\n",
       "      <td>0.777294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.411700</td>\n",
       "      <td>0.447861</td>\n",
       "      <td>0.762674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.384100</td>\n",
       "      <td>0.463540</td>\n",
       "      <td>0.771005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.397000</td>\n",
       "      <td>0.449141</td>\n",
       "      <td>0.774472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.408600</td>\n",
       "      <td>0.443987</td>\n",
       "      <td>0.778949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.381900</td>\n",
       "      <td>0.445458</td>\n",
       "      <td>0.779005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 943\n",
      "  Batch size = 48\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3ecda65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d8b7270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: essay, strct_fts_essay_position_pos_tags, token_count, paragraph, is_in_intro, token_count_covering_para, preceeding_tokens_in_sentence_count, is_last_in_para, label_and_comp_idxs, structural_fts_as_text, para_ratio, label_LinkedNotLinked, label_ComponentType, argument_bound_1, relative_position_in_para_token, succeeding_tokens_in_sentence_count, first_or_last, label_x, component_id, nr_preceeding_comps_in_para, is_in_conclusion, strct_fts_w_position_in_essay, text, sentence, structural_fts_as_text_combined, token_ratio, relative_position_in_para_char, argument_bound_2, essay_nr, is_first_in_para, argument_id, nr_following_comps_in_para, relation_SupportAttack, para_nr, tokens_count_covering_sentence, total_paras, component_pos_tags, label_RelationType, split.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1260\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='158' max='158' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [158/158 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_trainer = Trainer(model, data_collator=DataCollatorWithPadding(tokenizer))\n",
    "test_raw_preds, test_labels, _ = test_trainer.predict(test_dataset)\n",
    "test_preds = np.argmax(test_raw_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3851bd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86f68fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Premise      0.933     0.876     0.903       805\n",
      "       Claim      0.663     0.715     0.688       302\n",
      "  MajorClaim      0.792     0.922     0.852       153\n",
      "\n",
      "    accuracy                          0.843      1260\n",
      "   macro avg      0.796     0.838     0.814      1260\n",
      "weighted avg      0.851     0.843     0.845      1260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_name = labels.int2str([0,1,2])\n",
    "print(classification_report(test_labels, test_preds, target_names=target_name, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a46736",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "     Premise      0.933     0.876     0.903       805\n",
    "       Claim      0.663     0.715     0.688       302\n",
    "  MajorClaim      0.792     0.922     0.852       153\n",
    "\n",
    "    accuracy                          0.843      1260\n",
    "   macro avg      0.796     0.838     0.814      1260\n",
    "weighted avg      0.851     0.843     0.845      1260\n",
    "\n",
    "with the masked saved model prompt rep 3 + strct_fts_essay_position_pos_tags field + normal loss"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b5afc3a",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.683     0.712     0.697       302\n",
    "  MajorClaim      0.781     0.935     0.851       153\n",
    "     Premise      0.936     0.886     0.910       805\n",
    "\n",
    "    accuracy                          0.850      1260\n",
    "   macro avg      0.800     0.844     0.819      1260\n",
    "weighted avg      0.856     0.850     0.852      1260\n",
    "\n",
    "with the masked saved model + strct_fts_essay_position_pos_tags field + normal loss"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e08386e",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "     Premise      0.933     0.876     0.903       805\n",
    "  MajorClaim      0.794     0.935     0.859       153\n",
    "       Claim      0.670     0.719     0.693       302\n",
    "\n",
    "\n",
    "    accuracy                          0.845      1260\n",
    "   macro avg      0.799     0.843     0.818      1260\n",
    "weighted avg      0.853     0.845     0.848      1260\n",
    "\n",
    "with the masked saved model + strct_fts_essay_position_pos_tags field + normal loss"
   ]
  },
  {
   "cell_type": "raw",
   "id": "951539ee",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "     Premise      0.935     0.876     0.904       805\n",
    "       Claim      0.676     0.725     0.700       302\n",
    "  MajorClaim      0.797     0.948     0.866       153\n",
    "\n",
    "    accuracy                          0.848      1260\n",
    "   macro avg      0.803     0.850     0.823      1260\n",
    "weighted avg      0.856     0.848     0.851      1260"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0628932a",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "     Premise      0.934     0.883     0.908       805\n",
    "       Claim      0.677     0.748     0.711       302\n",
    "  MajorClaim      0.824     0.889     0.855       153\n",
    "\n",
    "    accuracy                          0.852      1260\n",
    "   macro avg      0.812     0.840     0.825      1260\n",
    "weighted avg      0.859     0.852     0.854      1260\n",
    "\n",
    "# OLD GOOD RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "356e48cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1803560c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f04482dcd00>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEJCAYAAAAAWTtiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiGklEQVR4nO3deZxU1Zn/8c/TzY7Q0HRDWkBBJTiKAREVNfGnYgyY+QVj3E3CGBxkYkzM7pbELDrOFkfGJWHUCO64ReIQwGBQdFQERI0i0iIIyGI3Owi9PfNHnYYS6OoqqOpbdfv7zuu++t5Tp+596MjDOffec465OyIicVQUdQAiIrmiBCcisaUEJyKxpQQnIrGlBCcisaUEJyKxpQQnIpEws4FmtjBp22xmV5tZqZk9a2ZLws/uob6Z2QQzqzSzN81saHPXUIITkUi4+2J3H+LuQ4DjgO3AU8A1wCx3HwDMCscAo4ABYRsH3NXcNdrkIO79VlZa7P36to06jLy1ZElp1CHkPf9kR9Qh5LUdbKPGd9qBnONLp3f26vX1adWd/+bOGe4+Mo2qI4D33X25mY0GTgvlk4DZwE+B0cBkT4xOeMXMuplZhbuvbuqkeZXg+vVty9wZfaMOI2+NGnVx1CHkvYY3FkUdQl571Wcd8Dmq1tfz6ow+adVtW/F+WZqnvQh4OOz3Skpaa4BeYb83sCLpOytDWWEkOBEpBE69N6RbuczM5iUdT3T3ickVzKwd8BXg2r2u5O5mtt/jSZXgRCQjDjSQds6pcvdhzdQZBSxw97XheG1j19PMKoB1oXwVkNzF6xPKmqSHDCKSsYY0/5emi9ndPQWYCowJ+2OAp5PKvxmepg4HNqW6/wZqwYlIhhynNv0uakpm1hn4InBFUvEtwBQzGwssBy4I5dOAs4FKEk9cL2vu/EpwIpIRB+rT76KmPpf7NqDHHmXVJJ6q7lnXgSszOb8SnIhkLIN7cJFSghORjDhQXyAT5SrBiUjGsnMHLveU4EQkI45n7R5crinBiUhG3KG2MPKbEpyIZMqo54CGs7YYJTgRyYgDDWrBiUhcqQUnIrGUeNFXCU5EYsiBWi+MYexKcCKSEceoL5B5OpTgRCRjDa4uqojEkO7BiUiMGfW6BycicZSY0VcJTkRiyN2o8eKow0iLEpyIZKxB9+BEJI4SDxnURRWRWNJDBhGJKT1kEJFYq9eLviISR45R64WROgqjnSkieaPxIUM6W3PMrJuZPW5m75rZIjM7ycxKzexZM1sSfnYPdc3MJphZpZm9aWZDmzu/EpyIZMQx6j29LQ23AdPd/UhgMLAIuAaY5e4DgFnhGGAUMCBs44C7mju5EpyIZKyBorS2VMysBDgVuAfA3WvcfSMwGpgUqk0Czgn7o4HJnvAK0M3MKlJdozA60jmworI9N4/vt+t4zYft+MaP13Dmeeu5eXw/1q5sR68+NVz/+2V06VbPG/97EDde1p/P9K0B4JSzN/L1H6yNKPpojB69mJEjl2LmTJ9+OH/840AOO2wDV101j7Zt66mvN+64Yxjvvdej+ZPFWPnBNfz4tg/pVl4HDtMe6MEf7ymPOqyscSdbr4n0Bz4G/mBmg4H5wPeAXu6+OtRZA/QK+72BFUnfXxnKVtOEnCY4MxtJoglaDNzt7rfk8nqZ6HvETu76y2IA6uvh0qFHc8qojUy5vSfHfn4LF161jkf/qyeP3t6Ty29I/P4GnbiVX0/+IMqwI3PooRsZOXIpV1/9RWpri/jNb57n1VcPZuzYhTz44NHMm3cwxx//EWPHLuSnPx0RdbiRqq8zJv7qYCrf6kTHzvXcPv09FrzQhQ+XdIg6tKxIPGRIe6hWmZnNSzqe6O4Tw34bYChwlbu/ama3sbs7mriWu5vZfq8AkbMuqpkVA3eQ6DcfBVxsZkfl6noHYuGcLlQcupNefWp5eUYJZ16wHoAzL1jPy9NLIo4uP/Ttu5nFi0vZubMNDQ1FvPVWOaecshJ3o1OnOgA6daqlurpjxJFGb/26tlS+1QmAT7YVs6KyA2UVtRFHlV0ZPGSocvdhSdvEpNOsBFa6+6vh+HESCW9tY9cz/FwXPl8F9E36fp9Q1qRc3oM7Aah096XuXgM8QqIPnXdmP92N087ZCMCGqrb06JX4C1vas44NVW131Vs0vzPjzxzI9ZcexrLF8fjXOF3Ll5dw9NFVdOmyk/bt6zj++NWUl2/n978/lrFjFzJ58tNcfvlC7rtvcNSh5pVefWo4fNAnvLugU9ShZI1jNHh6W8rzuK8BVpjZwFA0AngHmAqMCWVjgKfD/lTgm+Fp6nBgU1JXdp9y2UXdV3/5xBxeb7/U1hivzCzhW9ft/Xsyg8bW8RHHbOf+ue/QsXMDc2d14Zff6s8fXlrU0uFGZsWKEh577Ehuumk2O3a0YenS7jQ0GF/+ciUTJx7LSy/15Qtf+JCrr57LddedHnW4eaFDp3p+dvcyfvfzg9m+tTBm30hXFseiXgU8aGbtgKXAZSQaXlPMbCywHLgg1J0GnA1UAttD3ZQif8hgZuNIPPLlkN4tH85rz3XhiGO207080WrrXlZL9do29OhVR/XaNnTrkSjv3KVh13dOGLGF2681NlUXU9KjvsVjjsrMmYczc+bhAIwZ8wZVVZ247LI3+d3vEq8jzZnTl6uvnhtliHmjuI3zs7uX8dyT3Xnpz92iDierEuuiZifBuftCYNg+PtrrRq67O3BlJufPZRc1rf6yu09s7J+X92j5f+Vm/7H7ru4pwPCzNvOXKaUA/GVKKSd9aRMA69e1wcOtzndf70RDA3QtbT3JDaCkZAcA5eXbOOWUlcyefSjV1R055pjELZIhQ9ayalWXKEPME84P/mMFK5Z04MmJ8Xl6ultiZft0tqjlssn0GjDAzPqTSGwXAZfk8HoZ27G9iAVzuvC9f93dk77wO2u5aXw/pj/Sg569E6+JAMx5phvPTO5BcRto36GBa+9ahkX//1+LuuGGF+natYa6uiLuvPM4tm1rx4QJx3PFFQsoLnZqaoqYMOH4qMOM3NEnbOPM8zew9J0O3Pls4kn9H/65gtee6xpxZNmRWDawMLrc5r7fT2CbP7nZ2cB/knhN5F53vylV/WGDO/jcGX1TVWnVRo26OOoQ8l7DG63nvuj+eNVnsdnXH9A/zb2P7ubfnvL5tOreMOh/5rv7vrqgLSKnN73cfRqJG4MiEiOaD05EYikxH1xh3J9RghORDGlGXxGJqcRrImrBiUgMZTgWNVJKcCKSMa3JICKxlJguSV1UEYkp3YMTkVhKzCaiLqqIxFBiqJYSnIjEklpwIhJjGskgIrGkp6giEmvqoopILDWuyVAIlOBEJCMO1KkFJyJxpS6qiMRTGksC5gslOBHJSCFNeFkY7UwRySvZWPgZwMyWmdlbZrbQzOaFslIze9bMloSf3UO5mdkEM6s0szfNbGhz51eCE5GMNE54mY0EF5zu7kOSFqe5Bpjl7gOAWeEYYBQwIGzjgLuaO7ESnIhkxDHqGorS2vbTaGBS2J8EnJNUPtkTXgG6mVlFqhMpwYlIxhqwtLY0ODDTzOab2bhQ1svdV4f9NUCvsN8bWJH03ZWhrEl6yCAimfGM5oMra7y3Fkx094lJx59391Vm1hN41sze/dSl3N3M9nvxZiU4EclIhovOVKVa+NndV4Wf68zsKeAEYK2ZVbj76tAFXReqrwKSV4bvE8qapC6qiGQsGw8ZzKyzmXVp3AfOAv4GTAXGhGpjgKfD/lTgm+Fp6nBgU1JXdp/UghORjDhG/f4/QEjWC3jKzCCRix5y9+lm9howxczGAsuBC0L9acDZQCWwHbisuQsowYlIxrLxoq+7LwUG76O8Ghixj3IHrszkGkpwIpIRz+whQ6SU4EQkY64EJyLxpMH2IhJjasHthyWLuvLl40ZGHUbeqj6rW9Qh5L2yD7tHHUJes03FB3wOd6hvUIITkZgqlOmSlOBEJCOOuqgiElt6yCAiMeb7Pfy9ZSnBiUjG1EUVkVhKPEUtjHk6lOBEJGPqoopIbKmLKiKx5JgSnIjEV4H0UJXgRCRDDq6hWiISV+qiikhsFfxTVDP7L1J0td39uzmJSETyWlzGos5L8ZmItFYOFHqCc/dJycdm1sndt+c+JBHJd4XSRW12vIWZnWRm7wDvhuPBZnZnziMTkTxleEN6W9TSGVD2n8CXgGoAd38DODWHMYlIvvM0tzSYWbGZvW5mz4Tj/mb2qplVmtmjZtYulLcPx5Xh837NnTutEbPuvmKPovr0QheR2PHEQ4Z0tjR9D1iUdPwvwK3ufgSwARgbyscCG0L5raFeSukkuBVmdjLgZtbWzH60RzAi0tpkqQVnZn2ALwN3h2MDzgAeD1UmAeeE/dHhmPD5iFC/SekkuPEkVpPuDXwEDCHD1aVFJG4szY0yM5uXtI3b40T/CfwEaAjHPYCN7l4XjleSyD2EnysAwuebQv0mNfuir7tXAZc2V09EWpGG5qsEVe4+bF8fmNnfA+vcfb6ZnZadwD4tnaeoh5nZn8zsYzNbZ2ZPm9lhuQhGRApA43tw6WypnQJ8xcyWAY+Q6JreBnQzs8bGVx9gVdhfBfQFCJ+XEB5+NiWdLupDwBSgAjgYeAx4OI3viUhMuae3pT6HX+vufdy9H3AR8Jy7Xwr8FTgvVBsDPB32p4ZjwufPuae+SjoJrpO73+/udWF7AOiQxvdEJK6y+JrIPvwU+IGZVZK4x3ZPKL8H6BHKfwBc09yJUo1FLQ27fzaza0g0IR24EJi236GLSOHL8lAtd58NzA77S4ET9lFnB3B+JudN9ZBhPomE1vgnuSL5WsC1mVxIROLDCmSoVqqxqP1bMhARKRBukAfDsNKR1nxwZjYIOIqke2/uPjlXQYlIniv0FlwjM/sFcBqJBDcNGAW8CCjBibRWcUlwJB7HDgZed/fLzKwX8EBuw2p59/7peT7Z3oaGeqO+3rj6Gyfx+TPXcMm4Svr238b3vzmcykUlUYfZYnqWbOXG85+j9KBPAHhq7t/x6P9+jhGD3ucfz5xHv/INXHbnuSxa1XPXd474TDXXfvUFOrevocGNf7jjXGrqWsek0W3b1fOvkxfStl0DxcXOizPLefCO/nz/pkUcM2wT27YWA3Dr9Uey9N0uEUebBTFKcJ+4e4OZ1ZlZV2Ad4WW7VMzsXqDxTeVBBxhni7j2iuPZvLHdruPllQdx04+P5TvXvR1hVNGobzBum3YSiz8qp1O7GiZf9QRzK/vw/tpSfvLAl7j2q89/qn5xUQO/vGAWN045gyVryijptIO6+sJY/TwbamuKuPZbg9mxvQ3FbRr49/tfZ96cxIsI9/zHYbw0s2czZyggcZjwMsk8M+sG/DeJJ6tbgZfT+N59wO0UcFd2xbKDog4hMtVbOlO9pTMA22va8cG67pR33cbcyn3/23bigBVUrunBkjVlAGza3tpelTR2bE/8dWrTxilu4wWTBPZHwT9FbeTu3w67vzOz6UBXd38zje+9kM58TfnC3fj1HfPAjT8/0YfpTzXbSG01KrptZuDBVby9oleTdQ4p24QDEy57hm6dd/Dsm4dz/wvHtlyQeaCoyLntsXkcfMgnPPNwbxa/1ZWzL1rFmO9+wCXjl7Pw1e784beHUVcbg5ZtoSc4Mxua6jN3X5CbkKLxk7EnUP1xB0q67+Q3d85jxbLOvP16afNfjLmO7Wq55esz+e0zJ7NtZ7sm6xUXNTDk0DWMueNcdtS24c7Ln+HdVeW89n6fFow2Wg0NxlVfO57OXWq5YcLbHHrEVu679TA2VLWjTVvnu79czPmXf8jDd/WLOtQDFocW3H+k+MxJDIw9YGH6lHEAHYqj6xJWf5zoUm3a0J6X/9qLgYM2tfoEV1xUz79cOoMZCwcw++3U8yus23QQry+rYNP2jgC8tPgQBh5c1aoSXKNtW9ry5txuHPf59Tx53yEA1NUazz71Gb72D3vOHVugCqT73WRb2d1PT7FlJbmF60x092HuPqxdUcdsnTYj7TvU0bFT3a79ocOrWV7Zeu+/JTg/+9rzfPBxdx56cXCztV95ry+H91pP+7a1FBc1MLT/R3ywrnsLxJkfunavoXOXWgData/n2JM2sPKDTnQv2xlqOCeNqGJZZefogsyWdMeh5kErr3U8w29G9x41XP/vrwNQXOw8P72C+S+Xc9Lpaxn/40WUdK/hxtsWsPS9Lvz8O/uc2ip2Bh+6hrOHvseS1aU8cNVjANw58wTaFTfww6+8SPfOn/DbMX9myeoefPcPf8+WHe156MXPMenKJ3GH/118CC8tPjTiP0XLKS2v4Yc3v0tRkWNFzpwZPZn7fBn/fO9CSrrXgjlL3z2I23/12ahDzY48SF7psGZmG9n/E5s9TOIF4TJgLfALd78n1XdK2vX0k8svzEk8cfDxWRo915yyqe9GHUJee3nTU2yq+/iA+pft+/b1Pld/P626S3/0w/lNTXjZEnLWgnP3i3N1bhGJWIG04NKZ0dfM7Otm9vNwfIiZ7TWViYi0Dubpb1FL54WcO4GTgMYW2RbgjpxFJCL5LztTludcOl3UE919qJm9DuDuGxoXYhWRVioPWmfpSCfB1ZpZMeGPZGblZLKmjojETj50P9ORToKbADwF9DSzm0jMLnJDTqMSkfzlYAXSxElnLOqDZjYfGEFi+vJz3F0r24u0ZnFpwZnZIcB24E/JZe7+YS4DE5E8FpcEB/wPuxef6QD0BxYDR+cwLhHJY4VyD67Z10Tc/Rh3/1z4OYDEcl7pzAcnItIkM+tgZnPN7A0ze9vMfhnK+5vZq2ZWaWaPNr61YWbtw3Fl+Lxfc9fIeGKqME3SiZl+T0RiJDuD7XcCZ7j7YGAIMNLMhgP/Atzq7kcAG4Cxof5YYEMovzXUSymde3A/SDosAoYCHzUbuojEU5aeonpiIPzWcNg2bI1TsV0SyicBNwJ3AaPDPsDjwO1mZp5iQH06LbguSVt7EvfkRmfw5xCRuEm/BVdmZvOStnHJpzGzYjNbSGKtl2eB94GN7l4XqqwEeof93sAKgPD5JqBHqjBTtuDCC75d3P1Hzf+JRaQ1MDJ6yFCVajYRd68HhoR1X54CjjzQ+JI12YIzszbh4qdk84IiEgNZnvDS3TcCfyUx7r2bmTU2vvoAq8L+KsKKfuHzEqA61XlTdVHnhp8LzWyqmX3DzM5t3NIPXURiJUuziZhZeWi5YWYdgS8Ci0gkuvNCtTHA02F/ajgmfP5cqvtvkN57cB1IZMkz2P0+nANPpvFdEYmj7AzVqgAmhVthRcAUd3/GzN4BHjGz3wCvA40T5d4D3G9mlcB64KLmLpAqwfUMT1D/xu7E1qhAXvMTkVzIxou+YfnRvdaWdPelJN633bN8B3B+JtdIleCKgYP4dGLbda1MLiIiMVMgGSBVglvt7r9qsUhEpDDkyYpZ6UiV4KKfjlNE8lKhjEVNleBGtFgUIlJYCj3Bufv6lgxERApHbCa8FBH5lJjcgxMR2YtRODfoleBEJHNqwYlIXMXhKaqIyL4pwYlILMVp2UARkb2oBScicaV7cCISX0pwmfPaOupWr4k6jLxV+pAGlzRn5xeOiTqEvNYwt31WzqMWnIjEk5OtCS9zTglORDKS4aIzkVKCE5HMKcGJSFxZ6rVe8oYSnIhkRrOJiEicFco9uFTrooqI7JM1pLelPIdZXzP7q5m9Y2Zvm9n3QnmpmT1rZkvCz+6h3MxsgplVmtmbZja0uTiV4EQkc9lZ2b4O+KG7HwUMB640s6OAa4BZ7j4AmBWOAUYBA8I2DriruQsowYlIZrK0sr27r3b3BWF/C4lV7XsDo4FJodok4JywPxqY7AmvAN3MrCLVNZTgRCRz2WnB7WJm/UgsAv0q0MvdV4eP1gC9wn5vYEXS11aGsibpIYOIZCTDF33LzGxe0vFEd5/4qfOZHQQ8AVzt7pvNdk+I7u5utv+PNJTgRCRj1pB2zqly92FNnsesLYnk9qC7PxmK15pZhbuvDl3QdaF8FdA36et9QlmT1EUVkcyk2z1tJgdaoql2D7DI3X+b9NFUYEzYHwM8nVT+zfA0dTiwKakru09qwYlIxrI0o+8pwDeAt8xsYSi7DrgFmGJmY4HlwAXhs2nA2UAlsB24rLkLKMGJSOay8KKvu79I0ysQjthHfQeuzOQaSnAikrFCGcmgBCcimXFAg+1FJK60qpaIxJImvBSR+HJXF1VE4kstOBGJLyU4EYkrteBEJJ4cqC+MDKcEJyIZUwtOROJLT1FFJK7UghOReNKygSISVwaYHjKISFxpZXsRiSd1UQvbsNM2M/7XH1Fc5Pz54VKm3N6r+S/F3Pf/7QNOPGMjG6vbMv6sQQBcft0KThyxkbpa46Pl7fntj/uzbXPr+U/qR/84h+FDVrBxcwcuv/bcT312/qi3GH/pa3x1/CVs3tqBvhUb+cm4ORzRr5p7HzuOx6YdE1HU2VA4Y1FztiZDU6tW57uiIufKm1dxw6X9+cfTBnL66I0cMmBH1GFF7tnHyrhhzGc/VbZgTleuOGsQ/zRyEKs+6MCF3045PX7szHhhANf+21l7lZeXbuW4Yz5ibVXnXWVbtrXn9vuH89i0QS0ZYs5kY13UlpDLRWeaWrU6rw08djsfLWvHmg/bU1dbxOynu3HSlzZFHVbk/ja3C1s2frp1tmBOCQ31iRmn3339IMoqaqIILTJvLf4Mm7e236v821+fy8RHhuG+ezbujZs7snhpOXX1MVnnqXFGkea2iOXst51i1eq81uMztXz8Ubtdx1Wr21JWURthRIXhrAs+Zt7skqjDiNzJQ5dTtaETSz/sEXUoueOJp6jpbFFrkX9O9li1WmLmou98RH2d8dxTMf5LnYb27eq45CtvcN/jQ6MOJfeyvLJ9ruT8jvCeq1bv4/NxwDiADnTKdTjNql7TlvKDd3e1yipqqVrdNsKI8tsXz6vixBEbuebigTS9QFLrcHDPzXymfCsTb/4jAOWl2/jdb57myl/8fzZsiv6/7WzSayI0uWr1p7j7RGAiQFcrjfy3tnhhJ3r3r6FX351Ur2nLaaM3csuVh0YdVl467v9t4rzxq/nJBUeyc0dx1OFE7oOVpZx35SW7jh+8dQr/9LOvsHlrhwijypEsJTgzuxf4e2Cduw8KZaXAo0A/YBlwgbtvCAtF30ZibdTtwD803gZrSs4SXIpVq/NaQ71xx/W9ufmhpRQVw8xHSln+Xgz/A83QNRPe53MnbaFr9zruf2UhD9zamwu/vZq27Rq4+YHFQOJBw39d3y/aQFvQ9Vf+lcF/t4aSg3bwyIRHmPTEUP78/Gf3Wbd7yXbu+vVUOnWsxRuMr418m2/99Fy2f9Jun/XzmgPZW3TmPuB2YHJS2TXALHe/xcyuCcc/BUYBA8J2InBX+Nkk8xw1Nc3s88Ac4C12/zquc/dpTX2nq5X6ibbXeq8SWNsC/MvQwmq/UMjvl+XevLm3s2XzygO6l1DS+WAfftQVadWdOe/G+e4+LFWdcI/+maQW3GLgNHdfbWYVwGx3H2hmvw/7D+9Zr6lz56wF18yq1SJSyBpyum5gr6SktQZofNO+N7Aiqd7KUNbyCU5EYiqzLmqZmc1LOp4Y7rundyl3N9v/V4aV4EQkYxk8Ra1qrou6D2vNrCKpi7oulK8C+ibV6xPKmhST16pFpEXldiTDVGBM2B8DPJ1U/k1LGA5sSnX/DdSCE5GMZW8Ylpk9DJxGoiu7EvgFcAswxczGAsuBC0L1aSReEakk8ZrIZc2dXwlORDKTxVW13P3iJj7a63UKT7zycWUm51eCE5GMaSSDiMSXEpyIxJIDDUpwIhJL+THXWzqU4EQkc0pwIhJLDtTndKhW1ijBiUiGHFwJTkTiSl1UEYklPUUVkVhTC05EYksJTkRiyR3q66OOIi1KcCKSObXgRCS2lOBEJJ5cT1FFJKYcXC/6ikhsaaiWiMSSe66XDcwaJTgRyZweMohIXLlacCIST5rwUkTiqoAG22vhZxHJiANeX5/W1hwzG2lmi82s0syuyXasSnAikhkPE16ms6VgZsXAHcAo4CjgYjM7KpuhKsGJSMa8wdPamnECUOnuS929BngEGJ3NOJXgRCRzWWjBAb2BFUnHK0NZ1uTVQ4YtbKj6iz++POo4kpQBVVEHsUtN1AHsJb9+PwCzog5gL/n2Ozr0QE+whQ0z/uKPl6VZvYOZzUs6nujuEw80hnTlVYJz9/KoY0hmZvPcfVjUceQr/X6aF8ffkbuPzNKpVgF9k477hLKsURdVRKLyGjDAzPqbWTvgImBqNi+QVy04EWk93L3OzL4DzACKgXvd/e1sXkMJLrUWu1dQoPT7aZ5+Rym4+zRgWq7Ob14gQy5ERDKle3AiEltKcPuQ6+Ejhc7M7jWzdWb2t6hjyUdm1tfM/mpm75jZ22b2vahjaq3URd1DGD7yHvBFEi8evgZc7O7vRBpYHjGzU4GtwGR3HxR1PPnGzCqACndfYGZdgPnAOfpvqOWpBbe3nA8fKXTu/gKwPuo48pW7r3b3BWF/C7CILL+hL+lRgttbzoePSOthZv2AY4FXIw6lVVKCE8kRMzsIeAK42t03Rx1Pa6QEt7ecDx+R+DOztiSS24Pu/mTU8bRWSnB7y/nwEYk3MzPgHmCRu/826nhaMyW4Pbh7HdA4fGQRMCXbw0cKnZk9DLwMDDSzlWY2NuqY8swpwDeAM8xsYdjOjjqo1kiviYhIbKkFJyKxpQQnIrGlBCcisaUEJyKxpQQnIrGlBFdAzKw+vHLwNzN7zMw6HcC57jOz88L+3anWozSz08zs5P24xjIz22txkqbK96izNcNr3WhmP8o0Rok3JbjC8om7DwkzeNQA45M/NLP9mqHZ3S9vZqaL04CME5xI1JTgCtcc4IjQuppjZlOBd8ys2Mz+zcxeM7M3zewKSLxdb2a3h3nu/gL0bDyRmc02s2Fhf6SZLTCzN8xsVhgsPh74fmg9fsHMys3siXCN18zslPDdHmY2M8yBdjdgzf0hzOyPZjY/fGfcHp/dGspnmVl5KDvczKaH78wxsyOz8tuUWNKaDAUotNRGAdND0VBgkLt/EJLEJnc/3szaAy+Z2UwSM1oMBI4CegHvAPfucd5y4L+BU8O5St19vZn9Dtjq7v8e6j0E3OruL5rZISRGffwd8AvgRXf/lZl9GUhnhMO3wjU6Aq+Z2RPuXg10Bua5+/fN7Ofh3N8hscbBeHdfYmYnAncCZ+zHr1FaASW4wtLRzBaG/TkkxjueDMx19w9C+VnA5xrvrwElwADgVOBhd68HPjKz5/Zx/uHAC43ncvem5nw7EzgqMeQSgK5h5oxTgXPDd//HzDak8Wf6rpl9Nez3DbFWAw3Ao6H8AeDJcI2TgceSrt0+jWtIK6UEV1g+cfchyQXhL/q25CLgKnefsUe9bI6FLAKGu/uOfcSSNjM7jUSyPMndt5vZbKBDE9U9XHfjnr8DkaboHlz8zAD+KUzXg5l91sw6Ay8AF4Z7dBXA6fv47ivAqWbWP3y3NJRvAbok1ZsJXNV4YGZDwu4LwCWhbBTQvZlYS4ANIbkdSaIF2agIaGyFXkKi67sZ+MDMzg/XMDMb3Mw1pBVTgoufu0ncX1tgiUVhfk+ipf4UsCR8NpnEbCCf4u4fA+NIdAffYHcX8U/AVxsfMgDfBYaFhxjvsPtp7i9JJMi3SXRVP2wm1ulAGzNbBNxCIsE22gacEP4MZwC/CuWXAmNDfG+j6eQlBc0mIiKxpRaciMSWEpyIxJYSnIjElhKciMSWEpyIxJYSnIjElhKciMSWEpyIxNb/AVanhHAdNSbXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ae625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
