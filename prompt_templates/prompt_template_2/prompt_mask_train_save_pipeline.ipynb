{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3ac5ade",
   "metadata": {},
   "source": [
    "# Prompt, Mask, Train, Save, Pipeline-Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd99b32",
   "metadata": {},
   "source": [
    "#### prompt template: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207ec08b",
   "metadata": {},
   "source": [
    "# Notebook:\n",
    "\n",
    "##### Imports\n",
    "##### replace 'MajorClaim' by 'Stance'\n",
    "##### make train and test datasets\n",
    "##### train BERT Mask on the train dataset\n",
    "##### save the model\n",
    "##### create a pipeline using the saved model\n",
    "##### run predictions on it\n",
    "##### evaluate with the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcab434a",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a22c86e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.21.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2021.10.8)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.9.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.0.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.2)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.28.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.2)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (58.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: IProgress in /opt/conda/lib/python3.8/site-packages (0.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from IProgress) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.8/site-packages (2.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (0.9.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.8/site-packages (from datasets) (2022.7.1)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: dill<0.3.6 in /opt/conda/lib/python3.8/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets) (1.21.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets) (1.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install ipywidgets\n",
    "!pip install IProgress\n",
    "!pip install pandas\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec90a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df110ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from datasets import ClassLabel\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54902bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f804554e",
   "metadata": {},
   "source": [
    "### tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc4004d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415d416a",
   "metadata": {},
   "source": [
    "### make the train, test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67a33dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"/notebooks/Prompting/notebooks/pe_dataset_w_prompts_1_2_3_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10403e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename MajorClaim as stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf8238cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_nr</th>\n",
       "      <th>component_id</th>\n",
       "      <th>label_and_comp_idxs</th>\n",
       "      <th>text</th>\n",
       "      <th>label_x</th>\n",
       "      <th>label_ComponentType</th>\n",
       "      <th>relation_SupportAttack</th>\n",
       "      <th>label_RelationType</th>\n",
       "      <th>label_LinkedNotLinked</th>\n",
       "      <th>split</th>\n",
       "      <th>...</th>\n",
       "      <th>nr_following_comps_in_para</th>\n",
       "      <th>structural_fts_as_text</th>\n",
       "      <th>structural_fts_as_text_combined</th>\n",
       "      <th>para_ratio</th>\n",
       "      <th>first_or_last</th>\n",
       "      <th>strct_fts_w_position_in_essay</th>\n",
       "      <th>component_pos_tags</th>\n",
       "      <th>strct_fts_essay_position_pos_tags</th>\n",
       "      <th>prompted_representation_2</th>\n",
       "      <th>prompted_representation_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T1</td>\n",
       "      <td>MajorClaim 503 575</td>\n",
       "      <td>we should attach more importance to cooperatio...</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: PRON, VERB, VERB, ADJ, NO...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T2</td>\n",
       "      <td>MajorClaim 2154 2231</td>\n",
       "      <td>a more cooperative attitudes towards life is m...</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: DET, ADV, ADJ, NOUN, ADP,...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T3</td>\n",
       "      <td>Claim 591 714</td>\n",
       "      <td>through cooperation, children can learn about ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: ADP, NOUN, PUNCT, NOUN, V...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T4</td>\n",
       "      <td>Premise 716 851</td>\n",
       "      <td>What we acquired from team work is not only ho...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: PRON, PRON, VERB, ADP, NO...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T5</td>\n",
       "      <td>Premise 853 1086</td>\n",
       "      <td>During the process of cooperation, children ca...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: ADP, DET, NOUN, ADP, NOUN...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5968</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T11</td>\n",
       "      <td>Premise 1275 1339</td>\n",
       "      <td>indirectly they will learn how to socialize ea...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: ADV, PRON, VERB, VERB, AD...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5969</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T12</td>\n",
       "      <td>Premise 1341 1388</td>\n",
       "      <td>That will make children getting lots of friends</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: DET, VERB, VERB, NOUN, VE...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T13</td>\n",
       "      <td>Premise 1393 1436</td>\n",
       "      <td>they can contribute positively to community</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: PRON, VERB, VERB, ADV, AD...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5971</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T14</td>\n",
       "      <td>Premise 1448 1525</td>\n",
       "      <td>playing sport makes children getting healthy a...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: VERB, NOUN, VERB, NOUN, V...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T15</td>\n",
       "      <td>Claim 916 965</td>\n",
       "      <td>playing sports will give good effects on children</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: VERB, NOUN, VERB, VERB, A...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5973 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_nr component_id   label_and_comp_idxs  \\\n",
       "0     essay001           T1    MajorClaim 503 575   \n",
       "1     essay001           T2  MajorClaim 2154 2231   \n",
       "2     essay001           T3         Claim 591 714   \n",
       "3     essay001           T4       Premise 716 851   \n",
       "4     essay001           T5      Premise 853 1086   \n",
       "...        ...          ...                   ...   \n",
       "5968  essay402          T11     Premise 1275 1339   \n",
       "5969  essay402          T12     Premise 1341 1388   \n",
       "5970  essay402          T13     Premise 1393 1436   \n",
       "5971  essay402          T14     Premise 1448 1525   \n",
       "5972  essay402          T15         Claim 916 965   \n",
       "\n",
       "                                                   text     label_x  \\\n",
       "0     we should attach more importance to cooperatio...  MajorClaim   \n",
       "1     a more cooperative attitudes towards life is m...  MajorClaim   \n",
       "2     through cooperation, children can learn about ...       Claim   \n",
       "3     What we acquired from team work is not only ho...     Premise   \n",
       "4     During the process of cooperation, children ca...     Premise   \n",
       "...                                                 ...         ...   \n",
       "5968  indirectly they will learn how to socialize ea...     Premise   \n",
       "5969    That will make children getting lots of friends     Premise   \n",
       "5970        they can contribute positively to community     Premise   \n",
       "5971  playing sport makes children getting healthy a...     Premise   \n",
       "5972  playing sports will give good effects on children       Claim   \n",
       "\n",
       "     label_ComponentType relation_SupportAttack label_RelationType  \\\n",
       "0             MajorClaim                     []                      \n",
       "1             MajorClaim                     []                      \n",
       "2                  Claim                     []            Support   \n",
       "3                Premise                     []            Support   \n",
       "4                Premise                     []            Support   \n",
       "...                  ...                    ...                ...   \n",
       "5968             Premise                     []            Support   \n",
       "5969             Premise                     []            Support   \n",
       "5970             Premise                     []            Support   \n",
       "5971             Premise                     []            Support   \n",
       "5972               Claim                     []            Support   \n",
       "\n",
       "     label_LinkedNotLinked  split  ... nr_following_comps_in_para  \\\n",
       "0                   Linked  TRAIN  ...                          0   \n",
       "1                   Linked  TRAIN  ...                          0   \n",
       "2                   Linked  TRAIN  ...                          3   \n",
       "3                NotLinked  TRAIN  ...                          2   \n",
       "4                NotLinked  TRAIN  ...                          1   \n",
       "...                    ...    ...  ...                        ...   \n",
       "5968             NotLinked  TRAIN  ...                          3   \n",
       "5969             NotLinked  TRAIN  ...                          2   \n",
       "5970                Linked  TRAIN  ...                          1   \n",
       "5971             NotLinked  TRAIN  ...                          0   \n",
       "5972                Linked  TRAIN  ...                          7   \n",
       "\n",
       "                                 structural_fts_as_text  \\\n",
       "0     Topic: Should students be taught to compete or...   \n",
       "1     Topic: Should students be taught to compete or...   \n",
       "2     Topic: Should students be taught to compete or...   \n",
       "3     Topic: Should students be taught to compete or...   \n",
       "4     Topic: Should students be taught to compete or...   \n",
       "...                                                 ...   \n",
       "5968  Topic: Children should studying hard or playin...   \n",
       "5969  Topic: Children should studying hard or playin...   \n",
       "5970  Topic: Children should studying hard or playin...   \n",
       "5971  Topic: Children should studying hard or playin...   \n",
       "5972  Topic: Children should studying hard or playin...   \n",
       "\n",
       "                        structural_fts_as_text_combined  para_ratio  \\\n",
       "0     Topic: Should students be taught to compete or...        0.25   \n",
       "1     Topic: Should students be taught to compete or...        1.00   \n",
       "2     Topic: Should students be taught to compete or...        0.50   \n",
       "3     Topic: Should students be taught to compete or...        0.50   \n",
       "4     Topic: Should students be taught to compete or...        0.50   \n",
       "...                                                 ...         ...   \n",
       "5968  Topic: Children should studying hard or playin...        0.75   \n",
       "5969  Topic: Children should studying hard or playin...        0.75   \n",
       "5970  Topic: Children should studying hard or playin...        0.75   \n",
       "5971  Topic: Children should studying hard or playin...        0.75   \n",
       "5972  Topic: Children should studying hard or playin...        0.75   \n",
       "\n",
       "     first_or_last                      strct_fts_w_position_in_essay  \\\n",
       "0                1  Topic: Should students be taught to compete or...   \n",
       "1                1  Topic: Should students be taught to compete or...   \n",
       "2                0  Topic: Should students be taught to compete or...   \n",
       "3                0  Topic: Should students be taught to compete or...   \n",
       "4                0  Topic: Should students be taught to compete or...   \n",
       "...            ...                                                ...   \n",
       "5968             0  Topic: Children should studying hard or playin...   \n",
       "5969             0  Topic: Children should studying hard or playin...   \n",
       "5970             0  Topic: Children should studying hard or playin...   \n",
       "5971             0  Topic: Children should studying hard or playin...   \n",
       "5972             0  Topic: Children should studying hard or playin...   \n",
       "\n",
       "                                     component_pos_tags  \\\n",
       "0     Part Of Speech tags: PRON, VERB, VERB, ADJ, NO...   \n",
       "1     Part Of Speech tags: DET, ADV, ADJ, NOUN, ADP,...   \n",
       "2     Part Of Speech tags: ADP, NOUN, PUNCT, NOUN, V...   \n",
       "3     Part Of Speech tags: PRON, PRON, VERB, ADP, NO...   \n",
       "4     Part Of Speech tags: ADP, DET, NOUN, ADP, NOUN...   \n",
       "...                                                 ...   \n",
       "5968  Part Of Speech tags: ADV, PRON, VERB, VERB, AD...   \n",
       "5969  Part Of Speech tags: DET, VERB, VERB, NOUN, VE...   \n",
       "5970  Part Of Speech tags: PRON, VERB, VERB, ADV, AD...   \n",
       "5971  Part Of Speech tags: VERB, NOUN, VERB, NOUN, V...   \n",
       "5972  Part Of Speech tags: VERB, NOUN, VERB, VERB, A...   \n",
       "\n",
       "                      strct_fts_essay_position_pos_tags  \\\n",
       "0     Topic: Should students be taught to compete or...   \n",
       "1     Topic: Should students be taught to compete or...   \n",
       "2     Topic: Should students be taught to compete or...   \n",
       "3     Topic: Should students be taught to compete or...   \n",
       "4     Topic: Should students be taught to compete or...   \n",
       "...                                                 ...   \n",
       "5968  Topic: Children should studying hard or playin...   \n",
       "5969  Topic: Children should studying hard or playin...   \n",
       "5970  Topic: Children should studying hard or playin...   \n",
       "5971  Topic: Children should studying hard or playin...   \n",
       "5972  Topic: Children should studying hard or playin...   \n",
       "\n",
       "                              prompted_representation_2  \\\n",
       "0     Which of these choices best describes the foll...   \n",
       "1     Which of these choices best describes the foll...   \n",
       "2     Which of these choices best describes the foll...   \n",
       "3     Which of these choices best describes the foll...   \n",
       "4     Which of these choices best describes the foll...   \n",
       "...                                                 ...   \n",
       "5968  Which of these choices best describes the foll...   \n",
       "5969  Which of these choices best describes the foll...   \n",
       "5970  Which of these choices best describes the foll...   \n",
       "5971  Which of these choices best describes the foll...   \n",
       "5972  Which of these choices best describes the foll...   \n",
       "\n",
       "                              prompted_representation_3  \n",
       "0     How is the component best described?: \"MajorCl...  \n",
       "1     How is the component best described?: \"MajorCl...  \n",
       "2     How is the component best described?: \"MajorCl...  \n",
       "3     How is the component best described?: \"MajorCl...  \n",
       "4     How is the component best described?: \"MajorCl...  \n",
       "...                                                 ...  \n",
       "5968  How is the component best described?: \"MajorCl...  \n",
       "5969  How is the component best described?: \"MajorCl...  \n",
       "5970  How is the component best described?: \"MajorCl...  \n",
       "5971  How is the component best described?: \"MajorCl...  \n",
       "5972  How is the component best described?: \"MajorCl...  \n",
       "\n",
       "[5973 rows x 41 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c692932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_MC(x):\n",
    "    \n",
    "    prompted_rep = x.prompted_representation_2\n",
    "    \n",
    "    last_token = prompted_rep.split()[-1]\n",
    "    \n",
    "    if last_token == 'MajorClaim.':\n",
    "    \n",
    "        new_rep = prompted_rep.replace(last_token, \"Stance.\")\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        new_rep = prompted_rep\n",
    "    \n",
    "    return new_rep\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "422368ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which of these choices best describes the following component? \"MajorClaim\", \"Claim\" or \"Premise\". Component: Topic: Should students be taught to compete or to cooperate?, Sentence: From this point of view, I firmly believe that we should attach more importance to cooperation during primary education., First or last in essay: Yes, First in paragraph: Yes, Last in paragraph: Yes, In in introduction: Yes, Is in conclusion: No. Part Of Speech tags: PRON, VERB, VERB, ADJ, NOUN, ADP, NOUN, ADP, ADJ, NOUN. Stance.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_MC(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dd5912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct now. now run it on the whole df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c17b62a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prompted_rep_2_w_modif_MC'] = df.apply(lambda x: rename_MC(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f34b391d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which of these choices best describes the following component? \"MajorClaim\", \"Claim\" or \"Premise\". Component: Topic: Should students be taught to compete or to cooperate?, Sentence: From this point of view, I firmly believe that we should attach more importance to cooperation during primary education., First or last in essay: Yes, First in paragraph: Yes, Last in paragraph: Yes, In in introduction: Yes, Is in conclusion: No. Part Of Speech tags: PRON, VERB, VERB, ADJ, NOUN, ADP, NOUN, ADP, ADJ, NOUN. Stance.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prompted_rep_2_w_modif_MC'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eea2f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct the major claim? --> stance business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5f5ae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_mc(x):\n",
    "    \n",
    "    sent = x.prompted_rep_2_w_modif_MC\n",
    "    new_sent = sent.replace('the following component? \"MajorClaim\"', 'the following component? \"Stance\"')\n",
    "    \n",
    "    return new_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7e4e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prompted_rep_2_w_modif_MC_corrected'] = df.apply(lambda x: replace_mc(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a5cef68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which of these choices best describes the following component? \"Stance\", \"Claim\" or \"Premise\". Component: Topic: Should students be taught to compete or to cooperate?, Sentence: From this point of view, I firmly believe that we should attach more importance to cooperation during primary education., First or last in essay: Yes, First in paragraph: Yes, Last in paragraph: Yes, In in introduction: Yes, Is in conclusion: No. Part Of Speech tags: PRON, VERB, VERB, ADJ, NOUN, ADP, NOUN, ADP, ADJ, NOUN. Stance.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prompted_rep_2_w_modif_MC_corrected'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a4ddd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do a sanity check to see if it's correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b2507d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_tokens_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb290316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_token(x):\n",
    "    \n",
    "    prompted_rep = x.prompted_rep_2_w_modif_MC_corrected\n",
    "    \n",
    "    last_token = prompted_rep.split()[-1]\n",
    "    \n",
    "    last_tokens_list.append(last_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77f5e6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       None\n",
       "1       None\n",
       "2       None\n",
       "3       None\n",
       "4       None\n",
       "        ... \n",
       "5968    None\n",
       "5969    None\n",
       "5970    None\n",
       "5971    None\n",
       "5972    None\n",
       "Length: 5973, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(lambda x: get_last_token(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06282893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Stance.',\n",
       " 'Stance.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " 'Claim.',\n",
       " 'Premise.',\n",
       " 'Premise.',\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "494e1c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Claim.', 'Premise.', 'Stance.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(last_tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f166caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### YAAAAAAAAASSSSSSSSSS KINGGGGGGGGGGGGGGGG # correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abead289",
   "metadata": {},
   "source": [
    "## make train, test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1fd1a0",
   "metadata": {},
   "source": [
    "### train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8ead9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df.split == 'TRAIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1125db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77f61e3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_nr</th>\n",
       "      <th>component_id</th>\n",
       "      <th>label_and_comp_idxs</th>\n",
       "      <th>text</th>\n",
       "      <th>label_x</th>\n",
       "      <th>label_ComponentType</th>\n",
       "      <th>relation_SupportAttack</th>\n",
       "      <th>label_RelationType</th>\n",
       "      <th>label_LinkedNotLinked</th>\n",
       "      <th>split</th>\n",
       "      <th>...</th>\n",
       "      <th>structural_fts_as_text_combined</th>\n",
       "      <th>para_ratio</th>\n",
       "      <th>first_or_last</th>\n",
       "      <th>strct_fts_w_position_in_essay</th>\n",
       "      <th>component_pos_tags</th>\n",
       "      <th>strct_fts_essay_position_pos_tags</th>\n",
       "      <th>prompted_representation_2</th>\n",
       "      <th>prompted_representation_3</th>\n",
       "      <th>prompted_rep_2_w_modif_MC</th>\n",
       "      <th>prompted_rep_2_w_modif_MC_corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T1</td>\n",
       "      <td>MajorClaim 503 575</td>\n",
       "      <td>we should attach more importance to cooperatio...</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: PRON, VERB, VERB, ADJ, NO...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T2</td>\n",
       "      <td>MajorClaim 2154 2231</td>\n",
       "      <td>a more cooperative attitudes towards life is m...</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: DET, ADV, ADJ, NOUN, ADP,...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T3</td>\n",
       "      <td>Claim 591 714</td>\n",
       "      <td>through cooperation, children can learn about ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: ADP, NOUN, PUNCT, NOUN, V...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T4</td>\n",
       "      <td>Premise 716 851</td>\n",
       "      <td>What we acquired from team work is not only ho...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: PRON, PRON, VERB, ADP, NO...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T5</td>\n",
       "      <td>Premise 853 1086</td>\n",
       "      <td>During the process of cooperation, children ca...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: ADP, DET, NOUN, ADP, NOUN...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4708</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T11</td>\n",
       "      <td>Premise 1275 1339</td>\n",
       "      <td>indirectly they will learn how to socialize ea...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: ADV, PRON, VERB, VERB, AD...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4709</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T12</td>\n",
       "      <td>Premise 1341 1388</td>\n",
       "      <td>That will make children getting lots of friends</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: DET, VERB, VERB, NOUN, VE...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4710</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T13</td>\n",
       "      <td>Premise 1393 1436</td>\n",
       "      <td>they can contribute positively to community</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: PRON, VERB, VERB, ADV, AD...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4711</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T14</td>\n",
       "      <td>Premise 1448 1525</td>\n",
       "      <td>playing sport makes children getting healthy a...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: VERB, NOUN, VERB, NOUN, V...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T15</td>\n",
       "      <td>Claim 916 965</td>\n",
       "      <td>playing sports will give good effects on children</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: VERB, NOUN, VERB, VERB, A...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4713 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_nr component_id   label_and_comp_idxs  \\\n",
       "0     essay001           T1    MajorClaim 503 575   \n",
       "1     essay001           T2  MajorClaim 2154 2231   \n",
       "2     essay001           T3         Claim 591 714   \n",
       "3     essay001           T4       Premise 716 851   \n",
       "4     essay001           T5      Premise 853 1086   \n",
       "...        ...          ...                   ...   \n",
       "4708  essay402          T11     Premise 1275 1339   \n",
       "4709  essay402          T12     Premise 1341 1388   \n",
       "4710  essay402          T13     Premise 1393 1436   \n",
       "4711  essay402          T14     Premise 1448 1525   \n",
       "4712  essay402          T15         Claim 916 965   \n",
       "\n",
       "                                                   text     label_x  \\\n",
       "0     we should attach more importance to cooperatio...  MajorClaim   \n",
       "1     a more cooperative attitudes towards life is m...  MajorClaim   \n",
       "2     through cooperation, children can learn about ...       Claim   \n",
       "3     What we acquired from team work is not only ho...     Premise   \n",
       "4     During the process of cooperation, children ca...     Premise   \n",
       "...                                                 ...         ...   \n",
       "4708  indirectly they will learn how to socialize ea...     Premise   \n",
       "4709    That will make children getting lots of friends     Premise   \n",
       "4710        they can contribute positively to community     Premise   \n",
       "4711  playing sport makes children getting healthy a...     Premise   \n",
       "4712  playing sports will give good effects on children       Claim   \n",
       "\n",
       "     label_ComponentType relation_SupportAttack label_RelationType  \\\n",
       "0             MajorClaim                     []                      \n",
       "1             MajorClaim                     []                      \n",
       "2                  Claim                     []            Support   \n",
       "3                Premise                     []            Support   \n",
       "4                Premise                     []            Support   \n",
       "...                  ...                    ...                ...   \n",
       "4708             Premise                     []            Support   \n",
       "4709             Premise                     []            Support   \n",
       "4710             Premise                     []            Support   \n",
       "4711             Premise                     []            Support   \n",
       "4712               Claim                     []            Support   \n",
       "\n",
       "     label_LinkedNotLinked  split  ...  \\\n",
       "0                   Linked  TRAIN  ...   \n",
       "1                   Linked  TRAIN  ...   \n",
       "2                   Linked  TRAIN  ...   \n",
       "3                NotLinked  TRAIN  ...   \n",
       "4                NotLinked  TRAIN  ...   \n",
       "...                    ...    ...  ...   \n",
       "4708             NotLinked  TRAIN  ...   \n",
       "4709             NotLinked  TRAIN  ...   \n",
       "4710                Linked  TRAIN  ...   \n",
       "4711             NotLinked  TRAIN  ...   \n",
       "4712                Linked  TRAIN  ...   \n",
       "\n",
       "                        structural_fts_as_text_combined  para_ratio  \\\n",
       "0     Topic: Should students be taught to compete or...        0.25   \n",
       "1     Topic: Should students be taught to compete or...        1.00   \n",
       "2     Topic: Should students be taught to compete or...        0.50   \n",
       "3     Topic: Should students be taught to compete or...        0.50   \n",
       "4     Topic: Should students be taught to compete or...        0.50   \n",
       "...                                                 ...         ...   \n",
       "4708  Topic: Children should studying hard or playin...        0.75   \n",
       "4709  Topic: Children should studying hard or playin...        0.75   \n",
       "4710  Topic: Children should studying hard or playin...        0.75   \n",
       "4711  Topic: Children should studying hard or playin...        0.75   \n",
       "4712  Topic: Children should studying hard or playin...        0.75   \n",
       "\n",
       "      first_or_last                      strct_fts_w_position_in_essay  \\\n",
       "0                 1  Topic: Should students be taught to compete or...   \n",
       "1                 1  Topic: Should students be taught to compete or...   \n",
       "2                 0  Topic: Should students be taught to compete or...   \n",
       "3                 0  Topic: Should students be taught to compete or...   \n",
       "4                 0  Topic: Should students be taught to compete or...   \n",
       "...             ...                                                ...   \n",
       "4708              0  Topic: Children should studying hard or playin...   \n",
       "4709              0  Topic: Children should studying hard or playin...   \n",
       "4710              0  Topic: Children should studying hard or playin...   \n",
       "4711              0  Topic: Children should studying hard or playin...   \n",
       "4712              0  Topic: Children should studying hard or playin...   \n",
       "\n",
       "                                     component_pos_tags  \\\n",
       "0     Part Of Speech tags: PRON, VERB, VERB, ADJ, NO...   \n",
       "1     Part Of Speech tags: DET, ADV, ADJ, NOUN, ADP,...   \n",
       "2     Part Of Speech tags: ADP, NOUN, PUNCT, NOUN, V...   \n",
       "3     Part Of Speech tags: PRON, PRON, VERB, ADP, NO...   \n",
       "4     Part Of Speech tags: ADP, DET, NOUN, ADP, NOUN...   \n",
       "...                                                 ...   \n",
       "4708  Part Of Speech tags: ADV, PRON, VERB, VERB, AD...   \n",
       "4709  Part Of Speech tags: DET, VERB, VERB, NOUN, VE...   \n",
       "4710  Part Of Speech tags: PRON, VERB, VERB, ADV, AD...   \n",
       "4711  Part Of Speech tags: VERB, NOUN, VERB, NOUN, V...   \n",
       "4712  Part Of Speech tags: VERB, NOUN, VERB, VERB, A...   \n",
       "\n",
       "                      strct_fts_essay_position_pos_tags  \\\n",
       "0     Topic: Should students be taught to compete or...   \n",
       "1     Topic: Should students be taught to compete or...   \n",
       "2     Topic: Should students be taught to compete or...   \n",
       "3     Topic: Should students be taught to compete or...   \n",
       "4     Topic: Should students be taught to compete or...   \n",
       "...                                                 ...   \n",
       "4708  Topic: Children should studying hard or playin...   \n",
       "4709  Topic: Children should studying hard or playin...   \n",
       "4710  Topic: Children should studying hard or playin...   \n",
       "4711  Topic: Children should studying hard or playin...   \n",
       "4712  Topic: Children should studying hard or playin...   \n",
       "\n",
       "                              prompted_representation_2  \\\n",
       "0     Which of these choices best describes the foll...   \n",
       "1     Which of these choices best describes the foll...   \n",
       "2     Which of these choices best describes the foll...   \n",
       "3     Which of these choices best describes the foll...   \n",
       "4     Which of these choices best describes the foll...   \n",
       "...                                                 ...   \n",
       "4708  Which of these choices best describes the foll...   \n",
       "4709  Which of these choices best describes the foll...   \n",
       "4710  Which of these choices best describes the foll...   \n",
       "4711  Which of these choices best describes the foll...   \n",
       "4712  Which of these choices best describes the foll...   \n",
       "\n",
       "                              prompted_representation_3  \\\n",
       "0     How is the component best described?: \"MajorCl...   \n",
       "1     How is the component best described?: \"MajorCl...   \n",
       "2     How is the component best described?: \"MajorCl...   \n",
       "3     How is the component best described?: \"MajorCl...   \n",
       "4     How is the component best described?: \"MajorCl...   \n",
       "...                                                 ...   \n",
       "4708  How is the component best described?: \"MajorCl...   \n",
       "4709  How is the component best described?: \"MajorCl...   \n",
       "4710  How is the component best described?: \"MajorCl...   \n",
       "4711  How is the component best described?: \"MajorCl...   \n",
       "4712  How is the component best described?: \"MajorCl...   \n",
       "\n",
       "                              prompted_rep_2_w_modif_MC  \\\n",
       "0     Which of these choices best describes the foll...   \n",
       "1     Which of these choices best describes the foll...   \n",
       "2     Which of these choices best describes the foll...   \n",
       "3     Which of these choices best describes the foll...   \n",
       "4     Which of these choices best describes the foll...   \n",
       "...                                                 ...   \n",
       "4708  Which of these choices best describes the foll...   \n",
       "4709  Which of these choices best describes the foll...   \n",
       "4710  Which of these choices best describes the foll...   \n",
       "4711  Which of these choices best describes the foll...   \n",
       "4712  Which of these choices best describes the foll...   \n",
       "\n",
       "                    prompted_rep_2_w_modif_MC_corrected  \n",
       "0     Which of these choices best describes the foll...  \n",
       "1     Which of these choices best describes the foll...  \n",
       "2     Which of these choices best describes the foll...  \n",
       "3     Which of these choices best describes the foll...  \n",
       "4     Which of these choices best describes the foll...  \n",
       "...                                                 ...  \n",
       "4708  Which of these choices best describes the foll...  \n",
       "4709  Which of these choices best describes the foll...  \n",
       "4710  Which of these choices best describes the foll...  \n",
       "4711  Which of these choices best describes the foll...  \n",
       "4712  Which of these choices best describes the foll...  \n",
       "\n",
       "[4713 rows x 43 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23f1d254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRAIN    4713\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e998871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompted_texts_train_full = df_train['prompted_rep_2_w_modif_MC_corrected'][:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "918533f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4713"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompted_texts_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8718c93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "942.6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4713 * .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "389f5e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c434acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompted_texts_val = random.sample(prompted_texts_train_full, 472)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f07e58c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompted_texts_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "deb6fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompted_texts_train = [x for x in prompted_texts_train_full if x not in prompted_texts_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "999ac532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4241"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompted_texts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "514c559b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4713"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompted_texts_train) + len(prompted_texts_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8a6ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepare train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94006b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = tokenizer(prompted_texts_train, return_tensors='pt', max_length=512, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a842c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb479a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4241, 512])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8154dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training we will need labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1dd6468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train['labels'] = inputs_train.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29ce3baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0]])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "add3dd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4241, 512])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b1bf662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find where the last 102 is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66aff520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inputs_train['input_ids'][0] == 102).nonzero(as_tuple=True)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72a14583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c l a i m'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(4366)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8bdf79a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p r e m i s e'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(18458)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3b99ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# claim = 4366, premise = 18458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "01385349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inputs_train['input_ids'][1] == 102).nonzero(as_tuple=True)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9e73bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(102)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train['input_ids'][1][151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3ae5c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that all at [len-2] indices are either claim or premise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36b0b3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_indices_list = []\n",
    "\n",
    "for i in range(len(prompted_texts_train)):\n",
    "    sep_idx = (inputs_train['input_ids'][i] == 102).nonzero(as_tuple=True)[0].item()\n",
    "    sep_indices_list.append(sep_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "294b4c07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[126,\n",
       " 151,\n",
       " 150,\n",
       " 176,\n",
       " 225,\n",
       " 155,\n",
       " 106,\n",
       " 135,\n",
       " 157,\n",
       " 293,\n",
       " 119,\n",
       " 145,\n",
       " 159,\n",
       " 148,\n",
       " 118,\n",
       " 193,\n",
       " 144,\n",
       " 129,\n",
       " 154,\n",
       " 124,\n",
       " 134,\n",
       " 181,\n",
       " 147,\n",
       " 140,\n",
       " 167,\n",
       " 148,\n",
       " 110,\n",
       " 145,\n",
       " 184,\n",
       " 156,\n",
       " 136,\n",
       " 124,\n",
       " 213,\n",
       " 146,\n",
       " 133,\n",
       " 130,\n",
       " 136,\n",
       " 226,\n",
       " 212,\n",
       " 166,\n",
       " 158,\n",
       " 141,\n",
       " 124,\n",
       " 129,\n",
       " 162,\n",
       " 132,\n",
       " 137,\n",
       " 149,\n",
       " 185,\n",
       " 175,\n",
       " 153,\n",
       " 175,\n",
       " 148,\n",
       " 175,\n",
       " 170,\n",
       " 109,\n",
       " 126,\n",
       " 112,\n",
       " 115,\n",
       " 97,\n",
       " 116,\n",
       " 138,\n",
       " 160,\n",
       " 114,\n",
       " 136,\n",
       " 105,\n",
       " 129,\n",
       " 103,\n",
       " 133,\n",
       " 136,\n",
       " 161,\n",
       " 107,\n",
       " 131,\n",
       " 145,\n",
       " 143,\n",
       " 133,\n",
       " 182,\n",
       " 117,\n",
       " 144,\n",
       " 156,\n",
       " 157,\n",
       " 138,\n",
       " 148,\n",
       " 120,\n",
       " 131,\n",
       " 110,\n",
       " 118,\n",
       " 162,\n",
       " 168,\n",
       " 122,\n",
       " 104,\n",
       " 121,\n",
       " 135,\n",
       " 165,\n",
       " 135,\n",
       " 123,\n",
       " 107,\n",
       " 120,\n",
       " 131,\n",
       " 101,\n",
       " 135,\n",
       " 236,\n",
       " 220,\n",
       " 107,\n",
       " 125,\n",
       " 151,\n",
       " 150,\n",
       " 149,\n",
       " 175,\n",
       " 124,\n",
       " 128,\n",
       " 121,\n",
       " 124,\n",
       " 107,\n",
       " 147,\n",
       " 106,\n",
       " 100,\n",
       " 191,\n",
       " 138,\n",
       " 159,\n",
       " 135,\n",
       " 137,\n",
       " 139,\n",
       " 133,\n",
       " 155,\n",
       " 158,\n",
       " 144,\n",
       " 132,\n",
       " 154,\n",
       " 110,\n",
       " 154,\n",
       " 121,\n",
       " 124,\n",
       " 160,\n",
       " 109,\n",
       " 103,\n",
       " 110,\n",
       " 152,\n",
       " 148,\n",
       " 170,\n",
       " 151,\n",
       " 156,\n",
       " 155,\n",
       " 121,\n",
       " 201,\n",
       " 142,\n",
       " 109,\n",
       " 150,\n",
       " 150,\n",
       " 111,\n",
       " 182,\n",
       " 141,\n",
       " 150,\n",
       " 131,\n",
       " 133,\n",
       " 179,\n",
       " 132,\n",
       " 143,\n",
       " 194,\n",
       " 114,\n",
       " 124,\n",
       " 135,\n",
       " 214,\n",
       " 129,\n",
       " 152,\n",
       " 123,\n",
       " 105,\n",
       " 142,\n",
       " 149,\n",
       " 168,\n",
       " 130,\n",
       " 118,\n",
       " 165,\n",
       " 116,\n",
       " 126,\n",
       " 107,\n",
       " 186,\n",
       " 155,\n",
       " 166,\n",
       " 117,\n",
       " 131,\n",
       " 120,\n",
       " 114,\n",
       " 106,\n",
       " 109,\n",
       " 109,\n",
       " 132,\n",
       " 121,\n",
       " 123,\n",
       " 126,\n",
       " 106,\n",
       " 110,\n",
       " 96,\n",
       " 135,\n",
       " 99,\n",
       " 130,\n",
       " 137,\n",
       " 141,\n",
       " 147,\n",
       " 215,\n",
       " 125,\n",
       " 164,\n",
       " 138,\n",
       " 125,\n",
       " 135,\n",
       " 115,\n",
       " 128,\n",
       " 148,\n",
       " 202,\n",
       " 125,\n",
       " 163,\n",
       " 134,\n",
       " 135,\n",
       " 157,\n",
       " 173,\n",
       " 172,\n",
       " 137,\n",
       " 129,\n",
       " 169,\n",
       " 137,\n",
       " 168,\n",
       " 106,\n",
       " 132,\n",
       " 167,\n",
       " 201,\n",
       " 142,\n",
       " 180,\n",
       " 192,\n",
       " 144,\n",
       " 145,\n",
       " 192,\n",
       " 115,\n",
       " 149,\n",
       " 151,\n",
       " 167,\n",
       " 123,\n",
       " 162,\n",
       " 137,\n",
       " 124,\n",
       " 161,\n",
       " 164,\n",
       " 147,\n",
       " 107,\n",
       " 188,\n",
       " 125,\n",
       " 92,\n",
       " 135,\n",
       " 130,\n",
       " 166,\n",
       " 131,\n",
       " 136,\n",
       " 112,\n",
       " 174,\n",
       " 141,\n",
       " 162,\n",
       " 145,\n",
       " 177,\n",
       " 126,\n",
       " 145,\n",
       " 120,\n",
       " 151,\n",
       " 122,\n",
       " 137,\n",
       " 154,\n",
       " 124,\n",
       " 174,\n",
       " 186,\n",
       " 90,\n",
       " 140,\n",
       " 132,\n",
       " 145,\n",
       " 176,\n",
       " 137,\n",
       " 124,\n",
       " 186,\n",
       " 95,\n",
       " 152,\n",
       " 112,\n",
       " 145,\n",
       " 117,\n",
       " 113,\n",
       " 163,\n",
       " 169,\n",
       " 114,\n",
       " 178,\n",
       " 160,\n",
       " 100,\n",
       " 174,\n",
       " 191,\n",
       " 122,\n",
       " 153,\n",
       " 134,\n",
       " 132,\n",
       " 97,\n",
       " 140,\n",
       " 140,\n",
       " 149,\n",
       " 139,\n",
       " 144,\n",
       " 152,\n",
       " 131,\n",
       " 156,\n",
       " 134,\n",
       " 124,\n",
       " 154,\n",
       " 133,\n",
       " 157,\n",
       " 135,\n",
       " 128,\n",
       " 156,\n",
       " 122,\n",
       " 136,\n",
       " 161,\n",
       " 143,\n",
       " 160,\n",
       " 120,\n",
       " 113,\n",
       " 129,\n",
       " 187,\n",
       " 154,\n",
       " 134,\n",
       " 134,\n",
       " 180,\n",
       " 178,\n",
       " 117,\n",
       " 179,\n",
       " 173,\n",
       " 187,\n",
       " 122,\n",
       " 138,\n",
       " 131,\n",
       " 180,\n",
       " 136,\n",
       " 144,\n",
       " 117,\n",
       " 137,\n",
       " 146,\n",
       " 152,\n",
       " 140,\n",
       " 143,\n",
       " 133,\n",
       " 115,\n",
       " 181,\n",
       " 123,\n",
       " 126,\n",
       " 141,\n",
       " 120,\n",
       " 151,\n",
       " 144,\n",
       " 196,\n",
       " 130,\n",
       " 150,\n",
       " 136,\n",
       " 147,\n",
       " 200,\n",
       " 151,\n",
       " 151,\n",
       " 160,\n",
       " 170,\n",
       " 153,\n",
       " 188,\n",
       " 137,\n",
       " 139,\n",
       " 124,\n",
       " 183,\n",
       " 169,\n",
       " 128,\n",
       " 119,\n",
       " 99,\n",
       " 129,\n",
       " 133,\n",
       " 144,\n",
       " 135,\n",
       " 133,\n",
       " 109,\n",
       " 119,\n",
       " 169,\n",
       " 121,\n",
       " 121,\n",
       " 139,\n",
       " 113,\n",
       " 117,\n",
       " 145,\n",
       " 143,\n",
       " 165,\n",
       " 170,\n",
       " 142,\n",
       " 120,\n",
       " 155,\n",
       " 132,\n",
       " 109,\n",
       " 114,\n",
       " 123,\n",
       " 122,\n",
       " 139,\n",
       " 155,\n",
       " 105,\n",
       " 161,\n",
       " 145,\n",
       " 147,\n",
       " 107,\n",
       " 158,\n",
       " 145,\n",
       " 141,\n",
       " 127,\n",
       " 134,\n",
       " 111,\n",
       " 139,\n",
       " 135,\n",
       " 141,\n",
       " 107,\n",
       " 102,\n",
       " 113,\n",
       " 110,\n",
       " 138,\n",
       " 155,\n",
       " 109,\n",
       " 123,\n",
       " 115,\n",
       " 129,\n",
       " 130,\n",
       " 161,\n",
       " 151,\n",
       " 146,\n",
       " 130,\n",
       " 119,\n",
       " 142,\n",
       " 113,\n",
       " 155,\n",
       " 146,\n",
       " 147,\n",
       " 184,\n",
       " 158,\n",
       " 123,\n",
       " 122,\n",
       " 155,\n",
       " 181,\n",
       " 165,\n",
       " 150,\n",
       " 151,\n",
       " 111,\n",
       " 126,\n",
       " 108,\n",
       " 130,\n",
       " 127,\n",
       " 132,\n",
       " 111,\n",
       " 157,\n",
       " 139,\n",
       " 111,\n",
       " 170,\n",
       " 141,\n",
       " 130,\n",
       " 131,\n",
       " 157,\n",
       " 132,\n",
       " 146,\n",
       " 139,\n",
       " 134,\n",
       " 139,\n",
       " 140,\n",
       " 175,\n",
       " 182,\n",
       " 111,\n",
       " 131,\n",
       " 148,\n",
       " 162,\n",
       " 143,\n",
       " 149,\n",
       " 147,\n",
       " 137,\n",
       " 126,\n",
       " 219,\n",
       " 251,\n",
       " 164,\n",
       " 193,\n",
       " 195,\n",
       " 179,\n",
       " 168,\n",
       " 137,\n",
       " 130,\n",
       " 129,\n",
       " 154,\n",
       " 134,\n",
       " 134,\n",
       " 137,\n",
       " 109,\n",
       " 142,\n",
       " 120,\n",
       " 142,\n",
       " 166,\n",
       " 153,\n",
       " 144,\n",
       " 151,\n",
       " 151,\n",
       " 145,\n",
       " 177,\n",
       " 114,\n",
       " 137,\n",
       " 151,\n",
       " 121,\n",
       " 146,\n",
       " 163,\n",
       " 140,\n",
       " 125,\n",
       " 156,\n",
       " 198,\n",
       " 134,\n",
       " 225,\n",
       " 122,\n",
       " 134,\n",
       " 153,\n",
       " 115,\n",
       " 199,\n",
       " 137,\n",
       " 117,\n",
       " 158,\n",
       " 138,\n",
       " 140,\n",
       " 182,\n",
       " 143,\n",
       " 153,\n",
       " 126,\n",
       " 144,\n",
       " 137,\n",
       " 155,\n",
       " 160,\n",
       " 144,\n",
       " 126,\n",
       " 130,\n",
       " 189,\n",
       " 173,\n",
       " 132,\n",
       " 199,\n",
       " 139,\n",
       " 153,\n",
       " 159,\n",
       " 159,\n",
       " 130,\n",
       " 167,\n",
       " 161,\n",
       " 148,\n",
       " 182,\n",
       " 116,\n",
       " 145,\n",
       " 185,\n",
       " 132,\n",
       " 109,\n",
       " 119,\n",
       " 122,\n",
       " 144,\n",
       " 171,\n",
       " 192,\n",
       " 125,\n",
       " 109,\n",
       " 126,\n",
       " 108,\n",
       " 161,\n",
       " 119,\n",
       " 133,\n",
       " 116,\n",
       " 102,\n",
       " 135,\n",
       " 140,\n",
       " 129,\n",
       " 101,\n",
       " 108,\n",
       " 144,\n",
       " 101,\n",
       " 114,\n",
       " 100,\n",
       " 179,\n",
       " 114,\n",
       " 134,\n",
       " 113,\n",
       " 114,\n",
       " 133,\n",
       " 136,\n",
       " 114,\n",
       " 171,\n",
       " 145,\n",
       " 167,\n",
       " 167,\n",
       " 194,\n",
       " 110,\n",
       " 118,\n",
       " 142,\n",
       " 127,\n",
       " 154,\n",
       " 120,\n",
       " 171,\n",
       " 113,\n",
       " 115,\n",
       " 157,\n",
       " 155,\n",
       " 186,\n",
       " 156,\n",
       " 125,\n",
       " 121,\n",
       " 123,\n",
       " 198,\n",
       " 116,\n",
       " 180,\n",
       " 114,\n",
       " 160,\n",
       " 135,\n",
       " 178,\n",
       " 133,\n",
       " 145,\n",
       " 142,\n",
       " 173,\n",
       " 121,\n",
       " 119,\n",
       " 159,\n",
       " 133,\n",
       " 110,\n",
       " 122,\n",
       " 117,\n",
       " 109,\n",
       " 167,\n",
       " 129,\n",
       " 126,\n",
       " 106,\n",
       " 122,\n",
       " 142,\n",
       " 126,\n",
       " 99,\n",
       " 108,\n",
       " 120,\n",
       " 179,\n",
       " 167,\n",
       " 137,\n",
       " 125,\n",
       " 153,\n",
       " 100,\n",
       " 157,\n",
       " 129,\n",
       " 112,\n",
       " 155,\n",
       " 149,\n",
       " 147,\n",
       " 121,\n",
       " 103,\n",
       " 118,\n",
       " 114,\n",
       " 99,\n",
       " 148,\n",
       " 140,\n",
       " 128,\n",
       " 126,\n",
       " 137,\n",
       " 114,\n",
       " 100,\n",
       " 127,\n",
       " 109,\n",
       " 138,\n",
       " 112,\n",
       " 104,\n",
       " 142,\n",
       " 134,\n",
       " 123,\n",
       " 109,\n",
       " 141,\n",
       " 122,\n",
       " 106,\n",
       " 161,\n",
       " 126,\n",
       " 116,\n",
       " 110,\n",
       " 119,\n",
       " 138,\n",
       " 135,\n",
       " 164,\n",
       " 103,\n",
       " 109,\n",
       " 122,\n",
       " 141,\n",
       " 141,\n",
       " 136,\n",
       " 138,\n",
       " 142,\n",
       " 143,\n",
       " 163,\n",
       " 132,\n",
       " 150,\n",
       " 119,\n",
       " 136,\n",
       " 124,\n",
       " 118,\n",
       " 178,\n",
       " 118,\n",
       " 110,\n",
       " 123,\n",
       " 133,\n",
       " 114,\n",
       " 141,\n",
       " 121,\n",
       " 118,\n",
       " 131,\n",
       " 169,\n",
       " 152,\n",
       " 121,\n",
       " 160,\n",
       " 126,\n",
       " 125,\n",
       " 159,\n",
       " 128,\n",
       " 111,\n",
       " 162,\n",
       " 117,\n",
       " 141,\n",
       " 164,\n",
       " 233,\n",
       " 183,\n",
       " 133,\n",
       " 120,\n",
       " 261,\n",
       " 131,\n",
       " 163,\n",
       " 155,\n",
       " 145,\n",
       " 149,\n",
       " 134,\n",
       " 186,\n",
       " 174,\n",
       " 141,\n",
       " 122,\n",
       " 157,\n",
       " 134,\n",
       " 193,\n",
       " 202,\n",
       " 172,\n",
       " 174,\n",
       " 131,\n",
       " 198,\n",
       " 139,\n",
       " 127,\n",
       " 172,\n",
       " 124,\n",
       " 193,\n",
       " 148,\n",
       " 173,\n",
       " 187,\n",
       " 134,\n",
       " 170,\n",
       " 194,\n",
       " 135,\n",
       " 143,\n",
       " 158,\n",
       " 182,\n",
       " 155,\n",
       " 145,\n",
       " 147,\n",
       " 121,\n",
       " 124,\n",
       " 166,\n",
       " 180,\n",
       " 149,\n",
       " 144,\n",
       " 201,\n",
       " 150,\n",
       " 138,\n",
       " 132,\n",
       " 171,\n",
       " 136,\n",
       " 135,\n",
       " 173,\n",
       " 217,\n",
       " 181,\n",
       " 114,\n",
       " 163,\n",
       " 137,\n",
       " 177,\n",
       " 256,\n",
       " 138,\n",
       " 174,\n",
       " 232,\n",
       " 155,\n",
       " 131,\n",
       " 155,\n",
       " 163,\n",
       " 163,\n",
       " 167,\n",
       " 159,\n",
       " 159,\n",
       " 138,\n",
       " 148,\n",
       " 152,\n",
       " 165,\n",
       " 190,\n",
       " 113,\n",
       " 143,\n",
       " 168,\n",
       " 167,\n",
       " 132,\n",
       " 171,\n",
       " 113,\n",
       " 199,\n",
       " 159,\n",
       " 144,\n",
       " 102,\n",
       " 134,\n",
       " 156,\n",
       " 182,\n",
       " 122,\n",
       " 125,\n",
       " 139,\n",
       " 127,\n",
       " 137,\n",
       " 126,\n",
       " 159,\n",
       " 151,\n",
       " 140,\n",
       " 157,\n",
       " 109,\n",
       " 128,\n",
       " 148,\n",
       " 110,\n",
       " 137,\n",
       " 174,\n",
       " 172,\n",
       " 164,\n",
       " 162,\n",
       " 128,\n",
       " 192,\n",
       " 168,\n",
       " 181,\n",
       " 226,\n",
       " 133,\n",
       " 170,\n",
       " 167,\n",
       " 157,\n",
       " 166,\n",
       " 143,\n",
       " 173,\n",
       " 189,\n",
       " 184,\n",
       " 223,\n",
       " 114,\n",
       " 118,\n",
       " 153,\n",
       " 137,\n",
       " 129,\n",
       " 140,\n",
       " 120,\n",
       " 206,\n",
       " 133,\n",
       " 96,\n",
       " 172,\n",
       " 195,\n",
       " 134,\n",
       " 119,\n",
       " 204,\n",
       " 122,\n",
       " 108,\n",
       " 139,\n",
       " 124,\n",
       " 133,\n",
       " 141,\n",
       " 130,\n",
       " 109,\n",
       " 200,\n",
       " 120,\n",
       " 116,\n",
       " 120,\n",
       " 147,\n",
       " 151,\n",
       " 147,\n",
       " 135,\n",
       " 136,\n",
       " 146,\n",
       " 190,\n",
       " 120,\n",
       " 145,\n",
       " 171,\n",
       " 103,\n",
       " 143,\n",
       " 116,\n",
       " 158,\n",
       " 139,\n",
       " 129,\n",
       " 120,\n",
       " 148,\n",
       " 127,\n",
       " 153,\n",
       " 187,\n",
       " 153,\n",
       " 176,\n",
       " 125,\n",
       " 125,\n",
       " 147,\n",
       " 188,\n",
       " 159,\n",
       " 123,\n",
       " 135,\n",
       " 130,\n",
       " 151,\n",
       " 131,\n",
       " 108,\n",
       " 149,\n",
       " 133,\n",
       " 169,\n",
       " 138,\n",
       " 173,\n",
       " 139,\n",
       " 142,\n",
       " 183,\n",
       " 170,\n",
       " 173,\n",
       " 144,\n",
       " 191,\n",
       " 149,\n",
       " 127,\n",
       " 135,\n",
       " 150,\n",
       " 181,\n",
       " 135,\n",
       " 141,\n",
       " 151,\n",
       " 104,\n",
       " 157,\n",
       " 121,\n",
       " 124,\n",
       " 109,\n",
       " 132,\n",
       " 131,\n",
       " 166,\n",
       " 188,\n",
       " 148,\n",
       " 127,\n",
       " 130,\n",
       " 125,\n",
       " 126,\n",
       " 135,\n",
       " 138,\n",
       " 156,\n",
       " 148,\n",
       " 141,\n",
       " 140,\n",
       " 127,\n",
       " 132,\n",
       " 118,\n",
       " 164,\n",
       " 158,\n",
       " 161,\n",
       " 187,\n",
       " 187,\n",
       " 161,\n",
       " 140,\n",
       " 159,\n",
       " 159,\n",
       " 141,\n",
       " 131,\n",
       " 144,\n",
       " 201,\n",
       " 194,\n",
       " 180,\n",
       " 116,\n",
       " 111,\n",
       " 122,\n",
       " 130,\n",
       " 138,\n",
       " 136,\n",
       " 137,\n",
       " 109,\n",
       " 187,\n",
       " 158,\n",
       " 136,\n",
       " 135,\n",
       " 108,\n",
       " 155,\n",
       " 127,\n",
       " 114,\n",
       " 115,\n",
       " 130,\n",
       " 154,\n",
       " 146,\n",
       " 156,\n",
       " 182,\n",
       " 214,\n",
       " 161,\n",
       " 174,\n",
       " 177,\n",
       " 125,\n",
       " 144,\n",
       " 148,\n",
       " 200,\n",
       " 222,\n",
       " 179,\n",
       " 104,\n",
       " 156,\n",
       " 163,\n",
       " 118,\n",
       " 167,\n",
       " 102,\n",
       " 140,\n",
       " 127,\n",
       " 188,\n",
       " 158,\n",
       " 113,\n",
       " ...]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep_indices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "811ae96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4241"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sep_indices_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6df4dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tokens_indices_list = [x - 2 for x in sep_indices_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1af6dd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[124,\n",
       " 149,\n",
       " 148,\n",
       " 174,\n",
       " 223,\n",
       " 153,\n",
       " 104,\n",
       " 133,\n",
       " 155,\n",
       " 291,\n",
       " 117,\n",
       " 143,\n",
       " 157,\n",
       " 146,\n",
       " 116,\n",
       " 191,\n",
       " 142,\n",
       " 127,\n",
       " 152,\n",
       " 122,\n",
       " 132,\n",
       " 179,\n",
       " 145,\n",
       " 138,\n",
       " 165,\n",
       " 146,\n",
       " 108,\n",
       " 143,\n",
       " 182,\n",
       " 154,\n",
       " 134,\n",
       " 122,\n",
       " 211,\n",
       " 144,\n",
       " 131,\n",
       " 128,\n",
       " 134,\n",
       " 224,\n",
       " 210,\n",
       " 164,\n",
       " 156,\n",
       " 139,\n",
       " 122,\n",
       " 127,\n",
       " 160,\n",
       " 130,\n",
       " 135,\n",
       " 147,\n",
       " 183,\n",
       " 173,\n",
       " 151,\n",
       " 173,\n",
       " 146,\n",
       " 173,\n",
       " 168,\n",
       " 107,\n",
       " 124,\n",
       " 110,\n",
       " 113,\n",
       " 95,\n",
       " 114,\n",
       " 136,\n",
       " 158,\n",
       " 112,\n",
       " 134,\n",
       " 103,\n",
       " 127,\n",
       " 101,\n",
       " 131,\n",
       " 134,\n",
       " 159,\n",
       " 105,\n",
       " 129,\n",
       " 143,\n",
       " 141,\n",
       " 131,\n",
       " 180,\n",
       " 115,\n",
       " 142,\n",
       " 154,\n",
       " 155,\n",
       " 136,\n",
       " 146,\n",
       " 118,\n",
       " 129,\n",
       " 108,\n",
       " 116,\n",
       " 160,\n",
       " 166,\n",
       " 120,\n",
       " 102,\n",
       " 119,\n",
       " 133,\n",
       " 163,\n",
       " 133,\n",
       " 121,\n",
       " 105,\n",
       " 118,\n",
       " 129,\n",
       " 99,\n",
       " 133,\n",
       " 234,\n",
       " 218,\n",
       " 105,\n",
       " 123,\n",
       " 149,\n",
       " 148,\n",
       " 147,\n",
       " 173,\n",
       " 122,\n",
       " 126,\n",
       " 119,\n",
       " 122,\n",
       " 105,\n",
       " 145,\n",
       " 104,\n",
       " 98,\n",
       " 189,\n",
       " 136,\n",
       " 157,\n",
       " 133,\n",
       " 135,\n",
       " 137,\n",
       " 131,\n",
       " 153,\n",
       " 156,\n",
       " 142,\n",
       " 130,\n",
       " 152,\n",
       " 108,\n",
       " 152,\n",
       " 119,\n",
       " 122,\n",
       " 158,\n",
       " 107,\n",
       " 101,\n",
       " 108,\n",
       " 150,\n",
       " 146,\n",
       " 168,\n",
       " 149,\n",
       " 154,\n",
       " 153,\n",
       " 119,\n",
       " 199,\n",
       " 140,\n",
       " 107,\n",
       " 148,\n",
       " 148,\n",
       " 109,\n",
       " 180,\n",
       " 139,\n",
       " 148,\n",
       " 129,\n",
       " 131,\n",
       " 177,\n",
       " 130,\n",
       " 141,\n",
       " 192,\n",
       " 112,\n",
       " 122,\n",
       " 133,\n",
       " 212,\n",
       " 127,\n",
       " 150,\n",
       " 121,\n",
       " 103,\n",
       " 140,\n",
       " 147,\n",
       " 166,\n",
       " 128,\n",
       " 116,\n",
       " 163,\n",
       " 114,\n",
       " 124,\n",
       " 105,\n",
       " 184,\n",
       " 153,\n",
       " 164,\n",
       " 115,\n",
       " 129,\n",
       " 118,\n",
       " 112,\n",
       " 104,\n",
       " 107,\n",
       " 107,\n",
       " 130,\n",
       " 119,\n",
       " 121,\n",
       " 124,\n",
       " 104,\n",
       " 108,\n",
       " 94,\n",
       " 133,\n",
       " 97,\n",
       " 128,\n",
       " 135,\n",
       " 139,\n",
       " 145,\n",
       " 213,\n",
       " 123,\n",
       " 162,\n",
       " 136,\n",
       " 123,\n",
       " 133,\n",
       " 113,\n",
       " 126,\n",
       " 146,\n",
       " 200,\n",
       " 123,\n",
       " 161,\n",
       " 132,\n",
       " 133,\n",
       " 155,\n",
       " 171,\n",
       " 170,\n",
       " 135,\n",
       " 127,\n",
       " 167,\n",
       " 135,\n",
       " 166,\n",
       " 104,\n",
       " 130,\n",
       " 165,\n",
       " 199,\n",
       " 140,\n",
       " 178,\n",
       " 190,\n",
       " 142,\n",
       " 143,\n",
       " 190,\n",
       " 113,\n",
       " 147,\n",
       " 149,\n",
       " 165,\n",
       " 121,\n",
       " 160,\n",
       " 135,\n",
       " 122,\n",
       " 159,\n",
       " 162,\n",
       " 145,\n",
       " 105,\n",
       " 186,\n",
       " 123,\n",
       " 90,\n",
       " 133,\n",
       " 128,\n",
       " 164,\n",
       " 129,\n",
       " 134,\n",
       " 110,\n",
       " 172,\n",
       " 139,\n",
       " 160,\n",
       " 143,\n",
       " 175,\n",
       " 124,\n",
       " 143,\n",
       " 118,\n",
       " 149,\n",
       " 120,\n",
       " 135,\n",
       " 152,\n",
       " 122,\n",
       " 172,\n",
       " 184,\n",
       " 88,\n",
       " 138,\n",
       " 130,\n",
       " 143,\n",
       " 174,\n",
       " 135,\n",
       " 122,\n",
       " 184,\n",
       " 93,\n",
       " 150,\n",
       " 110,\n",
       " 143,\n",
       " 115,\n",
       " 111,\n",
       " 161,\n",
       " 167,\n",
       " 112,\n",
       " 176,\n",
       " 158,\n",
       " 98,\n",
       " 172,\n",
       " 189,\n",
       " 120,\n",
       " 151,\n",
       " 132,\n",
       " 130,\n",
       " 95,\n",
       " 138,\n",
       " 138,\n",
       " 147,\n",
       " 137,\n",
       " 142,\n",
       " 150,\n",
       " 129,\n",
       " 154,\n",
       " 132,\n",
       " 122,\n",
       " 152,\n",
       " 131,\n",
       " 155,\n",
       " 133,\n",
       " 126,\n",
       " 154,\n",
       " 120,\n",
       " 134,\n",
       " 159,\n",
       " 141,\n",
       " 158,\n",
       " 118,\n",
       " 111,\n",
       " 127,\n",
       " 185,\n",
       " 152,\n",
       " 132,\n",
       " 132,\n",
       " 178,\n",
       " 176,\n",
       " 115,\n",
       " 177,\n",
       " 171,\n",
       " 185,\n",
       " 120,\n",
       " 136,\n",
       " 129,\n",
       " 178,\n",
       " 134,\n",
       " 142,\n",
       " 115,\n",
       " 135,\n",
       " 144,\n",
       " 150,\n",
       " 138,\n",
       " 141,\n",
       " 131,\n",
       " 113,\n",
       " 179,\n",
       " 121,\n",
       " 124,\n",
       " 139,\n",
       " 118,\n",
       " 149,\n",
       " 142,\n",
       " 194,\n",
       " 128,\n",
       " 148,\n",
       " 134,\n",
       " 145,\n",
       " 198,\n",
       " 149,\n",
       " 149,\n",
       " 158,\n",
       " 168,\n",
       " 151,\n",
       " 186,\n",
       " 135,\n",
       " 137,\n",
       " 122,\n",
       " 181,\n",
       " 167,\n",
       " 126,\n",
       " 117,\n",
       " 97,\n",
       " 127,\n",
       " 131,\n",
       " 142,\n",
       " 133,\n",
       " 131,\n",
       " 107,\n",
       " 117,\n",
       " 167,\n",
       " 119,\n",
       " 119,\n",
       " 137,\n",
       " 111,\n",
       " 115,\n",
       " 143,\n",
       " 141,\n",
       " 163,\n",
       " 168,\n",
       " 140,\n",
       " 118,\n",
       " 153,\n",
       " 130,\n",
       " 107,\n",
       " 112,\n",
       " 121,\n",
       " 120,\n",
       " 137,\n",
       " 153,\n",
       " 103,\n",
       " 159,\n",
       " 143,\n",
       " 145,\n",
       " 105,\n",
       " 156,\n",
       " 143,\n",
       " 139,\n",
       " 125,\n",
       " 132,\n",
       " 109,\n",
       " 137,\n",
       " 133,\n",
       " 139,\n",
       " 105,\n",
       " 100,\n",
       " 111,\n",
       " 108,\n",
       " 136,\n",
       " 153,\n",
       " 107,\n",
       " 121,\n",
       " 113,\n",
       " 127,\n",
       " 128,\n",
       " 159,\n",
       " 149,\n",
       " 144,\n",
       " 128,\n",
       " 117,\n",
       " 140,\n",
       " 111,\n",
       " 153,\n",
       " 144,\n",
       " 145,\n",
       " 182,\n",
       " 156,\n",
       " 121,\n",
       " 120,\n",
       " 153,\n",
       " 179,\n",
       " 163,\n",
       " 148,\n",
       " 149,\n",
       " 109,\n",
       " 124,\n",
       " 106,\n",
       " 128,\n",
       " 125,\n",
       " 130,\n",
       " 109,\n",
       " 155,\n",
       " 137,\n",
       " 109,\n",
       " 168,\n",
       " 139,\n",
       " 128,\n",
       " 129,\n",
       " 155,\n",
       " 130,\n",
       " 144,\n",
       " 137,\n",
       " 132,\n",
       " 137,\n",
       " 138,\n",
       " 173,\n",
       " 180,\n",
       " 109,\n",
       " 129,\n",
       " 146,\n",
       " 160,\n",
       " 141,\n",
       " 147,\n",
       " 145,\n",
       " 135,\n",
       " 124,\n",
       " 217,\n",
       " 249,\n",
       " 162,\n",
       " 191,\n",
       " 193,\n",
       " 177,\n",
       " 166,\n",
       " 135,\n",
       " 128,\n",
       " 127,\n",
       " 152,\n",
       " 132,\n",
       " 132,\n",
       " 135,\n",
       " 107,\n",
       " 140,\n",
       " 118,\n",
       " 140,\n",
       " 164,\n",
       " 151,\n",
       " 142,\n",
       " 149,\n",
       " 149,\n",
       " 143,\n",
       " 175,\n",
       " 112,\n",
       " 135,\n",
       " 149,\n",
       " 119,\n",
       " 144,\n",
       " 161,\n",
       " 138,\n",
       " 123,\n",
       " 154,\n",
       " 196,\n",
       " 132,\n",
       " 223,\n",
       " 120,\n",
       " 132,\n",
       " 151,\n",
       " 113,\n",
       " 197,\n",
       " 135,\n",
       " 115,\n",
       " 156,\n",
       " 136,\n",
       " 138,\n",
       " 180,\n",
       " 141,\n",
       " 151,\n",
       " 124,\n",
       " 142,\n",
       " 135,\n",
       " 153,\n",
       " 158,\n",
       " 142,\n",
       " 124,\n",
       " 128,\n",
       " 187,\n",
       " 171,\n",
       " 130,\n",
       " 197,\n",
       " 137,\n",
       " 151,\n",
       " 157,\n",
       " 157,\n",
       " 128,\n",
       " 165,\n",
       " 159,\n",
       " 146,\n",
       " 180,\n",
       " 114,\n",
       " 143,\n",
       " 183,\n",
       " 130,\n",
       " 107,\n",
       " 117,\n",
       " 120,\n",
       " 142,\n",
       " 169,\n",
       " 190,\n",
       " 123,\n",
       " 107,\n",
       " 124,\n",
       " 106,\n",
       " 159,\n",
       " 117,\n",
       " 131,\n",
       " 114,\n",
       " 100,\n",
       " 133,\n",
       " 138,\n",
       " 127,\n",
       " 99,\n",
       " 106,\n",
       " 142,\n",
       " 99,\n",
       " 112,\n",
       " 98,\n",
       " 177,\n",
       " 112,\n",
       " 132,\n",
       " 111,\n",
       " 112,\n",
       " 131,\n",
       " 134,\n",
       " 112,\n",
       " 169,\n",
       " 143,\n",
       " 165,\n",
       " 165,\n",
       " 192,\n",
       " 108,\n",
       " 116,\n",
       " 140,\n",
       " 125,\n",
       " 152,\n",
       " 118,\n",
       " 169,\n",
       " 111,\n",
       " 113,\n",
       " 155,\n",
       " 153,\n",
       " 184,\n",
       " 154,\n",
       " 123,\n",
       " 119,\n",
       " 121,\n",
       " 196,\n",
       " 114,\n",
       " 178,\n",
       " 112,\n",
       " 158,\n",
       " 133,\n",
       " 176,\n",
       " 131,\n",
       " 143,\n",
       " 140,\n",
       " 171,\n",
       " 119,\n",
       " 117,\n",
       " 157,\n",
       " 131,\n",
       " 108,\n",
       " 120,\n",
       " 115,\n",
       " 107,\n",
       " 165,\n",
       " 127,\n",
       " 124,\n",
       " 104,\n",
       " 120,\n",
       " 140,\n",
       " 124,\n",
       " 97,\n",
       " 106,\n",
       " 118,\n",
       " 177,\n",
       " 165,\n",
       " 135,\n",
       " 123,\n",
       " 151,\n",
       " 98,\n",
       " 155,\n",
       " 127,\n",
       " 110,\n",
       " 153,\n",
       " 147,\n",
       " 145,\n",
       " 119,\n",
       " 101,\n",
       " 116,\n",
       " 112,\n",
       " 97,\n",
       " 146,\n",
       " 138,\n",
       " 126,\n",
       " 124,\n",
       " 135,\n",
       " 112,\n",
       " 98,\n",
       " 125,\n",
       " 107,\n",
       " 136,\n",
       " 110,\n",
       " 102,\n",
       " 140,\n",
       " 132,\n",
       " 121,\n",
       " 107,\n",
       " 139,\n",
       " 120,\n",
       " 104,\n",
       " 159,\n",
       " 124,\n",
       " 114,\n",
       " 108,\n",
       " 117,\n",
       " 136,\n",
       " 133,\n",
       " 162,\n",
       " 101,\n",
       " 107,\n",
       " 120,\n",
       " 139,\n",
       " 139,\n",
       " 134,\n",
       " 136,\n",
       " 140,\n",
       " 141,\n",
       " 161,\n",
       " 130,\n",
       " 148,\n",
       " 117,\n",
       " 134,\n",
       " 122,\n",
       " 116,\n",
       " 176,\n",
       " 116,\n",
       " 108,\n",
       " 121,\n",
       " 131,\n",
       " 112,\n",
       " 139,\n",
       " 119,\n",
       " 116,\n",
       " 129,\n",
       " 167,\n",
       " 150,\n",
       " 119,\n",
       " 158,\n",
       " 124,\n",
       " 123,\n",
       " 157,\n",
       " 126,\n",
       " 109,\n",
       " 160,\n",
       " 115,\n",
       " 139,\n",
       " 162,\n",
       " 231,\n",
       " 181,\n",
       " 131,\n",
       " 118,\n",
       " 259,\n",
       " 129,\n",
       " 161,\n",
       " 153,\n",
       " 143,\n",
       " 147,\n",
       " 132,\n",
       " 184,\n",
       " 172,\n",
       " 139,\n",
       " 120,\n",
       " 155,\n",
       " 132,\n",
       " 191,\n",
       " 200,\n",
       " 170,\n",
       " 172,\n",
       " 129,\n",
       " 196,\n",
       " 137,\n",
       " 125,\n",
       " 170,\n",
       " 122,\n",
       " 191,\n",
       " 146,\n",
       " 171,\n",
       " 185,\n",
       " 132,\n",
       " 168,\n",
       " 192,\n",
       " 133,\n",
       " 141,\n",
       " 156,\n",
       " 180,\n",
       " 153,\n",
       " 143,\n",
       " 145,\n",
       " 119,\n",
       " 122,\n",
       " 164,\n",
       " 178,\n",
       " 147,\n",
       " 142,\n",
       " 199,\n",
       " 148,\n",
       " 136,\n",
       " 130,\n",
       " 169,\n",
       " 134,\n",
       " 133,\n",
       " 171,\n",
       " 215,\n",
       " 179,\n",
       " 112,\n",
       " 161,\n",
       " 135,\n",
       " 175,\n",
       " 254,\n",
       " 136,\n",
       " 172,\n",
       " 230,\n",
       " 153,\n",
       " 129,\n",
       " 153,\n",
       " 161,\n",
       " 161,\n",
       " 165,\n",
       " 157,\n",
       " 157,\n",
       " 136,\n",
       " 146,\n",
       " 150,\n",
       " 163,\n",
       " 188,\n",
       " 111,\n",
       " 141,\n",
       " 166,\n",
       " 165,\n",
       " 130,\n",
       " 169,\n",
       " 111,\n",
       " 197,\n",
       " 157,\n",
       " 142,\n",
       " 100,\n",
       " 132,\n",
       " 154,\n",
       " 180,\n",
       " 120,\n",
       " 123,\n",
       " 137,\n",
       " 125,\n",
       " 135,\n",
       " 124,\n",
       " 157,\n",
       " 149,\n",
       " 138,\n",
       " 155,\n",
       " 107,\n",
       " 126,\n",
       " 146,\n",
       " 108,\n",
       " 135,\n",
       " 172,\n",
       " 170,\n",
       " 162,\n",
       " 160,\n",
       " 126,\n",
       " 190,\n",
       " 166,\n",
       " 179,\n",
       " 224,\n",
       " 131,\n",
       " 168,\n",
       " 165,\n",
       " 155,\n",
       " 164,\n",
       " 141,\n",
       " 171,\n",
       " 187,\n",
       " 182,\n",
       " 221,\n",
       " 112,\n",
       " 116,\n",
       " 151,\n",
       " 135,\n",
       " 127,\n",
       " 138,\n",
       " 118,\n",
       " 204,\n",
       " 131,\n",
       " 94,\n",
       " 170,\n",
       " 193,\n",
       " 132,\n",
       " 117,\n",
       " 202,\n",
       " 120,\n",
       " 106,\n",
       " 137,\n",
       " 122,\n",
       " 131,\n",
       " 139,\n",
       " 128,\n",
       " 107,\n",
       " 198,\n",
       " 118,\n",
       " 114,\n",
       " 118,\n",
       " 145,\n",
       " 149,\n",
       " 145,\n",
       " 133,\n",
       " 134,\n",
       " 144,\n",
       " 188,\n",
       " 118,\n",
       " 143,\n",
       " 169,\n",
       " 101,\n",
       " 141,\n",
       " 114,\n",
       " 156,\n",
       " 137,\n",
       " 127,\n",
       " 118,\n",
       " 146,\n",
       " 125,\n",
       " 151,\n",
       " 185,\n",
       " 151,\n",
       " 174,\n",
       " 123,\n",
       " 123,\n",
       " 145,\n",
       " 186,\n",
       " 157,\n",
       " 121,\n",
       " 133,\n",
       " 128,\n",
       " 149,\n",
       " 129,\n",
       " 106,\n",
       " 147,\n",
       " 131,\n",
       " 167,\n",
       " 136,\n",
       " 171,\n",
       " 137,\n",
       " 140,\n",
       " 181,\n",
       " 168,\n",
       " 171,\n",
       " 142,\n",
       " 189,\n",
       " 147,\n",
       " 125,\n",
       " 133,\n",
       " 148,\n",
       " 179,\n",
       " 133,\n",
       " 139,\n",
       " 149,\n",
       " 102,\n",
       " 155,\n",
       " 119,\n",
       " 122,\n",
       " 107,\n",
       " 130,\n",
       " 129,\n",
       " 164,\n",
       " 186,\n",
       " 146,\n",
       " 125,\n",
       " 128,\n",
       " 123,\n",
       " 124,\n",
       " 133,\n",
       " 136,\n",
       " 154,\n",
       " 146,\n",
       " 139,\n",
       " 138,\n",
       " 125,\n",
       " 130,\n",
       " 116,\n",
       " 162,\n",
       " 156,\n",
       " 159,\n",
       " 185,\n",
       " 185,\n",
       " 159,\n",
       " 138,\n",
       " 157,\n",
       " 157,\n",
       " 139,\n",
       " 129,\n",
       " 142,\n",
       " 199,\n",
       " 192,\n",
       " 178,\n",
       " 114,\n",
       " 109,\n",
       " 120,\n",
       " 128,\n",
       " 136,\n",
       " 134,\n",
       " 135,\n",
       " 107,\n",
       " 185,\n",
       " 156,\n",
       " 134,\n",
       " 133,\n",
       " 106,\n",
       " 153,\n",
       " 125,\n",
       " 112,\n",
       " 113,\n",
       " 128,\n",
       " 152,\n",
       " 144,\n",
       " 154,\n",
       " 180,\n",
       " 212,\n",
       " 159,\n",
       " 172,\n",
       " 175,\n",
       " 123,\n",
       " 142,\n",
       " 146,\n",
       " 198,\n",
       " 220,\n",
       " 177,\n",
       " 102,\n",
       " 154,\n",
       " 161,\n",
       " 116,\n",
       " 165,\n",
       " 100,\n",
       " 138,\n",
       " 125,\n",
       " 186,\n",
       " 156,\n",
       " 111,\n",
       " ...]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_tokens_indices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c3e99c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs_pe['input_ids'][0][143].item() # correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c8cd6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get a list of input ids at all these indics: they should be either claim = 4366, premise = 18458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "64d2f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index_minus_2 = []\n",
    "\n",
    "for idx, val in enumerate(class_tokens_indices_list):\n",
    "    at_idx_minus_2 = inputs_train['input_ids'][idx][val].item()\n",
    "    list_index_minus_2.append(at_idx_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "93ead923",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4366, 11032, 18458}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list_index_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1d67ffa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s t a n c e'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(11032)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f239496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ab44933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make the class token indices 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ec06ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, val in enumerate(class_tokens_indices_list):\n",
    "    inputs_train['input_ids'][idx][val] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6dcde695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check if they are 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9c6bde54",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsontroi_check_list = []\n",
    "\n",
    "for idx, val in enumerate(class_tokens_indices_list):\n",
    "    at_idx_minus_2 = inputs_train['input_ids'][idx][val].item()\n",
    "    unsontroi_check_list.append(at_idx_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f260bb91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{103}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(unsontroi_check_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be662ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "876773ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "01c569d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PeDataset(inputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e38041c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=)\n",
    "# maybe we don't need this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316ede1",
   "metadata": {},
   "source": [
    "### prepare val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a9454780",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_eval = tokenizer(prompted_texts_val, return_tensors='pt', max_length=512, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "98a6ecf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ac732918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([472, 512])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_eval['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "906abbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training we will need labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d7f03cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_eval['labels'] = inputs_eval.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eeb33285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0]])}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e548ea75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([472, 512])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_eval['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "43ed292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find where the last 102 is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b22e5b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inputs_eval['input_ids'][0] == 102).nonzero(as_tuple=True)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d1ea71cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c l a i m'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(4366)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f040c1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p r e m i s e'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(18458)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "689011c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# claim = 4366, premise = 18458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "73d7f108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inputs_eval['input_ids'][1] == 102).nonzero(as_tuple=True)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9fb8957a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1010)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_eval['input_ids'][1][123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9ed2aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that all at [len-2] indices are either claim or premise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fbf67668",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_indices_list = []\n",
    "\n",
    "for i in range(len(prompted_texts_val)):\n",
    "    sep_idx = (inputs_eval['input_ids'][i] == 102).nonzero(as_tuple=True)[0].item()\n",
    "    sep_indices_list.append(sep_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "28a7eeaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[144,\n",
       " 163,\n",
       " 114,\n",
       " 154,\n",
       " 105,\n",
       " 129,\n",
       " 136,\n",
       " 152,\n",
       " 127,\n",
       " 117,\n",
       " 144,\n",
       " 121,\n",
       " 116,\n",
       " 120,\n",
       " 153,\n",
       " 131,\n",
       " 133,\n",
       " 158,\n",
       " 157,\n",
       " 115,\n",
       " 195,\n",
       " 161,\n",
       " 121,\n",
       " 185,\n",
       " 135,\n",
       " 140,\n",
       " 134,\n",
       " 122,\n",
       " 184,\n",
       " 118,\n",
       " 185,\n",
       " 146,\n",
       " 110,\n",
       " 122,\n",
       " 137,\n",
       " 130,\n",
       " 163,\n",
       " 166,\n",
       " 146,\n",
       " 123,\n",
       " 176,\n",
       " 139,\n",
       " 147,\n",
       " 121,\n",
       " 114,\n",
       " 129,\n",
       " 165,\n",
       " 117,\n",
       " 191,\n",
       " 145,\n",
       " 136,\n",
       " 113,\n",
       " 135,\n",
       " 125,\n",
       " 117,\n",
       " 185,\n",
       " 177,\n",
       " 140,\n",
       " 190,\n",
       " 189,\n",
       " 126,\n",
       " 156,\n",
       " 102,\n",
       " 127,\n",
       " 112,\n",
       " 159,\n",
       " 195,\n",
       " 130,\n",
       " 153,\n",
       " 147,\n",
       " 103,\n",
       " 148,\n",
       " 200,\n",
       " 128,\n",
       " 178,\n",
       " 169,\n",
       " 161,\n",
       " 148,\n",
       " 135,\n",
       " 128,\n",
       " 142,\n",
       " 185,\n",
       " 138,\n",
       " 129,\n",
       " 130,\n",
       " 148,\n",
       " 126,\n",
       " 152,\n",
       " 119,\n",
       " 181,\n",
       " 213,\n",
       " 113,\n",
       " 127,\n",
       " 183,\n",
       " 130,\n",
       " 157,\n",
       " 164,\n",
       " 129,\n",
       " 166,\n",
       " 128,\n",
       " 113,\n",
       " 164,\n",
       " 188,\n",
       " 187,\n",
       " 105,\n",
       " 146,\n",
       " 130,\n",
       " 167,\n",
       " 198,\n",
       " 147,\n",
       " 122,\n",
       " 128,\n",
       " 134,\n",
       " 139,\n",
       " 150,\n",
       " 150,\n",
       " 166,\n",
       " 153,\n",
       " 133,\n",
       " 119,\n",
       " 127,\n",
       " 122,\n",
       " 129,\n",
       " 109,\n",
       " 105,\n",
       " 146,\n",
       " 161,\n",
       " 237,\n",
       " 115,\n",
       " 174,\n",
       " 205,\n",
       " 154,\n",
       " 137,\n",
       " 151,\n",
       " 111,\n",
       " 114,\n",
       " 136,\n",
       " 114,\n",
       " 132,\n",
       " 125,\n",
       " 181,\n",
       " 195,\n",
       " 141,\n",
       " 114,\n",
       " 111,\n",
       " 162,\n",
       " 117,\n",
       " 164,\n",
       " 191,\n",
       " 145,\n",
       " 131,\n",
       " 129,\n",
       " 164,\n",
       " 112,\n",
       " 146,\n",
       " 129,\n",
       " 132,\n",
       " 161,\n",
       " 180,\n",
       " 194,\n",
       " 122,\n",
       " 204,\n",
       " 176,\n",
       " 130,\n",
       " 140,\n",
       " 155,\n",
       " 117,\n",
       " 174,\n",
       " 126,\n",
       " 137,\n",
       " 124,\n",
       " 115,\n",
       " 155,\n",
       " 146,\n",
       " 118,\n",
       " 124,\n",
       " 106,\n",
       " 151,\n",
       " 168,\n",
       " 139,\n",
       " 137,\n",
       " 131,\n",
       " 119,\n",
       " 130,\n",
       " 166,\n",
       " 152,\n",
       " 116,\n",
       " 168,\n",
       " 169,\n",
       " 152,\n",
       " 158,\n",
       " 212,\n",
       " 187,\n",
       " 139,\n",
       " 103,\n",
       " 130,\n",
       " 110,\n",
       " 121,\n",
       " 129,\n",
       " 138,\n",
       " 151,\n",
       " 123,\n",
       " 184,\n",
       " 137,\n",
       " 131,\n",
       " 149,\n",
       " 122,\n",
       " 144,\n",
       " 207,\n",
       " 151,\n",
       " 174,\n",
       " 104,\n",
       " 126,\n",
       " 143,\n",
       " 133,\n",
       " 127,\n",
       " 149,\n",
       " 109,\n",
       " 128,\n",
       " 161,\n",
       " 162,\n",
       " 144,\n",
       " 152,\n",
       " 121,\n",
       " 190,\n",
       " 147,\n",
       " 142,\n",
       " 124,\n",
       " 135,\n",
       " 170,\n",
       " 117,\n",
       " 150,\n",
       " 121,\n",
       " 129,\n",
       " 176,\n",
       " 161,\n",
       " 124,\n",
       " 166,\n",
       " 136,\n",
       " 129,\n",
       " 114,\n",
       " 157,\n",
       " 123,\n",
       " 160,\n",
       " 133,\n",
       " 141,\n",
       " 143,\n",
       " 117,\n",
       " 139,\n",
       " 125,\n",
       " 115,\n",
       " 156,\n",
       " 139,\n",
       " 140,\n",
       " 153,\n",
       " 127,\n",
       " 148,\n",
       " 111,\n",
       " 124,\n",
       " 183,\n",
       " 169,\n",
       " 147,\n",
       " 158,\n",
       " 166,\n",
       " 163,\n",
       " 232,\n",
       " 134,\n",
       " 129,\n",
       " 141,\n",
       " 137,\n",
       " 121,\n",
       " 176,\n",
       " 123,\n",
       " 130,\n",
       " 160,\n",
       " 138,\n",
       " 121,\n",
       " 116,\n",
       " 141,\n",
       " 150,\n",
       " 128,\n",
       " 132,\n",
       " 120,\n",
       " 126,\n",
       " 170,\n",
       " 118,\n",
       " 119,\n",
       " 130,\n",
       " 129,\n",
       " 131,\n",
       " 131,\n",
       " 128,\n",
       " 166,\n",
       " 119,\n",
       " 175,\n",
       " 127,\n",
       " 115,\n",
       " 161,\n",
       " 160,\n",
       " 147,\n",
       " 117,\n",
       " 170,\n",
       " 127,\n",
       " 146,\n",
       " 122,\n",
       " 140,\n",
       " 131,\n",
       " 131,\n",
       " 126,\n",
       " 189,\n",
       " 114,\n",
       " 149,\n",
       " 148,\n",
       " 122,\n",
       " 165,\n",
       " 100,\n",
       " 143,\n",
       " 179,\n",
       " 125,\n",
       " 136,\n",
       " 119,\n",
       " 111,\n",
       " 161,\n",
       " 109,\n",
       " 147,\n",
       " 142,\n",
       " 252,\n",
       " 157,\n",
       " 136,\n",
       " 115,\n",
       " 101,\n",
       " 215,\n",
       " 132,\n",
       " 139,\n",
       " 115,\n",
       " 136,\n",
       " 140,\n",
       " 153,\n",
       " 93,\n",
       " 217,\n",
       " 109,\n",
       " 135,\n",
       " 125,\n",
       " 138,\n",
       " 110,\n",
       " 167,\n",
       " 126,\n",
       " 121,\n",
       " 147,\n",
       " 193,\n",
       " 180,\n",
       " 121,\n",
       " 195,\n",
       " 148,\n",
       " 117,\n",
       " 188,\n",
       " 127,\n",
       " 162,\n",
       " 163,\n",
       " 125,\n",
       " 120,\n",
       " 134,\n",
       " 208,\n",
       " 170,\n",
       " 101,\n",
       " 118,\n",
       " 144,\n",
       " 185,\n",
       " 141,\n",
       " 114,\n",
       " 143,\n",
       " 122,\n",
       " 135,\n",
       " 149,\n",
       " 179,\n",
       " 150,\n",
       " 105,\n",
       " 112,\n",
       " 132,\n",
       " 134,\n",
       " 126,\n",
       " 130,\n",
       " 115,\n",
       " 132,\n",
       " 156,\n",
       " 146,\n",
       " 177,\n",
       " 129,\n",
       " 108,\n",
       " 119,\n",
       " 243,\n",
       " 150,\n",
       " 99,\n",
       " 162,\n",
       " 210,\n",
       " 138,\n",
       " 116,\n",
       " 177,\n",
       " 190,\n",
       " 150,\n",
       " 155,\n",
       " 137,\n",
       " 186,\n",
       " 132,\n",
       " 131,\n",
       " 128,\n",
       " 133,\n",
       " 150,\n",
       " 131,\n",
       " 142,\n",
       " 192,\n",
       " 143,\n",
       " 122,\n",
       " 128,\n",
       " 150,\n",
       " 117,\n",
       " 109,\n",
       " 152,\n",
       " 154,\n",
       " 191,\n",
       " 233,\n",
       " 129,\n",
       " 129,\n",
       " 167,\n",
       " 134,\n",
       " 153,\n",
       " 168,\n",
       " 103,\n",
       " 106,\n",
       " 154,\n",
       " 259,\n",
       " 151,\n",
       " 179,\n",
       " 203,\n",
       " 159,\n",
       " 134,\n",
       " 134,\n",
       " 174,\n",
       " 115,\n",
       " 141,\n",
       " 180,\n",
       " 167,\n",
       " 135,\n",
       " 116,\n",
       " 131,\n",
       " 131,\n",
       " 120,\n",
       " 133,\n",
       " 130,\n",
       " 175,\n",
       " 145,\n",
       " 128,\n",
       " 103,\n",
       " 137,\n",
       " 210,\n",
       " 141,\n",
       " 144,\n",
       " 116,\n",
       " 160,\n",
       " 147,\n",
       " 180,\n",
       " 151,\n",
       " 160,\n",
       " 108,\n",
       " 140,\n",
       " 164,\n",
       " 168,\n",
       " 185,\n",
       " 136,\n",
       " 156,\n",
       " 117,\n",
       " 111]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep_indices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6503dda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sep_indices_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4e54d654",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tokens_indices_list = [x - 2 for x in sep_indices_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5a436e87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[142,\n",
       " 161,\n",
       " 112,\n",
       " 152,\n",
       " 103,\n",
       " 127,\n",
       " 134,\n",
       " 150,\n",
       " 125,\n",
       " 115,\n",
       " 142,\n",
       " 119,\n",
       " 114,\n",
       " 118,\n",
       " 151,\n",
       " 129,\n",
       " 131,\n",
       " 156,\n",
       " 155,\n",
       " 113,\n",
       " 193,\n",
       " 159,\n",
       " 119,\n",
       " 183,\n",
       " 133,\n",
       " 138,\n",
       " 132,\n",
       " 120,\n",
       " 182,\n",
       " 116,\n",
       " 183,\n",
       " 144,\n",
       " 108,\n",
       " 120,\n",
       " 135,\n",
       " 128,\n",
       " 161,\n",
       " 164,\n",
       " 144,\n",
       " 121,\n",
       " 174,\n",
       " 137,\n",
       " 145,\n",
       " 119,\n",
       " 112,\n",
       " 127,\n",
       " 163,\n",
       " 115,\n",
       " 189,\n",
       " 143,\n",
       " 134,\n",
       " 111,\n",
       " 133,\n",
       " 123,\n",
       " 115,\n",
       " 183,\n",
       " 175,\n",
       " 138,\n",
       " 188,\n",
       " 187,\n",
       " 124,\n",
       " 154,\n",
       " 100,\n",
       " 125,\n",
       " 110,\n",
       " 157,\n",
       " 193,\n",
       " 128,\n",
       " 151,\n",
       " 145,\n",
       " 101,\n",
       " 146,\n",
       " 198,\n",
       " 126,\n",
       " 176,\n",
       " 167,\n",
       " 159,\n",
       " 146,\n",
       " 133,\n",
       " 126,\n",
       " 140,\n",
       " 183,\n",
       " 136,\n",
       " 127,\n",
       " 128,\n",
       " 146,\n",
       " 124,\n",
       " 150,\n",
       " 117,\n",
       " 179,\n",
       " 211,\n",
       " 111,\n",
       " 125,\n",
       " 181,\n",
       " 128,\n",
       " 155,\n",
       " 162,\n",
       " 127,\n",
       " 164,\n",
       " 126,\n",
       " 111,\n",
       " 162,\n",
       " 186,\n",
       " 185,\n",
       " 103,\n",
       " 144,\n",
       " 128,\n",
       " 165,\n",
       " 196,\n",
       " 145,\n",
       " 120,\n",
       " 126,\n",
       " 132,\n",
       " 137,\n",
       " 148,\n",
       " 148,\n",
       " 164,\n",
       " 151,\n",
       " 131,\n",
       " 117,\n",
       " 125,\n",
       " 120,\n",
       " 127,\n",
       " 107,\n",
       " 103,\n",
       " 144,\n",
       " 159,\n",
       " 235,\n",
       " 113,\n",
       " 172,\n",
       " 203,\n",
       " 152,\n",
       " 135,\n",
       " 149,\n",
       " 109,\n",
       " 112,\n",
       " 134,\n",
       " 112,\n",
       " 130,\n",
       " 123,\n",
       " 179,\n",
       " 193,\n",
       " 139,\n",
       " 112,\n",
       " 109,\n",
       " 160,\n",
       " 115,\n",
       " 162,\n",
       " 189,\n",
       " 143,\n",
       " 129,\n",
       " 127,\n",
       " 162,\n",
       " 110,\n",
       " 144,\n",
       " 127,\n",
       " 130,\n",
       " 159,\n",
       " 178,\n",
       " 192,\n",
       " 120,\n",
       " 202,\n",
       " 174,\n",
       " 128,\n",
       " 138,\n",
       " 153,\n",
       " 115,\n",
       " 172,\n",
       " 124,\n",
       " 135,\n",
       " 122,\n",
       " 113,\n",
       " 153,\n",
       " 144,\n",
       " 116,\n",
       " 122,\n",
       " 104,\n",
       " 149,\n",
       " 166,\n",
       " 137,\n",
       " 135,\n",
       " 129,\n",
       " 117,\n",
       " 128,\n",
       " 164,\n",
       " 150,\n",
       " 114,\n",
       " 166,\n",
       " 167,\n",
       " 150,\n",
       " 156,\n",
       " 210,\n",
       " 185,\n",
       " 137,\n",
       " 101,\n",
       " 128,\n",
       " 108,\n",
       " 119,\n",
       " 127,\n",
       " 136,\n",
       " 149,\n",
       " 121,\n",
       " 182,\n",
       " 135,\n",
       " 129,\n",
       " 147,\n",
       " 120,\n",
       " 142,\n",
       " 205,\n",
       " 149,\n",
       " 172,\n",
       " 102,\n",
       " 124,\n",
       " 141,\n",
       " 131,\n",
       " 125,\n",
       " 147,\n",
       " 107,\n",
       " 126,\n",
       " 159,\n",
       " 160,\n",
       " 142,\n",
       " 150,\n",
       " 119,\n",
       " 188,\n",
       " 145,\n",
       " 140,\n",
       " 122,\n",
       " 133,\n",
       " 168,\n",
       " 115,\n",
       " 148,\n",
       " 119,\n",
       " 127,\n",
       " 174,\n",
       " 159,\n",
       " 122,\n",
       " 164,\n",
       " 134,\n",
       " 127,\n",
       " 112,\n",
       " 155,\n",
       " 121,\n",
       " 158,\n",
       " 131,\n",
       " 139,\n",
       " 141,\n",
       " 115,\n",
       " 137,\n",
       " 123,\n",
       " 113,\n",
       " 154,\n",
       " 137,\n",
       " 138,\n",
       " 151,\n",
       " 125,\n",
       " 146,\n",
       " 109,\n",
       " 122,\n",
       " 181,\n",
       " 167,\n",
       " 145,\n",
       " 156,\n",
       " 164,\n",
       " 161,\n",
       " 230,\n",
       " 132,\n",
       " 127,\n",
       " 139,\n",
       " 135,\n",
       " 119,\n",
       " 174,\n",
       " 121,\n",
       " 128,\n",
       " 158,\n",
       " 136,\n",
       " 119,\n",
       " 114,\n",
       " 139,\n",
       " 148,\n",
       " 126,\n",
       " 130,\n",
       " 118,\n",
       " 124,\n",
       " 168,\n",
       " 116,\n",
       " 117,\n",
       " 128,\n",
       " 127,\n",
       " 129,\n",
       " 129,\n",
       " 126,\n",
       " 164,\n",
       " 117,\n",
       " 173,\n",
       " 125,\n",
       " 113,\n",
       " 159,\n",
       " 158,\n",
       " 145,\n",
       " 115,\n",
       " 168,\n",
       " 125,\n",
       " 144,\n",
       " 120,\n",
       " 138,\n",
       " 129,\n",
       " 129,\n",
       " 124,\n",
       " 187,\n",
       " 112,\n",
       " 147,\n",
       " 146,\n",
       " 120,\n",
       " 163,\n",
       " 98,\n",
       " 141,\n",
       " 177,\n",
       " 123,\n",
       " 134,\n",
       " 117,\n",
       " 109,\n",
       " 159,\n",
       " 107,\n",
       " 145,\n",
       " 140,\n",
       " 250,\n",
       " 155,\n",
       " 134,\n",
       " 113,\n",
       " 99,\n",
       " 213,\n",
       " 130,\n",
       " 137,\n",
       " 113,\n",
       " 134,\n",
       " 138,\n",
       " 151,\n",
       " 91,\n",
       " 215,\n",
       " 107,\n",
       " 133,\n",
       " 123,\n",
       " 136,\n",
       " 108,\n",
       " 165,\n",
       " 124,\n",
       " 119,\n",
       " 145,\n",
       " 191,\n",
       " 178,\n",
       " 119,\n",
       " 193,\n",
       " 146,\n",
       " 115,\n",
       " 186,\n",
       " 125,\n",
       " 160,\n",
       " 161,\n",
       " 123,\n",
       " 118,\n",
       " 132,\n",
       " 206,\n",
       " 168,\n",
       " 99,\n",
       " 116,\n",
       " 142,\n",
       " 183,\n",
       " 139,\n",
       " 112,\n",
       " 141,\n",
       " 120,\n",
       " 133,\n",
       " 147,\n",
       " 177,\n",
       " 148,\n",
       " 103,\n",
       " 110,\n",
       " 130,\n",
       " 132,\n",
       " 124,\n",
       " 128,\n",
       " 113,\n",
       " 130,\n",
       " 154,\n",
       " 144,\n",
       " 175,\n",
       " 127,\n",
       " 106,\n",
       " 117,\n",
       " 241,\n",
       " 148,\n",
       " 97,\n",
       " 160,\n",
       " 208,\n",
       " 136,\n",
       " 114,\n",
       " 175,\n",
       " 188,\n",
       " 148,\n",
       " 153,\n",
       " 135,\n",
       " 184,\n",
       " 130,\n",
       " 129,\n",
       " 126,\n",
       " 131,\n",
       " 148,\n",
       " 129,\n",
       " 140,\n",
       " 190,\n",
       " 141,\n",
       " 120,\n",
       " 126,\n",
       " 148,\n",
       " 115,\n",
       " 107,\n",
       " 150,\n",
       " 152,\n",
       " 189,\n",
       " 231,\n",
       " 127,\n",
       " 127,\n",
       " 165,\n",
       " 132,\n",
       " 151,\n",
       " 166,\n",
       " 101,\n",
       " 104,\n",
       " 152,\n",
       " 257,\n",
       " 149,\n",
       " 177,\n",
       " 201,\n",
       " 157,\n",
       " 132,\n",
       " 132,\n",
       " 172,\n",
       " 113,\n",
       " 139,\n",
       " 178,\n",
       " 165,\n",
       " 133,\n",
       " 114,\n",
       " 129,\n",
       " 129,\n",
       " 118,\n",
       " 131,\n",
       " 128,\n",
       " 173,\n",
       " 143,\n",
       " 126,\n",
       " 101,\n",
       " 135,\n",
       " 208,\n",
       " 139,\n",
       " 142,\n",
       " 114,\n",
       " 158,\n",
       " 145,\n",
       " 178,\n",
       " 149,\n",
       " 158,\n",
       " 106,\n",
       " 138,\n",
       " 162,\n",
       " 166,\n",
       " 183,\n",
       " 134,\n",
       " 154,\n",
       " 115,\n",
       " 109]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_tokens_indices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b8b03394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs_pe['input_ids'][0][143].item() # correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d299854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get a list of input ids at all these indics: they should be either claim = 4366, premise = 18458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "97dd72f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index_minus_2 = []\n",
    "\n",
    "for idx, val in enumerate(class_tokens_indices_list):\n",
    "    at_idx_minus_2 = inputs_eval['input_ids'][idx][val].item()\n",
    "    list_index_minus_2.append(at_idx_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e5fbe4e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4366, 11032, 18458}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list_index_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f521bc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s t a n c e'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(11032)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "687b99a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d5831ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make the class token indices 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "14dd4d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, val in enumerate(class_tokens_indices_list):\n",
    "    inputs_eval['input_ids'][idx][val] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "86d4a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check if they are 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0587132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsontroi_check_list = []\n",
    "\n",
    "for idx, val in enumerate(class_tokens_indices_list):\n",
    "    at_idx_minus_2 = inputs_eval['input_ids'][idx][val].item()\n",
    "    unsontroi_check_list.append(at_idx_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6ad94811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{103}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(unsontroi_check_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7344fcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4c6ea88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PeDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, encodings):\n",
    "#         self.encodings = encodings\n",
    "#     def __getitem__(self, idx):\n",
    "#         return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "#     def __len__(self):\n",
    "#         return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e269ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = PeDataset(inputs_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787d4d35",
   "metadata": {},
   "source": [
    "### test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1ee4541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[df.split == 'TEST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ae8ece98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "aac0e24b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_nr</th>\n",
       "      <th>component_id</th>\n",
       "      <th>label_and_comp_idxs</th>\n",
       "      <th>text</th>\n",
       "      <th>label_x</th>\n",
       "      <th>label_ComponentType</th>\n",
       "      <th>relation_SupportAttack</th>\n",
       "      <th>label_RelationType</th>\n",
       "      <th>label_LinkedNotLinked</th>\n",
       "      <th>split</th>\n",
       "      <th>...</th>\n",
       "      <th>structural_fts_as_text_combined</th>\n",
       "      <th>para_ratio</th>\n",
       "      <th>first_or_last</th>\n",
       "      <th>strct_fts_w_position_in_essay</th>\n",
       "      <th>component_pos_tags</th>\n",
       "      <th>strct_fts_essay_position_pos_tags</th>\n",
       "      <th>prompted_representation_2</th>\n",
       "      <th>prompted_representation_3</th>\n",
       "      <th>prompted_rep_2_w_modif_MC</th>\n",
       "      <th>prompted_rep_2_w_modif_MC_corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>essay004</td>\n",
       "      <td>T1</td>\n",
       "      <td>MajorClaim 262 376</td>\n",
       "      <td>this industry has affected the cultural attrib...</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Linked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Part Of Speech tags: DET, NOUN, AUX, VERB, DET...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>essay004</td>\n",
       "      <td>T2</td>\n",
       "      <td>MajorClaim 1663 1758</td>\n",
       "      <td>the tourism has created threatening pressure o...</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Linked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Part Of Speech tags: DET, NOUN, AUX, VERB, VER...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>essay004</td>\n",
       "      <td>T3</td>\n",
       "      <td>Claim 179 239</td>\n",
       "      <td>the tourism bring large profit for the destina...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Attack</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Part Of Speech tags: DET, NOUN, VERB, ADJ, NOU...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>essay004</td>\n",
       "      <td>T4</td>\n",
       "      <td>Claim 953 1031</td>\n",
       "      <td>international tourism can create negative impa...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Part Of Speech tags: ADJ, NOUN, VERB, VERB, AD...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>essay004</td>\n",
       "      <td>T5</td>\n",
       "      <td>Claim 1578 1624</td>\n",
       "      <td>tourism has threatened the nature environments</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Part Of Speech tags: NOUN, AUX, VERB, DET, NOU...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>essay398</td>\n",
       "      <td>T12</td>\n",
       "      <td>Claim 1484 1589</td>\n",
       "      <td>universities should encourage more girls to ch...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Part Of Speech tags: NOUN, VERB, VERB, ADJ, NO...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>essay398</td>\n",
       "      <td>T13</td>\n",
       "      <td>Premise 1595 1648</td>\n",
       "      <td>this could avoid imbalance of gender in some s...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Part Of Speech tags: DET, VERB, VERB, NOUN, AD...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>essay398</td>\n",
       "      <td>T14</td>\n",
       "      <td>Premise 1650 1734</td>\n",
       "      <td>It would affect students' mental health to stu...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Part Of Speech tags: PRON, VERB, VERB, NOUN, P...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>essay398</td>\n",
       "      <td>T15</td>\n",
       "      <td>Premise 1349 1388</td>\n",
       "      <td>she is unlikely to focus on her subject</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Part Of Speech tags: PRON, AUX, ADJ, PART, VER...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>essay398</td>\n",
       "      <td>T16</td>\n",
       "      <td>Premise 1394 1463</td>\n",
       "      <td>this also can block the girl's future developm...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Part Of Speech tags: DET, ADV, VERB, VERB, DET...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_nr component_id   label_and_comp_idxs  \\\n",
       "0     essay004           T1    MajorClaim 262 376   \n",
       "1     essay004           T2  MajorClaim 1663 1758   \n",
       "2     essay004           T3         Claim 179 239   \n",
       "3     essay004           T4        Claim 953 1031   \n",
       "4     essay004           T5       Claim 1578 1624   \n",
       "...        ...          ...                   ...   \n",
       "1255  essay398          T12       Claim 1484 1589   \n",
       "1256  essay398          T13     Premise 1595 1648   \n",
       "1257  essay398          T14     Premise 1650 1734   \n",
       "1258  essay398          T15     Premise 1349 1388   \n",
       "1259  essay398          T16     Premise 1394 1463   \n",
       "\n",
       "                                                   text     label_x  \\\n",
       "0     this industry has affected the cultural attrib...  MajorClaim   \n",
       "1     the tourism has created threatening pressure o...  MajorClaim   \n",
       "2     the tourism bring large profit for the destina...       Claim   \n",
       "3     international tourism can create negative impa...       Claim   \n",
       "4        tourism has threatened the nature environments       Claim   \n",
       "...                                                 ...         ...   \n",
       "1255  universities should encourage more girls to ch...       Claim   \n",
       "1256  this could avoid imbalance of gender in some s...     Premise   \n",
       "1257  It would affect students' mental health to stu...     Premise   \n",
       "1258            she is unlikely to focus on her subject     Premise   \n",
       "1259  this also can block the girl's future developm...     Premise   \n",
       "\n",
       "     label_ComponentType relation_SupportAttack label_RelationType  \\\n",
       "0             MajorClaim                     []                      \n",
       "1             MajorClaim                     []                      \n",
       "2                  Claim                     []             Attack   \n",
       "3                  Claim                     []            Support   \n",
       "4                  Claim                     []            Support   \n",
       "...                  ...                    ...                ...   \n",
       "1255               Claim                     []            Support   \n",
       "1256             Premise                     []            Support   \n",
       "1257             Premise                     []            Support   \n",
       "1258             Premise                     []            Support   \n",
       "1259             Premise                     []            Support   \n",
       "\n",
       "     label_LinkedNotLinked split  ...  \\\n",
       "0                   Linked  TEST  ...   \n",
       "1                   Linked  TEST  ...   \n",
       "2                NotLinked  TEST  ...   \n",
       "3                   Linked  TEST  ...   \n",
       "4                   Linked  TEST  ...   \n",
       "...                    ...   ...  ...   \n",
       "1255                Linked  TEST  ...   \n",
       "1256             NotLinked  TEST  ...   \n",
       "1257             NotLinked  TEST  ...   \n",
       "1258             NotLinked  TEST  ...   \n",
       "1259             NotLinked  TEST  ...   \n",
       "\n",
       "                        structural_fts_as_text_combined  para_ratio  \\\n",
       "0     Topic: International tourism is now more commo...        0.25   \n",
       "1     Topic: International tourism is now more commo...        1.00   \n",
       "2     Topic: International tourism is now more commo...        0.25   \n",
       "3     Topic: International tourism is now more commo...        0.50   \n",
       "4     Topic: International tourism is now more commo...        0.75   \n",
       "...                                                 ...         ...   \n",
       "1255  Topic: We can not forcedly put the same number...        0.80   \n",
       "1256  Topic: We can not forcedly put the same number...        0.80   \n",
       "1257  Topic: We can not forcedly put the same number...        0.80   \n",
       "1258  Topic: We can not forcedly put the same number...        0.60   \n",
       "1259  Topic: We can not forcedly put the same number...        0.60   \n",
       "\n",
       "      first_or_last                      strct_fts_w_position_in_essay  \\\n",
       "0                 1  Topic: International tourism is now more commo...   \n",
       "1                 1  Topic: International tourism is now more commo...   \n",
       "2                 1  Topic: International tourism is now more commo...   \n",
       "3                 0  Topic: International tourism is now more commo...   \n",
       "4                 0  Topic: International tourism is now more commo...   \n",
       "...             ...                                                ...   \n",
       "1255              0  Topic: We can not forcedly put the same number...   \n",
       "1256              0  Topic: We can not forcedly put the same number...   \n",
       "1257              0  Topic: We can not forcedly put the same number...   \n",
       "1258              0  Topic: We can not forcedly put the same number...   \n",
       "1259              0  Topic: We can not forcedly put the same number...   \n",
       "\n",
       "                                     component_pos_tags  \\\n",
       "0     Part Of Speech tags: DET, NOUN, AUX, VERB, DET...   \n",
       "1     Part Of Speech tags: DET, NOUN, AUX, VERB, VER...   \n",
       "2     Part Of Speech tags: DET, NOUN, VERB, ADJ, NOU...   \n",
       "3     Part Of Speech tags: ADJ, NOUN, VERB, VERB, AD...   \n",
       "4     Part Of Speech tags: NOUN, AUX, VERB, DET, NOU...   \n",
       "...                                                 ...   \n",
       "1255  Part Of Speech tags: NOUN, VERB, VERB, ADJ, NO...   \n",
       "1256  Part Of Speech tags: DET, VERB, VERB, NOUN, AD...   \n",
       "1257  Part Of Speech tags: PRON, VERB, VERB, NOUN, P...   \n",
       "1258  Part Of Speech tags: PRON, AUX, ADJ, PART, VER...   \n",
       "1259  Part Of Speech tags: DET, ADV, VERB, VERB, DET...   \n",
       "\n",
       "                      strct_fts_essay_position_pos_tags  \\\n",
       "0     Topic: International tourism is now more commo...   \n",
       "1     Topic: International tourism is now more commo...   \n",
       "2     Topic: International tourism is now more commo...   \n",
       "3     Topic: International tourism is now more commo...   \n",
       "4     Topic: International tourism is now more commo...   \n",
       "...                                                 ...   \n",
       "1255  Topic: We can not forcedly put the same number...   \n",
       "1256  Topic: We can not forcedly put the same number...   \n",
       "1257  Topic: We can not forcedly put the same number...   \n",
       "1258  Topic: We can not forcedly put the same number...   \n",
       "1259  Topic: We can not forcedly put the same number...   \n",
       "\n",
       "                              prompted_representation_2  \\\n",
       "0     Which of these choices best describes the foll...   \n",
       "1     Which of these choices best describes the foll...   \n",
       "2     Which of these choices best describes the foll...   \n",
       "3     Which of these choices best describes the foll...   \n",
       "4     Which of these choices best describes the foll...   \n",
       "...                                                 ...   \n",
       "1255  Which of these choices best describes the foll...   \n",
       "1256  Which of these choices best describes the foll...   \n",
       "1257  Which of these choices best describes the foll...   \n",
       "1258  Which of these choices best describes the foll...   \n",
       "1259  Which of these choices best describes the foll...   \n",
       "\n",
       "                              prompted_representation_3  \\\n",
       "0     How is the component best described?: \"MajorCl...   \n",
       "1     How is the component best described?: \"MajorCl...   \n",
       "2     How is the component best described?: \"MajorCl...   \n",
       "3     How is the component best described?: \"MajorCl...   \n",
       "4     How is the component best described?: \"MajorCl...   \n",
       "...                                                 ...   \n",
       "1255  How is the component best described?: \"MajorCl...   \n",
       "1256  How is the component best described?: \"MajorCl...   \n",
       "1257  How is the component best described?: \"MajorCl...   \n",
       "1258  How is the component best described?: \"MajorCl...   \n",
       "1259  How is the component best described?: \"MajorCl...   \n",
       "\n",
       "                              prompted_rep_2_w_modif_MC  \\\n",
       "0     Which of these choices best describes the foll...   \n",
       "1     Which of these choices best describes the foll...   \n",
       "2     Which of these choices best describes the foll...   \n",
       "3     Which of these choices best describes the foll...   \n",
       "4     Which of these choices best describes the foll...   \n",
       "...                                                 ...   \n",
       "1255  Which of these choices best describes the foll...   \n",
       "1256  Which of these choices best describes the foll...   \n",
       "1257  Which of these choices best describes the foll...   \n",
       "1258  Which of these choices best describes the foll...   \n",
       "1259  Which of these choices best describes the foll...   \n",
       "\n",
       "                    prompted_rep_2_w_modif_MC_corrected  \n",
       "0     Which of these choices best describes the foll...  \n",
       "1     Which of these choices best describes the foll...  \n",
       "2     Which of these choices best describes the foll...  \n",
       "3     Which of these choices best describes the foll...  \n",
       "4     Which of these choices best describes the foll...  \n",
       "...                                                 ...  \n",
       "1255  Which of these choices best describes the foll...  \n",
       "1256  Which of these choices best describes the foll...  \n",
       "1257  Which of these choices best describes the foll...  \n",
       "1258  Which of these choices best describes the foll...  \n",
       "1259  Which of these choices best describes the foll...  \n",
       "\n",
       "[1260 rows x 43 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4a77421a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TEST    1260\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c0df6d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompted_texts_test = df_test['prompted_rep_2_w_modif_MC_corrected'][:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3000a5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompted_texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b419b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test = tokenizer(prompted_texts_test, return_tensors='pt', max_length=512, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "819d8ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0],\n",
       "        [ 101, 2029, 1997,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "46f38f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1260, 512])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3f38d892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test we do not need labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d3d5907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_train['labels'] = inputs_train.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "046778f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c7887e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_train['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7e78ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find where the last 102 is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9596ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(inputs_train['input_ids'][0] == 102).nonzero(as_tuple=True)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "43ad58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.decode(4366)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b86d8546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.decode(18458)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "471cd999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# claim = 4366, premise = 18458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3654320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(inputs_train['input_ids'][1] == 102).nonzero(as_tuple=True)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "90e15000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_train['input_ids'][1][169]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4f93b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that all at [len-2] indices are either claim or premise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4a1a215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_indices_list_test = []\n",
    "\n",
    "for i in range(len(prompted_texts_test)):\n",
    "    sep_idx = (inputs_test['input_ids'][i] == 102).nonzero(as_tuple=True)[0].item()\n",
    "    sep_indices_list_test.append(sep_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d076d9d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[151,\n",
       " 133,\n",
       " 134,\n",
       " 117,\n",
       " 104,\n",
       " 143,\n",
       " 259,\n",
       " 150,\n",
       " 128,\n",
       " 236,\n",
       " 155,\n",
       " 120,\n",
       " 146,\n",
       " 159,\n",
       " 142,\n",
       " 145,\n",
       " 205,\n",
       " 152,\n",
       " 136,\n",
       " 111,\n",
       " 118,\n",
       " 119,\n",
       " 122,\n",
       " 99,\n",
       " 146,\n",
       " 133,\n",
       " 139,\n",
       " 143,\n",
       " 110,\n",
       " 139,\n",
       " 111,\n",
       " 124,\n",
       " 127,\n",
       " 113,\n",
       " 149,\n",
       " 140,\n",
       " 108,\n",
       " 143,\n",
       " 106,\n",
       " 132,\n",
       " 132,\n",
       " 116,\n",
       " 119,\n",
       " 127,\n",
       " 120,\n",
       " 99,\n",
       " 107,\n",
       " 123,\n",
       " 118,\n",
       " 93,\n",
       " 103,\n",
       " 166,\n",
       " 128,\n",
       " 149,\n",
       " 109,\n",
       " 141,\n",
       " 156,\n",
       " 146,\n",
       " 108,\n",
       " 120,\n",
       " 147,\n",
       " 150,\n",
       " 153,\n",
       " 132,\n",
       " 163,\n",
       " 143,\n",
       " 196,\n",
       " 179,\n",
       " 225,\n",
       " 170,\n",
       " 170,\n",
       " 144,\n",
       " 124,\n",
       " 144,\n",
       " 117,\n",
       " 133,\n",
       " 148,\n",
       " 115,\n",
       " 137,\n",
       " 143,\n",
       " 127,\n",
       " 152,\n",
       " 160,\n",
       " 150,\n",
       " 136,\n",
       " 108,\n",
       " 114,\n",
       " 146,\n",
       " 160,\n",
       " 107,\n",
       " 104,\n",
       " 111,\n",
       " 124,\n",
       " 134,\n",
       " 124,\n",
       " 161,\n",
       " 137,\n",
       " 151,\n",
       " 121,\n",
       " 129,\n",
       " 111,\n",
       " 187,\n",
       " 100,\n",
       " 176,\n",
       " 147,\n",
       " 143,\n",
       " 145,\n",
       " 133,\n",
       " 121,\n",
       " 231,\n",
       " 140,\n",
       " 152,\n",
       " 148,\n",
       " 113,\n",
       " 135,\n",
       " 187,\n",
       " 152,\n",
       " 137,\n",
       " 116,\n",
       " 128,\n",
       " 135,\n",
       " 165,\n",
       " 193,\n",
       " 134,\n",
       " 186,\n",
       " 102,\n",
       " 204,\n",
       " 102,\n",
       " 157,\n",
       " 116,\n",
       " 162,\n",
       " 130,\n",
       " 140,\n",
       " 168,\n",
       " 118,\n",
       " 161,\n",
       " 115,\n",
       " 134,\n",
       " 99,\n",
       " 132,\n",
       " 168,\n",
       " 117,\n",
       " 136,\n",
       " 112,\n",
       " 142,\n",
       " 165,\n",
       " 201,\n",
       " 119,\n",
       " 118,\n",
       " 124,\n",
       " 147,\n",
       " 185,\n",
       " 134,\n",
       " 133,\n",
       " 130,\n",
       " 137,\n",
       " 156,\n",
       " 112,\n",
       " 152,\n",
       " 163,\n",
       " 212,\n",
       " 143,\n",
       " 120,\n",
       " 130,\n",
       " 150,\n",
       " 144,\n",
       " 120,\n",
       " 150,\n",
       " 142,\n",
       " 140,\n",
       " 133,\n",
       " 196,\n",
       " 141,\n",
       " 120,\n",
       " 120,\n",
       " 140,\n",
       " 134,\n",
       " 150,\n",
       " 144,\n",
       " 129,\n",
       " 107,\n",
       " 191,\n",
       " 177,\n",
       " 121,\n",
       " 239,\n",
       " 197,\n",
       " 138,\n",
       " 129,\n",
       " 141,\n",
       " 149,\n",
       " 157,\n",
       " 192,\n",
       " 140,\n",
       " 166,\n",
       " 149,\n",
       " 152,\n",
       " 127,\n",
       " 155,\n",
       " 132,\n",
       " 123,\n",
       " 189,\n",
       " 128,\n",
       " 121,\n",
       " 148,\n",
       " 145,\n",
       " 154,\n",
       " 158,\n",
       " 99,\n",
       " 138,\n",
       " 106,\n",
       " 120,\n",
       " 171,\n",
       " 155,\n",
       " 108,\n",
       " 225,\n",
       " 131,\n",
       " 146,\n",
       " 125,\n",
       " 184,\n",
       " 141,\n",
       " 179,\n",
       " 128,\n",
       " 130,\n",
       " 146,\n",
       " 185,\n",
       " 118,\n",
       " 139,\n",
       " 155,\n",
       " 123,\n",
       " 170,\n",
       " 129,\n",
       " 128,\n",
       " 165,\n",
       " 152,\n",
       " 143,\n",
       " 151,\n",
       " 162,\n",
       " 136,\n",
       " 154,\n",
       " 129,\n",
       " 171,\n",
       " 156,\n",
       " 138,\n",
       " 148,\n",
       " 174,\n",
       " 128,\n",
       " 140,\n",
       " 186,\n",
       " 125,\n",
       " 151,\n",
       " 117,\n",
       " 231,\n",
       " 110,\n",
       " 140,\n",
       " 146,\n",
       " 132,\n",
       " 134,\n",
       " 192,\n",
       " 127,\n",
       " 170,\n",
       " 120,\n",
       " 120,\n",
       " 102,\n",
       " 143,\n",
       " 133,\n",
       " 171,\n",
       " 183,\n",
       " 131,\n",
       " 105,\n",
       " 145,\n",
       " 145,\n",
       " 208,\n",
       " 107,\n",
       " 136,\n",
       " 160,\n",
       " 130,\n",
       " 117,\n",
       " 119,\n",
       " 198,\n",
       " 100,\n",
       " 119,\n",
       " 111,\n",
       " 130,\n",
       " 118,\n",
       " 125,\n",
       " 140,\n",
       " 197,\n",
       " 211,\n",
       " 113,\n",
       " 112,\n",
       " 130,\n",
       " 115,\n",
       " 127,\n",
       " 140,\n",
       " 140,\n",
       " 105,\n",
       " 177,\n",
       " 112,\n",
       " 141,\n",
       " 194,\n",
       " 129,\n",
       " 148,\n",
       " 163,\n",
       " 108,\n",
       " 141,\n",
       " 161,\n",
       " 138,\n",
       " 147,\n",
       " 150,\n",
       " 164,\n",
       " 101,\n",
       " 142,\n",
       " 184,\n",
       " 173,\n",
       " 172,\n",
       " 168,\n",
       " 101,\n",
       " 157,\n",
       " 193,\n",
       " 139,\n",
       " 107,\n",
       " 173,\n",
       " 115,\n",
       " 181,\n",
       " 128,\n",
       " 118,\n",
       " 133,\n",
       " 117,\n",
       " 116,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 188,\n",
       " 134,\n",
       " 119,\n",
       " 136,\n",
       " 156,\n",
       " 114,\n",
       " 104,\n",
       " 133,\n",
       " 127,\n",
       " 153,\n",
       " 118,\n",
       " 144,\n",
       " 157,\n",
       " 151,\n",
       " 128,\n",
       " 152,\n",
       " 123,\n",
       " 135,\n",
       " 129,\n",
       " 126,\n",
       " 121,\n",
       " 166,\n",
       " 122,\n",
       " 120,\n",
       " 124,\n",
       " 120,\n",
       " 140,\n",
       " 92,\n",
       " 116,\n",
       " 122,\n",
       " 104,\n",
       " 103,\n",
       " 112,\n",
       " 155,\n",
       " 125,\n",
       " 111,\n",
       " 113,\n",
       " 114,\n",
       " 113,\n",
       " 128,\n",
       " 109,\n",
       " 140,\n",
       " 136,\n",
       " 127,\n",
       " 149,\n",
       " 112,\n",
       " 131,\n",
       " 103,\n",
       " 243,\n",
       " 155,\n",
       " 126,\n",
       " 133,\n",
       " 131,\n",
       " 125,\n",
       " 152,\n",
       " 115,\n",
       " 138,\n",
       " 116,\n",
       " 110,\n",
       " 130,\n",
       " 136,\n",
       " 106,\n",
       " 139,\n",
       " 106,\n",
       " 131,\n",
       " 134,\n",
       " 115,\n",
       " 153,\n",
       " 175,\n",
       " 179,\n",
       " 145,\n",
       " 148,\n",
       " 145,\n",
       " 161,\n",
       " 140,\n",
       " 226,\n",
       " 155,\n",
       " 176,\n",
       " 118,\n",
       " 118,\n",
       " 146,\n",
       " 135,\n",
       " 137,\n",
       " 135,\n",
       " 123,\n",
       " 180,\n",
       " 124,\n",
       " 131,\n",
       " 155,\n",
       " 170,\n",
       " 243,\n",
       " 152,\n",
       " 192,\n",
       " 152,\n",
       " 234,\n",
       " 124,\n",
       " 121,\n",
       " 119,\n",
       " 122,\n",
       " 118,\n",
       " 123,\n",
       " 121,\n",
       " 108,\n",
       " 108,\n",
       " 103,\n",
       " 130,\n",
       " 123,\n",
       " 172,\n",
       " 135,\n",
       " 154,\n",
       " 160,\n",
       " 137,\n",
       " 114,\n",
       " 112,\n",
       " 143,\n",
       " 104,\n",
       " 152,\n",
       " 138,\n",
       " 110,\n",
       " 113,\n",
       " 144,\n",
       " 104,\n",
       " 108,\n",
       " 159,\n",
       " 138,\n",
       " 112,\n",
       " 144,\n",
       " 137,\n",
       " 108,\n",
       " 130,\n",
       " 124,\n",
       " 107,\n",
       " 148,\n",
       " 131,\n",
       " 135,\n",
       " 131,\n",
       " 125,\n",
       " 143,\n",
       " 147,\n",
       " 125,\n",
       " 128,\n",
       " 121,\n",
       " 173,\n",
       " 94,\n",
       " 177,\n",
       " 166,\n",
       " 124,\n",
       " 114,\n",
       " 138,\n",
       " 175,\n",
       " 138,\n",
       " 170,\n",
       " 138,\n",
       " 150,\n",
       " 143,\n",
       " 151,\n",
       " 176,\n",
       " 142,\n",
       " 124,\n",
       " 178,\n",
       " 114,\n",
       " 144,\n",
       " 146,\n",
       " 134,\n",
       " 141,\n",
       " 108,\n",
       " 127,\n",
       " 175,\n",
       " 112,\n",
       " 119,\n",
       " 135,\n",
       " 106,\n",
       " 140,\n",
       " 160,\n",
       " 127,\n",
       " 129,\n",
       " 112,\n",
       " 103,\n",
       " 152,\n",
       " 135,\n",
       " 145,\n",
       " 113,\n",
       " 153,\n",
       " 102,\n",
       " 128,\n",
       " 101,\n",
       " 210,\n",
       " 182,\n",
       " 181,\n",
       " 173,\n",
       " 139,\n",
       " 112,\n",
       " 124,\n",
       " 140,\n",
       " 230,\n",
       " 123,\n",
       " 166,\n",
       " 108,\n",
       " 155,\n",
       " 130,\n",
       " 164,\n",
       " 160,\n",
       " 166,\n",
       " 157,\n",
       " 243,\n",
       " 177,\n",
       " 228,\n",
       " 211,\n",
       " 182,\n",
       " 165,\n",
       " 166,\n",
       " 141,\n",
       " 136,\n",
       " 109,\n",
       " 147,\n",
       " 219,\n",
       " 118,\n",
       " 149,\n",
       " 111,\n",
       " 128,\n",
       " 145,\n",
       " 133,\n",
       " 118,\n",
       " 221,\n",
       " 159,\n",
       " 192,\n",
       " 129,\n",
       " 158,\n",
       " 112,\n",
       " 138,\n",
       " 120,\n",
       " 124,\n",
       " 110,\n",
       " 133,\n",
       " 125,\n",
       " 157,\n",
       " 122,\n",
       " 109,\n",
       " 122,\n",
       " 121,\n",
       " 181,\n",
       " 105,\n",
       " 130,\n",
       " 109,\n",
       " 129,\n",
       " 157,\n",
       " 111,\n",
       " 106,\n",
       " 120,\n",
       " 98,\n",
       " 145,\n",
       " 119,\n",
       " 173,\n",
       " 142,\n",
       " 166,\n",
       " 182,\n",
       " 147,\n",
       " 111,\n",
       " 162,\n",
       " 153,\n",
       " 159,\n",
       " 131,\n",
       " 113,\n",
       " 111,\n",
       " 111,\n",
       " 137,\n",
       " 125,\n",
       " 134,\n",
       " 127,\n",
       " 106,\n",
       " 185,\n",
       " 109,\n",
       " 113,\n",
       " 118,\n",
       " 114,\n",
       " 143,\n",
       " 103,\n",
       " 144,\n",
       " 125,\n",
       " 104,\n",
       " 132,\n",
       " 101,\n",
       " 142,\n",
       " 131,\n",
       " 148,\n",
       " 236,\n",
       " 163,\n",
       " 144,\n",
       " 158,\n",
       " 203,\n",
       " 125,\n",
       " 140,\n",
       " 121,\n",
       " 127,\n",
       " 164,\n",
       " 136,\n",
       " 136,\n",
       " 132,\n",
       " 138,\n",
       " 154,\n",
       " 165,\n",
       " 157,\n",
       " 251,\n",
       " 132,\n",
       " 110,\n",
       " 175,\n",
       " 161,\n",
       " 129,\n",
       " 123,\n",
       " 153,\n",
       " 122,\n",
       " 137,\n",
       " 159,\n",
       " 194,\n",
       " 112,\n",
       " 107,\n",
       " 135,\n",
       " 126,\n",
       " 110,\n",
       " 188,\n",
       " 138,\n",
       " 117,\n",
       " 130,\n",
       " 111,\n",
       " 118,\n",
       " 170,\n",
       " 118,\n",
       " 151,\n",
       " 127,\n",
       " 142,\n",
       " 109,\n",
       " 144,\n",
       " 125,\n",
       " 102,\n",
       " 139,\n",
       " 130,\n",
       " 165,\n",
       " 111,\n",
       " 133,\n",
       " 109,\n",
       " 127,\n",
       " 129,\n",
       " 110,\n",
       " 122,\n",
       " 116,\n",
       " 132,\n",
       " 157,\n",
       " 134,\n",
       " 126,\n",
       " 115,\n",
       " 107,\n",
       " 107,\n",
       " 108,\n",
       " 108,\n",
       " 117,\n",
       " 124,\n",
       " 119,\n",
       " 120,\n",
       " 140,\n",
       " 124,\n",
       " 136,\n",
       " 128,\n",
       " 130,\n",
       " 124,\n",
       " 167,\n",
       " 128,\n",
       " 165,\n",
       " 106,\n",
       " 124,\n",
       " 160,\n",
       " 117,\n",
       " 142,\n",
       " 124,\n",
       " 121,\n",
       " 144,\n",
       " 159,\n",
       " 131,\n",
       " 170,\n",
       " 212,\n",
       " 149,\n",
       " 125,\n",
       " 133,\n",
       " 137,\n",
       " 128,\n",
       " 126,\n",
       " 111,\n",
       " 135,\n",
       " 100,\n",
       " 129,\n",
       " 105,\n",
       " 126,\n",
       " 147,\n",
       " 118,\n",
       " 131,\n",
       " 159,\n",
       " 143,\n",
       " 140,\n",
       " 151,\n",
       " 96,\n",
       " 136,\n",
       " 125,\n",
       " 169,\n",
       " 120,\n",
       " 144,\n",
       " 133,\n",
       " 109,\n",
       " 145,\n",
       " 137,\n",
       " 135,\n",
       " 136,\n",
       " 132,\n",
       " 102,\n",
       " 147,\n",
       " 127,\n",
       " 128,\n",
       " 138,\n",
       " 158,\n",
       " 141,\n",
       " 168,\n",
       " 117,\n",
       " 135,\n",
       " 139,\n",
       " 192,\n",
       " 182,\n",
       " 142,\n",
       " 125,\n",
       " 139,\n",
       " 163,\n",
       " 131,\n",
       " 159,\n",
       " 138,\n",
       " 115,\n",
       " 155,\n",
       " 115,\n",
       " 134,\n",
       " 115,\n",
       " 105,\n",
       " 148,\n",
       " 157,\n",
       " 114,\n",
       " 130,\n",
       " 112,\n",
       " 133,\n",
       " 134,\n",
       " 125,\n",
       " 150,\n",
       " 117,\n",
       " 109,\n",
       " 192,\n",
       " 137,\n",
       " 126,\n",
       " 129,\n",
       " 126,\n",
       " 111,\n",
       " 124,\n",
       " 125,\n",
       " 190,\n",
       " 146,\n",
       " 139,\n",
       " 130,\n",
       " 114,\n",
       " 139,\n",
       " 141,\n",
       " 143,\n",
       " 150,\n",
       " 112,\n",
       " 137,\n",
       " 97,\n",
       " 141,\n",
       " 160,\n",
       " 133,\n",
       " 110,\n",
       " 133,\n",
       " 167,\n",
       " 141,\n",
       " 156,\n",
       " 150,\n",
       " 129,\n",
       " 147,\n",
       " 180,\n",
       " 186,\n",
       " 133,\n",
       " 131,\n",
       " 160,\n",
       " 130,\n",
       " 124,\n",
       " 146,\n",
       " 153,\n",
       " 147,\n",
       " 121,\n",
       " 145,\n",
       " 141,\n",
       " 131,\n",
       " 123,\n",
       " 172,\n",
       " 168,\n",
       " 122,\n",
       " 130,\n",
       " 106,\n",
       " 142,\n",
       " 132,\n",
       " 137,\n",
       " 127,\n",
       " 171,\n",
       " 170,\n",
       " 112,\n",
       " 160,\n",
       " 132,\n",
       " 156,\n",
       " 112,\n",
       " 127,\n",
       " 160,\n",
       " 139,\n",
       " 163,\n",
       " 124,\n",
       " 210,\n",
       " 120,\n",
       " 121,\n",
       " 144,\n",
       " 243,\n",
       " 139,\n",
       " 111,\n",
       " 134,\n",
       " 134,\n",
       " 204,\n",
       " 125,\n",
       " 129,\n",
       " 154,\n",
       " 127,\n",
       " 131,\n",
       " 109,\n",
       " 148,\n",
       " 154,\n",
       " 163,\n",
       " 182,\n",
       " 160,\n",
       " 145,\n",
       " 146,\n",
       " 129,\n",
       " 156,\n",
       " 131,\n",
       " 155,\n",
       " 199,\n",
       " 113,\n",
       " 132,\n",
       " 142,\n",
       " 124,\n",
       " 99,\n",
       " 166,\n",
       " 146,\n",
       " 206,\n",
       " 99,\n",
       " 127,\n",
       " 122,\n",
       " 147,\n",
       " 154,\n",
       " 160,\n",
       " 114,\n",
       " 142,\n",
       " 196,\n",
       " 190,\n",
       " 118,\n",
       " 121,\n",
       " 181,\n",
       " 188,\n",
       " 137,\n",
       " 128,\n",
       " 152,\n",
       " 141,\n",
       " 160,\n",
       " 151,\n",
       " 135,\n",
       " 164,\n",
       " 106,\n",
       " 153,\n",
       " 132,\n",
       " 118,\n",
       " 152,\n",
       " 124,\n",
       " 129,\n",
       " 148,\n",
       " 163,\n",
       " 137,\n",
       " 131,\n",
       " 145,\n",
       " 119,\n",
       " 127,\n",
       " 111,\n",
       " 147,\n",
       " 133,\n",
       " 117,\n",
       " 110,\n",
       " 142,\n",
       " 119,\n",
       " 132,\n",
       " 147,\n",
       " 130,\n",
       " 188,\n",
       " 130,\n",
       " 133,\n",
       " 113,\n",
       " 144,\n",
       " 136,\n",
       " 133,\n",
       " 128,\n",
       " 149,\n",
       " 146,\n",
       " 144,\n",
       " 138,\n",
       " 131,\n",
       " 159,\n",
       " 123,\n",
       " 121,\n",
       " 119,\n",
       " 116,\n",
       " 122,\n",
       " 116,\n",
       " 120,\n",
       " 110,\n",
       " 109,\n",
       " 107,\n",
       " 111,\n",
       " 118,\n",
       " 158,\n",
       " 141,\n",
       " 155,\n",
       " 136,\n",
       " 139,\n",
       " 126,\n",
       " 115,\n",
       " 99,\n",
       " 131,\n",
       " 113,\n",
       " 150,\n",
       " 122,\n",
       " 171,\n",
       " 118,\n",
       " 130,\n",
       " 111,\n",
       " 113,\n",
       " 237,\n",
       " 143,\n",
       " 169,\n",
       " 107,\n",
       " 145,\n",
       " 150,\n",
       " 120,\n",
       " 163,\n",
       " 112,\n",
       " 102,\n",
       " 156,\n",
       " 112,\n",
       " 111,\n",
       " 161,\n",
       " 118,\n",
       " 115,\n",
       " 122,\n",
       " 141,\n",
       " 196,\n",
       " 165,\n",
       " 187,\n",
       " 179,\n",
       " 200,\n",
       " 99,\n",
       " 197,\n",
       " 162,\n",
       " 162,\n",
       " 108,\n",
       " ...]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep_indices_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b30d8f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sep_indices_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d5682588",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tokens_indices_test_list = [x - 2 for x in sep_indices_list_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "653b5ab0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[149,\n",
       " 131,\n",
       " 132,\n",
       " 115,\n",
       " 102,\n",
       " 141,\n",
       " 257,\n",
       " 148,\n",
       " 126,\n",
       " 234,\n",
       " 153,\n",
       " 118,\n",
       " 144,\n",
       " 157,\n",
       " 140,\n",
       " 143,\n",
       " 203,\n",
       " 150,\n",
       " 134,\n",
       " 109,\n",
       " 116,\n",
       " 117,\n",
       " 120,\n",
       " 97,\n",
       " 144,\n",
       " 131,\n",
       " 137,\n",
       " 141,\n",
       " 108,\n",
       " 137,\n",
       " 109,\n",
       " 122,\n",
       " 125,\n",
       " 111,\n",
       " 147,\n",
       " 138,\n",
       " 106,\n",
       " 141,\n",
       " 104,\n",
       " 130,\n",
       " 130,\n",
       " 114,\n",
       " 117,\n",
       " 125,\n",
       " 118,\n",
       " 97,\n",
       " 105,\n",
       " 121,\n",
       " 116,\n",
       " 91,\n",
       " 101,\n",
       " 164,\n",
       " 126,\n",
       " 147,\n",
       " 107,\n",
       " 139,\n",
       " 154,\n",
       " 144,\n",
       " 106,\n",
       " 118,\n",
       " 145,\n",
       " 148,\n",
       " 151,\n",
       " 130,\n",
       " 161,\n",
       " 141,\n",
       " 194,\n",
       " 177,\n",
       " 223,\n",
       " 168,\n",
       " 168,\n",
       " 142,\n",
       " 122,\n",
       " 142,\n",
       " 115,\n",
       " 131,\n",
       " 146,\n",
       " 113,\n",
       " 135,\n",
       " 141,\n",
       " 125,\n",
       " 150,\n",
       " 158,\n",
       " 148,\n",
       " 134,\n",
       " 106,\n",
       " 112,\n",
       " 144,\n",
       " 158,\n",
       " 105,\n",
       " 102,\n",
       " 109,\n",
       " 122,\n",
       " 132,\n",
       " 122,\n",
       " 159,\n",
       " 135,\n",
       " 149,\n",
       " 119,\n",
       " 127,\n",
       " 109,\n",
       " 185,\n",
       " 98,\n",
       " 174,\n",
       " 145,\n",
       " 141,\n",
       " 143,\n",
       " 131,\n",
       " 119,\n",
       " 229,\n",
       " 138,\n",
       " 150,\n",
       " 146,\n",
       " 111,\n",
       " 133,\n",
       " 185,\n",
       " 150,\n",
       " 135,\n",
       " 114,\n",
       " 126,\n",
       " 133,\n",
       " 163,\n",
       " 191,\n",
       " 132,\n",
       " 184,\n",
       " 100,\n",
       " 202,\n",
       " 100,\n",
       " 155,\n",
       " 114,\n",
       " 160,\n",
       " 128,\n",
       " 138,\n",
       " 166,\n",
       " 116,\n",
       " 159,\n",
       " 113,\n",
       " 132,\n",
       " 97,\n",
       " 130,\n",
       " 166,\n",
       " 115,\n",
       " 134,\n",
       " 110,\n",
       " 140,\n",
       " 163,\n",
       " 199,\n",
       " 117,\n",
       " 116,\n",
       " 122,\n",
       " 145,\n",
       " 183,\n",
       " 132,\n",
       " 131,\n",
       " 128,\n",
       " 135,\n",
       " 154,\n",
       " 110,\n",
       " 150,\n",
       " 161,\n",
       " 210,\n",
       " 141,\n",
       " 118,\n",
       " 128,\n",
       " 148,\n",
       " 142,\n",
       " 118,\n",
       " 148,\n",
       " 140,\n",
       " 138,\n",
       " 131,\n",
       " 194,\n",
       " 139,\n",
       " 118,\n",
       " 118,\n",
       " 138,\n",
       " 132,\n",
       " 148,\n",
       " 142,\n",
       " 127,\n",
       " 105,\n",
       " 189,\n",
       " 175,\n",
       " 119,\n",
       " 237,\n",
       " 195,\n",
       " 136,\n",
       " 127,\n",
       " 139,\n",
       " 147,\n",
       " 155,\n",
       " 190,\n",
       " 138,\n",
       " 164,\n",
       " 147,\n",
       " 150,\n",
       " 125,\n",
       " 153,\n",
       " 130,\n",
       " 121,\n",
       " 187,\n",
       " 126,\n",
       " 119,\n",
       " 146,\n",
       " 143,\n",
       " 152,\n",
       " 156,\n",
       " 97,\n",
       " 136,\n",
       " 104,\n",
       " 118,\n",
       " 169,\n",
       " 153,\n",
       " 106,\n",
       " 223,\n",
       " 129,\n",
       " 144,\n",
       " 123,\n",
       " 182,\n",
       " 139,\n",
       " 177,\n",
       " 126,\n",
       " 128,\n",
       " 144,\n",
       " 183,\n",
       " 116,\n",
       " 137,\n",
       " 153,\n",
       " 121,\n",
       " 168,\n",
       " 127,\n",
       " 126,\n",
       " 163,\n",
       " 150,\n",
       " 141,\n",
       " 149,\n",
       " 160,\n",
       " 134,\n",
       " 152,\n",
       " 127,\n",
       " 169,\n",
       " 154,\n",
       " 136,\n",
       " 146,\n",
       " 172,\n",
       " 126,\n",
       " 138,\n",
       " 184,\n",
       " 123,\n",
       " 149,\n",
       " 115,\n",
       " 229,\n",
       " 108,\n",
       " 138,\n",
       " 144,\n",
       " 130,\n",
       " 132,\n",
       " 190,\n",
       " 125,\n",
       " 168,\n",
       " 118,\n",
       " 118,\n",
       " 100,\n",
       " 141,\n",
       " 131,\n",
       " 169,\n",
       " 181,\n",
       " 129,\n",
       " 103,\n",
       " 143,\n",
       " 143,\n",
       " 206,\n",
       " 105,\n",
       " 134,\n",
       " 158,\n",
       " 128,\n",
       " 115,\n",
       " 117,\n",
       " 196,\n",
       " 98,\n",
       " 117,\n",
       " 109,\n",
       " 128,\n",
       " 116,\n",
       " 123,\n",
       " 138,\n",
       " 195,\n",
       " 209,\n",
       " 111,\n",
       " 110,\n",
       " 128,\n",
       " 113,\n",
       " 125,\n",
       " 138,\n",
       " 138,\n",
       " 103,\n",
       " 175,\n",
       " 110,\n",
       " 139,\n",
       " 192,\n",
       " 127,\n",
       " 146,\n",
       " 161,\n",
       " 106,\n",
       " 139,\n",
       " 159,\n",
       " 136,\n",
       " 145,\n",
       " 148,\n",
       " 162,\n",
       " 99,\n",
       " 140,\n",
       " 182,\n",
       " 171,\n",
       " 170,\n",
       " 166,\n",
       " 99,\n",
       " 155,\n",
       " 191,\n",
       " 137,\n",
       " 105,\n",
       " 171,\n",
       " 113,\n",
       " 179,\n",
       " 126,\n",
       " 116,\n",
       " 131,\n",
       " 115,\n",
       " 114,\n",
       " 138,\n",
       " 138,\n",
       " 138,\n",
       " 186,\n",
       " 132,\n",
       " 117,\n",
       " 134,\n",
       " 154,\n",
       " 112,\n",
       " 102,\n",
       " 131,\n",
       " 125,\n",
       " 151,\n",
       " 116,\n",
       " 142,\n",
       " 155,\n",
       " 149,\n",
       " 126,\n",
       " 150,\n",
       " 121,\n",
       " 133,\n",
       " 127,\n",
       " 124,\n",
       " 119,\n",
       " 164,\n",
       " 120,\n",
       " 118,\n",
       " 122,\n",
       " 118,\n",
       " 138,\n",
       " 90,\n",
       " 114,\n",
       " 120,\n",
       " 102,\n",
       " 101,\n",
       " 110,\n",
       " 153,\n",
       " 123,\n",
       " 109,\n",
       " 111,\n",
       " 112,\n",
       " 111,\n",
       " 126,\n",
       " 107,\n",
       " 138,\n",
       " 134,\n",
       " 125,\n",
       " 147,\n",
       " 110,\n",
       " 129,\n",
       " 101,\n",
       " 241,\n",
       " 153,\n",
       " 124,\n",
       " 131,\n",
       " 129,\n",
       " 123,\n",
       " 150,\n",
       " 113,\n",
       " 136,\n",
       " 114,\n",
       " 108,\n",
       " 128,\n",
       " 134,\n",
       " 104,\n",
       " 137,\n",
       " 104,\n",
       " 129,\n",
       " 132,\n",
       " 113,\n",
       " 151,\n",
       " 173,\n",
       " 177,\n",
       " 143,\n",
       " 146,\n",
       " 143,\n",
       " 159,\n",
       " 138,\n",
       " 224,\n",
       " 153,\n",
       " 174,\n",
       " 116,\n",
       " 116,\n",
       " 144,\n",
       " 133,\n",
       " 135,\n",
       " 133,\n",
       " 121,\n",
       " 178,\n",
       " 122,\n",
       " 129,\n",
       " 153,\n",
       " 168,\n",
       " 241,\n",
       " 150,\n",
       " 190,\n",
       " 150,\n",
       " 232,\n",
       " 122,\n",
       " 119,\n",
       " 117,\n",
       " 120,\n",
       " 116,\n",
       " 121,\n",
       " 119,\n",
       " 106,\n",
       " 106,\n",
       " 101,\n",
       " 128,\n",
       " 121,\n",
       " 170,\n",
       " 133,\n",
       " 152,\n",
       " 158,\n",
       " 135,\n",
       " 112,\n",
       " 110,\n",
       " 141,\n",
       " 102,\n",
       " 150,\n",
       " 136,\n",
       " 108,\n",
       " 111,\n",
       " 142,\n",
       " 102,\n",
       " 106,\n",
       " 157,\n",
       " 136,\n",
       " 110,\n",
       " 142,\n",
       " 135,\n",
       " 106,\n",
       " 128,\n",
       " 122,\n",
       " 105,\n",
       " 146,\n",
       " 129,\n",
       " 133,\n",
       " 129,\n",
       " 123,\n",
       " 141,\n",
       " 145,\n",
       " 123,\n",
       " 126,\n",
       " 119,\n",
       " 171,\n",
       " 92,\n",
       " 175,\n",
       " 164,\n",
       " 122,\n",
       " 112,\n",
       " 136,\n",
       " 173,\n",
       " 136,\n",
       " 168,\n",
       " 136,\n",
       " 148,\n",
       " 141,\n",
       " 149,\n",
       " 174,\n",
       " 140,\n",
       " 122,\n",
       " 176,\n",
       " 112,\n",
       " 142,\n",
       " 144,\n",
       " 132,\n",
       " 139,\n",
       " 106,\n",
       " 125,\n",
       " 173,\n",
       " 110,\n",
       " 117,\n",
       " 133,\n",
       " 104,\n",
       " 138,\n",
       " 158,\n",
       " 125,\n",
       " 127,\n",
       " 110,\n",
       " 101,\n",
       " 150,\n",
       " 133,\n",
       " 143,\n",
       " 111,\n",
       " 151,\n",
       " 100,\n",
       " 126,\n",
       " 99,\n",
       " 208,\n",
       " 180,\n",
       " 179,\n",
       " 171,\n",
       " 137,\n",
       " 110,\n",
       " 122,\n",
       " 138,\n",
       " 228,\n",
       " 121,\n",
       " 164,\n",
       " 106,\n",
       " 153,\n",
       " 128,\n",
       " 162,\n",
       " 158,\n",
       " 164,\n",
       " 155,\n",
       " 241,\n",
       " 175,\n",
       " 226,\n",
       " 209,\n",
       " 180,\n",
       " 163,\n",
       " 164,\n",
       " 139,\n",
       " 134,\n",
       " 107,\n",
       " 145,\n",
       " 217,\n",
       " 116,\n",
       " 147,\n",
       " 109,\n",
       " 126,\n",
       " 143,\n",
       " 131,\n",
       " 116,\n",
       " 219,\n",
       " 157,\n",
       " 190,\n",
       " 127,\n",
       " 156,\n",
       " 110,\n",
       " 136,\n",
       " 118,\n",
       " 122,\n",
       " 108,\n",
       " 131,\n",
       " 123,\n",
       " 155,\n",
       " 120,\n",
       " 107,\n",
       " 120,\n",
       " 119,\n",
       " 179,\n",
       " 103,\n",
       " 128,\n",
       " 107,\n",
       " 127,\n",
       " 155,\n",
       " 109,\n",
       " 104,\n",
       " 118,\n",
       " 96,\n",
       " 143,\n",
       " 117,\n",
       " 171,\n",
       " 140,\n",
       " 164,\n",
       " 180,\n",
       " 145,\n",
       " 109,\n",
       " 160,\n",
       " 151,\n",
       " 157,\n",
       " 129,\n",
       " 111,\n",
       " 109,\n",
       " 109,\n",
       " 135,\n",
       " 123,\n",
       " 132,\n",
       " 125,\n",
       " 104,\n",
       " 183,\n",
       " 107,\n",
       " 111,\n",
       " 116,\n",
       " 112,\n",
       " 141,\n",
       " 101,\n",
       " 142,\n",
       " 123,\n",
       " 102,\n",
       " 130,\n",
       " 99,\n",
       " 140,\n",
       " 129,\n",
       " 146,\n",
       " 234,\n",
       " 161,\n",
       " 142,\n",
       " 156,\n",
       " 201,\n",
       " 123,\n",
       " 138,\n",
       " 119,\n",
       " 125,\n",
       " 162,\n",
       " 134,\n",
       " 134,\n",
       " 130,\n",
       " 136,\n",
       " 152,\n",
       " 163,\n",
       " 155,\n",
       " 249,\n",
       " 130,\n",
       " 108,\n",
       " 173,\n",
       " 159,\n",
       " 127,\n",
       " 121,\n",
       " 151,\n",
       " 120,\n",
       " 135,\n",
       " 157,\n",
       " 192,\n",
       " 110,\n",
       " 105,\n",
       " 133,\n",
       " 124,\n",
       " 108,\n",
       " 186,\n",
       " 136,\n",
       " 115,\n",
       " 128,\n",
       " 109,\n",
       " 116,\n",
       " 168,\n",
       " 116,\n",
       " 149,\n",
       " 125,\n",
       " 140,\n",
       " 107,\n",
       " 142,\n",
       " 123,\n",
       " 100,\n",
       " 137,\n",
       " 128,\n",
       " 163,\n",
       " 109,\n",
       " 131,\n",
       " 107,\n",
       " 125,\n",
       " 127,\n",
       " 108,\n",
       " 120,\n",
       " 114,\n",
       " 130,\n",
       " 155,\n",
       " 132,\n",
       " 124,\n",
       " 113,\n",
       " 105,\n",
       " 105,\n",
       " 106,\n",
       " 106,\n",
       " 115,\n",
       " 122,\n",
       " 117,\n",
       " 118,\n",
       " 138,\n",
       " 122,\n",
       " 134,\n",
       " 126,\n",
       " 128,\n",
       " 122,\n",
       " 165,\n",
       " 126,\n",
       " 163,\n",
       " 104,\n",
       " 122,\n",
       " 158,\n",
       " 115,\n",
       " 140,\n",
       " 122,\n",
       " 119,\n",
       " 142,\n",
       " 157,\n",
       " 129,\n",
       " 168,\n",
       " 210,\n",
       " 147,\n",
       " 123,\n",
       " 131,\n",
       " 135,\n",
       " 126,\n",
       " 124,\n",
       " 109,\n",
       " 133,\n",
       " 98,\n",
       " 127,\n",
       " 103,\n",
       " 124,\n",
       " 145,\n",
       " 116,\n",
       " 129,\n",
       " 157,\n",
       " 141,\n",
       " 138,\n",
       " 149,\n",
       " 94,\n",
       " 134,\n",
       " 123,\n",
       " 167,\n",
       " 118,\n",
       " 142,\n",
       " 131,\n",
       " 107,\n",
       " 143,\n",
       " 135,\n",
       " 133,\n",
       " 134,\n",
       " 130,\n",
       " 100,\n",
       " 145,\n",
       " 125,\n",
       " 126,\n",
       " 136,\n",
       " 156,\n",
       " 139,\n",
       " 166,\n",
       " 115,\n",
       " 133,\n",
       " 137,\n",
       " 190,\n",
       " 180,\n",
       " 140,\n",
       " 123,\n",
       " 137,\n",
       " 161,\n",
       " 129,\n",
       " 157,\n",
       " 136,\n",
       " 113,\n",
       " 153,\n",
       " 113,\n",
       " 132,\n",
       " 113,\n",
       " 103,\n",
       " 146,\n",
       " 155,\n",
       " 112,\n",
       " 128,\n",
       " 110,\n",
       " 131,\n",
       " 132,\n",
       " 123,\n",
       " 148,\n",
       " 115,\n",
       " 107,\n",
       " 190,\n",
       " 135,\n",
       " 124,\n",
       " 127,\n",
       " 124,\n",
       " 109,\n",
       " 122,\n",
       " 123,\n",
       " 188,\n",
       " 144,\n",
       " 137,\n",
       " 128,\n",
       " 112,\n",
       " 137,\n",
       " 139,\n",
       " 141,\n",
       " 148,\n",
       " 110,\n",
       " 135,\n",
       " 95,\n",
       " 139,\n",
       " 158,\n",
       " 131,\n",
       " 108,\n",
       " 131,\n",
       " 165,\n",
       " 139,\n",
       " 154,\n",
       " 148,\n",
       " 127,\n",
       " 145,\n",
       " 178,\n",
       " 184,\n",
       " 131,\n",
       " 129,\n",
       " 158,\n",
       " 128,\n",
       " 122,\n",
       " 144,\n",
       " 151,\n",
       " 145,\n",
       " 119,\n",
       " 143,\n",
       " 139,\n",
       " 129,\n",
       " 121,\n",
       " 170,\n",
       " 166,\n",
       " 120,\n",
       " 128,\n",
       " 104,\n",
       " 140,\n",
       " 130,\n",
       " 135,\n",
       " 125,\n",
       " 169,\n",
       " 168,\n",
       " 110,\n",
       " 158,\n",
       " 130,\n",
       " 154,\n",
       " 110,\n",
       " 125,\n",
       " 158,\n",
       " 137,\n",
       " 161,\n",
       " 122,\n",
       " 208,\n",
       " 118,\n",
       " 119,\n",
       " 142,\n",
       " 241,\n",
       " 137,\n",
       " 109,\n",
       " 132,\n",
       " 132,\n",
       " 202,\n",
       " 123,\n",
       " 127,\n",
       " 152,\n",
       " 125,\n",
       " 129,\n",
       " 107,\n",
       " 146,\n",
       " 152,\n",
       " 161,\n",
       " 180,\n",
       " 158,\n",
       " 143,\n",
       " 144,\n",
       " 127,\n",
       " 154,\n",
       " 129,\n",
       " 153,\n",
       " 197,\n",
       " 111,\n",
       " 130,\n",
       " 140,\n",
       " 122,\n",
       " 97,\n",
       " 164,\n",
       " 144,\n",
       " 204,\n",
       " 97,\n",
       " 125,\n",
       " 120,\n",
       " 145,\n",
       " 152,\n",
       " 158,\n",
       " 112,\n",
       " 140,\n",
       " 194,\n",
       " 188,\n",
       " 116,\n",
       " 119,\n",
       " 179,\n",
       " 186,\n",
       " 135,\n",
       " 126,\n",
       " 150,\n",
       " 139,\n",
       " 158,\n",
       " 149,\n",
       " 133,\n",
       " 162,\n",
       " 104,\n",
       " 151,\n",
       " 130,\n",
       " 116,\n",
       " 150,\n",
       " 122,\n",
       " 127,\n",
       " 146,\n",
       " 161,\n",
       " 135,\n",
       " 129,\n",
       " 143,\n",
       " 117,\n",
       " 125,\n",
       " 109,\n",
       " 145,\n",
       " 131,\n",
       " 115,\n",
       " 108,\n",
       " 140,\n",
       " 117,\n",
       " 130,\n",
       " 145,\n",
       " 128,\n",
       " 186,\n",
       " 128,\n",
       " 131,\n",
       " 111,\n",
       " 142,\n",
       " 134,\n",
       " 131,\n",
       " 126,\n",
       " 147,\n",
       " 144,\n",
       " 142,\n",
       " 136,\n",
       " 129,\n",
       " 157,\n",
       " 121,\n",
       " 119,\n",
       " 117,\n",
       " 114,\n",
       " 120,\n",
       " 114,\n",
       " 118,\n",
       " 108,\n",
       " 107,\n",
       " 105,\n",
       " 109,\n",
       " 116,\n",
       " 156,\n",
       " 139,\n",
       " 153,\n",
       " 134,\n",
       " 137,\n",
       " 124,\n",
       " 113,\n",
       " 97,\n",
       " 129,\n",
       " 111,\n",
       " 148,\n",
       " 120,\n",
       " 169,\n",
       " 116,\n",
       " 128,\n",
       " 109,\n",
       " 111,\n",
       " 235,\n",
       " 141,\n",
       " 167,\n",
       " 105,\n",
       " 143,\n",
       " 148,\n",
       " 118,\n",
       " 161,\n",
       " 110,\n",
       " 100,\n",
       " 154,\n",
       " 110,\n",
       " 109,\n",
       " 159,\n",
       " 116,\n",
       " 113,\n",
       " 120,\n",
       " 139,\n",
       " 194,\n",
       " 163,\n",
       " 185,\n",
       " 177,\n",
       " 198,\n",
       " 97,\n",
       " 195,\n",
       " 160,\n",
       " 160,\n",
       " 106,\n",
       " ...]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_tokens_indices_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1520b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs_pe['input_ids'][0][143].item() # correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b9dfab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get a list of input ids at all these indices: they should be either claim = 4366, premise = 18458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0a01e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index_minus_2_test = []\n",
    "\n",
    "for idx, val in enumerate(class_tokens_indices_test_list):\n",
    "    at_idx_minus_2 = inputs_test['input_ids'][idx][val].item()\n",
    "    list_index_minus_2_test.append(at_idx_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a748e5c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4366, 11032, 18458}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list_index_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7470b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8c2763fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make the class token indices 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "52cfbf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, val in enumerate(class_tokens_indices_test_list):\n",
    "    inputs_test['input_ids'][idx][val] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5cad75d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check if they are 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8b174064",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsontroi_check_list = []\n",
    "\n",
    "for idx, val in enumerate(class_tokens_indices_test_list):\n",
    "    at_idx_minus_2 = inputs_test['input_ids'][idx][val].item()\n",
    "    unsontroi_check_list.append(at_idx_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8d3bb227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{103}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(unsontroi_check_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d7b6081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "08d4b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PeDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, encodings):\n",
    "#         self.encodings = encodings\n",
    "#     def __getitem__(self, idx):\n",
    "#         return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "#     def __len__(self):\n",
    "#         return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "05e88c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PeDataset(inputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4e9e65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "# maybe we don't need this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be47dcc6",
   "metadata": {},
   "source": [
    "## get the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "90dfec7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1a877f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a5d3256a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "62c297d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see with a simple trainer now and then we will try the fancy trainer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2189fdcf",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d5c17b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "90c6a793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0eb3be44",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4ad4a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCHS = 10\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bd77b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \n",
    "    # output\n",
    "    output_dir='output',          \n",
    "    \n",
    "    # params\n",
    "    num_train_epochs=NB_EPOCHS,               # nb of epochs\n",
    "    per_device_train_batch_size=BATCH_SIZE,   # batch size per device during training\n",
    "    per_device_eval_batch_size=BATCH_SIZE,    # cf. paper Sun et al.\n",
    "    learning_rate=1e-5,#2e-5,                 # cf. paper Sun et al.\n",
    "#     warmup_steps=500,                         # number of warmup steps for learning rate scheduler\n",
    "    warmup_ratio=0.1,                         # cf. paper Sun et al.\n",
    "    weight_decay=0.01,                        # strength of weight decay\n",
    "    \n",
    "    # eval\n",
    "    evaluation_strategy=\"epoch\",              # cf. paper Sun et al.\n",
    "    #eval_steps=20,                            # cf. paper Sun et al.\n",
    "    #eval_accumulation_steps = BATCH_SIZE,\n",
    "    # fp16_full_eval = True,\n",
    "    \n",
    "    # clean the tensor board folder to see the loss properly.\n",
    "    \n",
    "    # log\n",
    "    logging_dir=\"/notebooks/Prompting/results\",  \n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    \n",
    "    # save\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=2,\n",
    "    # save_steps=20, # default 500\n",
    "    load_best_model_at_end=True,              # cf. paper Sun et al.\n",
    "    metric_for_best_model='eval_loss' \n",
    "    # metric_for_best_model='f1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c07a1c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import TrainingArguments\n",
    "\n",
    "# args = TrainingArguments(\n",
    "#     output_dir = 'out',\n",
    "#     per_device_train_batch_size=16,\n",
    "#     num_train_epochs=2\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d766206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset\n",
    "    #compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c4ccddce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 4241\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5310\n",
      "/tmp/ipykernel_196/1625588428.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5310' max='5310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5310/5310 48:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.004312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.001359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.001189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.001260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.001074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.001082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 472\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-531\n",
      "Configuration saved in output/checkpoint-531/config.json\n",
      "Model weights saved in output/checkpoint-531/pytorch_model.bin\n",
      "/tmp/ipykernel_196/1625588428.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 472\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-1062\n",
      "Configuration saved in output/checkpoint-1062/config.json\n",
      "Model weights saved in output/checkpoint-1062/pytorch_model.bin\n",
      "/tmp/ipykernel_196/1625588428.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 472\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-1593\n",
      "Configuration saved in output/checkpoint-1593/config.json\n",
      "Model weights saved in output/checkpoint-1593/pytorch_model.bin\n",
      "Deleting older checkpoint [output/checkpoint-531] due to args.save_total_limit\n",
      "/tmp/ipykernel_196/1625588428.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 472\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-2124\n",
      "Configuration saved in output/checkpoint-2124/config.json\n",
      "Model weights saved in output/checkpoint-2124/pytorch_model.bin\n",
      "Deleting older checkpoint [output/checkpoint-1062] due to args.save_total_limit\n",
      "/tmp/ipykernel_196/1625588428.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 472\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-2655\n",
      "Configuration saved in output/checkpoint-2655/config.json\n",
      "Model weights saved in output/checkpoint-2655/pytorch_model.bin\n",
      "Deleting older checkpoint [output/checkpoint-1593] due to args.save_total_limit\n",
      "/tmp/ipykernel_196/1625588428.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 472\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-3186\n",
      "Configuration saved in output/checkpoint-3186/config.json\n",
      "Model weights saved in output/checkpoint-3186/pytorch_model.bin\n",
      "Deleting older checkpoint [output/checkpoint-2124] due to args.save_total_limit\n",
      "/tmp/ipykernel_196/1625588428.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 472\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-3717\n",
      "Configuration saved in output/checkpoint-3717/config.json\n",
      "Model weights saved in output/checkpoint-3717/pytorch_model.bin\n",
      "Deleting older checkpoint [output/checkpoint-3186] due to args.save_total_limit\n",
      "/tmp/ipykernel_196/1625588428.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 472\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-4248\n",
      "Configuration saved in output/checkpoint-4248/config.json\n",
      "Model weights saved in output/checkpoint-4248/pytorch_model.bin\n",
      "Deleting older checkpoint [output/checkpoint-2655] due to args.save_total_limit\n",
      "/tmp/ipykernel_196/1625588428.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 472\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-4779\n",
      "Configuration saved in output/checkpoint-4779/config.json\n",
      "Model weights saved in output/checkpoint-4779/pytorch_model.bin\n",
      "Deleting older checkpoint [output/checkpoint-3717] due to args.save_total_limit\n",
      "/tmp/ipykernel_196/1625588428.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 472\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-5310\n",
      "Configuration saved in output/checkpoint-5310/config.json\n",
      "Model weights saved in output/checkpoint-5310/pytorch_model.bin\n",
      "Deleting older checkpoint [output/checkpoint-4779] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from output/checkpoint-4248 (score: 0.0009741681860759854).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5310, training_loss=0.25779909381446503, metrics={'train_runtime': 2919.4553, 'train_samples_per_second': 14.527, 'train_steps_per_second': 1.819, 'total_flos': 1.1162516110848e+16, 'train_loss': 0.25779909381446503, 'epoch': 10.0})"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "06c56ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to pe_mask_model_prompted_rep_2\n",
      "Configuration saved in pe_mask_model_prompted_rep_2/config.json\n",
      "Model weights saved in pe_mask_model_prompted_rep_2/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"pe_mask_model_prompted_rep_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "02cc6ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new idea: take this model and finetune the PE dataset on it.\n",
    "# so instead of loading a pre-trained BERT, load this instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8d3ac1",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "de452375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /notebooks/Prompting/notebooks/prompt_template_2/pe_mask_model_prompted_rep_2/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /notebooks/Prompting/notebooks/prompt_template_2/pe_mask_model_prompted_rep_2/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForMaskedLM.\n",
      "\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at /notebooks/Prompting/notebooks/prompt_template_2/pe_mask_model_prompted_rep_2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "saved_model = BertForMaskedLM.from_pretrained(\"/notebooks/Prompting/notebooks/prompt_template_2/pe_mask_model_prompted_rep_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5465d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "72585c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "28a4b626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(\"fill-mask\", model=saved_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d29107ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "23a5f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['stance', 'claim', 'premise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "01ac34d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok now see how to do this for the whole list of test components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bcfe57e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# but first we must replace the last token by [MASK]!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e34e850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masked_components(x):\n",
    "    \n",
    "    prompted_rep = x.prompted_rep_2_w_modif_MC_corrected\n",
    "    \n",
    "    last_token = prompted_rep.split()[-1]\n",
    "    \n",
    "\n",
    "    new_rep = prompted_rep.replace(last_token, \"[MASK].\")\n",
    "\n",
    "    \n",
    "    return new_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bc4d7bd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_nr</th>\n",
       "      <th>component_id</th>\n",
       "      <th>label_and_comp_idxs</th>\n",
       "      <th>text</th>\n",
       "      <th>label_x</th>\n",
       "      <th>label_ComponentType</th>\n",
       "      <th>relation_SupportAttack</th>\n",
       "      <th>label_RelationType</th>\n",
       "      <th>label_LinkedNotLinked</th>\n",
       "      <th>split</th>\n",
       "      <th>...</th>\n",
       "      <th>structural_fts_as_text_combined</th>\n",
       "      <th>para_ratio</th>\n",
       "      <th>first_or_last</th>\n",
       "      <th>strct_fts_w_position_in_essay</th>\n",
       "      <th>component_pos_tags</th>\n",
       "      <th>strct_fts_essay_position_pos_tags</th>\n",
       "      <th>prompted_representation_2</th>\n",
       "      <th>prompted_representation_3</th>\n",
       "      <th>prompted_rep_2_w_modif_MC</th>\n",
       "      <th>prompted_rep_2_w_modif_MC_corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>essay004</td>\n",
       "      <td>T1</td>\n",
       "      <td>MajorClaim 262 376</td>\n",
       "      <td>this industry has affected the cultural attrib...</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Linked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Part Of Speech tags: DET, NOUN, AUX, VERB, DET...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>essay004</td>\n",
       "      <td>T2</td>\n",
       "      <td>MajorClaim 1663 1758</td>\n",
       "      <td>the tourism has created threatening pressure o...</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Linked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Part Of Speech tags: DET, NOUN, AUX, VERB, VER...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>essay004</td>\n",
       "      <td>T3</td>\n",
       "      <td>Claim 179 239</td>\n",
       "      <td>the tourism bring large profit for the destina...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Attack</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Part Of Speech tags: DET, NOUN, VERB, ADJ, NOU...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>essay004</td>\n",
       "      <td>T4</td>\n",
       "      <td>Claim 953 1031</td>\n",
       "      <td>international tourism can create negative impa...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Part Of Speech tags: ADJ, NOUN, VERB, VERB, AD...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>essay004</td>\n",
       "      <td>T5</td>\n",
       "      <td>Claim 1578 1624</td>\n",
       "      <td>tourism has threatened the nature environments</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Part Of Speech tags: NOUN, AUX, VERB, DET, NOU...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>essay398</td>\n",
       "      <td>T12</td>\n",
       "      <td>Claim 1484 1589</td>\n",
       "      <td>universities should encourage more girls to ch...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Part Of Speech tags: NOUN, VERB, VERB, ADJ, NO...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>essay398</td>\n",
       "      <td>T13</td>\n",
       "      <td>Premise 1595 1648</td>\n",
       "      <td>this could avoid imbalance of gender in some s...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Part Of Speech tags: DET, VERB, VERB, NOUN, AD...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>essay398</td>\n",
       "      <td>T14</td>\n",
       "      <td>Premise 1650 1734</td>\n",
       "      <td>It would affect students' mental health to stu...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Part Of Speech tags: PRON, VERB, VERB, NOUN, P...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>essay398</td>\n",
       "      <td>T15</td>\n",
       "      <td>Premise 1349 1388</td>\n",
       "      <td>she is unlikely to focus on her subject</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Part Of Speech tags: PRON, AUX, ADJ, PART, VER...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>essay398</td>\n",
       "      <td>T16</td>\n",
       "      <td>Premise 1394 1463</td>\n",
       "      <td>this also can block the girl's future developm...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Part Of Speech tags: DET, ADV, VERB, VERB, DET...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>How is the component best described?: \"MajorCl...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "      <td>Which of these choices best describes the foll...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_nr component_id   label_and_comp_idxs  \\\n",
       "0     essay004           T1    MajorClaim 262 376   \n",
       "1     essay004           T2  MajorClaim 1663 1758   \n",
       "2     essay004           T3         Claim 179 239   \n",
       "3     essay004           T4        Claim 953 1031   \n",
       "4     essay004           T5       Claim 1578 1624   \n",
       "...        ...          ...                   ...   \n",
       "1255  essay398          T12       Claim 1484 1589   \n",
       "1256  essay398          T13     Premise 1595 1648   \n",
       "1257  essay398          T14     Premise 1650 1734   \n",
       "1258  essay398          T15     Premise 1349 1388   \n",
       "1259  essay398          T16     Premise 1394 1463   \n",
       "\n",
       "                                                   text     label_x  \\\n",
       "0     this industry has affected the cultural attrib...  MajorClaim   \n",
       "1     the tourism has created threatening pressure o...  MajorClaim   \n",
       "2     the tourism bring large profit for the destina...       Claim   \n",
       "3     international tourism can create negative impa...       Claim   \n",
       "4        tourism has threatened the nature environments       Claim   \n",
       "...                                                 ...         ...   \n",
       "1255  universities should encourage more girls to ch...       Claim   \n",
       "1256  this could avoid imbalance of gender in some s...     Premise   \n",
       "1257  It would affect students' mental health to stu...     Premise   \n",
       "1258            she is unlikely to focus on her subject     Premise   \n",
       "1259  this also can block the girl's future developm...     Premise   \n",
       "\n",
       "     label_ComponentType relation_SupportAttack label_RelationType  \\\n",
       "0             MajorClaim                     []                      \n",
       "1             MajorClaim                     []                      \n",
       "2                  Claim                     []             Attack   \n",
       "3                  Claim                     []            Support   \n",
       "4                  Claim                     []            Support   \n",
       "...                  ...                    ...                ...   \n",
       "1255               Claim                     []            Support   \n",
       "1256             Premise                     []            Support   \n",
       "1257             Premise                     []            Support   \n",
       "1258             Premise                     []            Support   \n",
       "1259             Premise                     []            Support   \n",
       "\n",
       "     label_LinkedNotLinked split  ...  \\\n",
       "0                   Linked  TEST  ...   \n",
       "1                   Linked  TEST  ...   \n",
       "2                NotLinked  TEST  ...   \n",
       "3                   Linked  TEST  ...   \n",
       "4                   Linked  TEST  ...   \n",
       "...                    ...   ...  ...   \n",
       "1255                Linked  TEST  ...   \n",
       "1256             NotLinked  TEST  ...   \n",
       "1257             NotLinked  TEST  ...   \n",
       "1258             NotLinked  TEST  ...   \n",
       "1259             NotLinked  TEST  ...   \n",
       "\n",
       "                        structural_fts_as_text_combined  para_ratio  \\\n",
       "0     Topic: International tourism is now more commo...        0.25   \n",
       "1     Topic: International tourism is now more commo...        1.00   \n",
       "2     Topic: International tourism is now more commo...        0.25   \n",
       "3     Topic: International tourism is now more commo...        0.50   \n",
       "4     Topic: International tourism is now more commo...        0.75   \n",
       "...                                                 ...         ...   \n",
       "1255  Topic: We can not forcedly put the same number...        0.80   \n",
       "1256  Topic: We can not forcedly put the same number...        0.80   \n",
       "1257  Topic: We can not forcedly put the same number...        0.80   \n",
       "1258  Topic: We can not forcedly put the same number...        0.60   \n",
       "1259  Topic: We can not forcedly put the same number...        0.60   \n",
       "\n",
       "      first_or_last                      strct_fts_w_position_in_essay  \\\n",
       "0                 1  Topic: International tourism is now more commo...   \n",
       "1                 1  Topic: International tourism is now more commo...   \n",
       "2                 1  Topic: International tourism is now more commo...   \n",
       "3                 0  Topic: International tourism is now more commo...   \n",
       "4                 0  Topic: International tourism is now more commo...   \n",
       "...             ...                                                ...   \n",
       "1255              0  Topic: We can not forcedly put the same number...   \n",
       "1256              0  Topic: We can not forcedly put the same number...   \n",
       "1257              0  Topic: We can not forcedly put the same number...   \n",
       "1258              0  Topic: We can not forcedly put the same number...   \n",
       "1259              0  Topic: We can not forcedly put the same number...   \n",
       "\n",
       "                                     component_pos_tags  \\\n",
       "0     Part Of Speech tags: DET, NOUN, AUX, VERB, DET...   \n",
       "1     Part Of Speech tags: DET, NOUN, AUX, VERB, VER...   \n",
       "2     Part Of Speech tags: DET, NOUN, VERB, ADJ, NOU...   \n",
       "3     Part Of Speech tags: ADJ, NOUN, VERB, VERB, AD...   \n",
       "4     Part Of Speech tags: NOUN, AUX, VERB, DET, NOU...   \n",
       "...                                                 ...   \n",
       "1255  Part Of Speech tags: NOUN, VERB, VERB, ADJ, NO...   \n",
       "1256  Part Of Speech tags: DET, VERB, VERB, NOUN, AD...   \n",
       "1257  Part Of Speech tags: PRON, VERB, VERB, NOUN, P...   \n",
       "1258  Part Of Speech tags: PRON, AUX, ADJ, PART, VER...   \n",
       "1259  Part Of Speech tags: DET, ADV, VERB, VERB, DET...   \n",
       "\n",
       "                      strct_fts_essay_position_pos_tags  \\\n",
       "0     Topic: International tourism is now more commo...   \n",
       "1     Topic: International tourism is now more commo...   \n",
       "2     Topic: International tourism is now more commo...   \n",
       "3     Topic: International tourism is now more commo...   \n",
       "4     Topic: International tourism is now more commo...   \n",
       "...                                                 ...   \n",
       "1255  Topic: We can not forcedly put the same number...   \n",
       "1256  Topic: We can not forcedly put the same number...   \n",
       "1257  Topic: We can not forcedly put the same number...   \n",
       "1258  Topic: We can not forcedly put the same number...   \n",
       "1259  Topic: We can not forcedly put the same number...   \n",
       "\n",
       "                              prompted_representation_2  \\\n",
       "0     Which of these choices best describes the foll...   \n",
       "1     Which of these choices best describes the foll...   \n",
       "2     Which of these choices best describes the foll...   \n",
       "3     Which of these choices best describes the foll...   \n",
       "4     Which of these choices best describes the foll...   \n",
       "...                                                 ...   \n",
       "1255  Which of these choices best describes the foll...   \n",
       "1256  Which of these choices best describes the foll...   \n",
       "1257  Which of these choices best describes the foll...   \n",
       "1258  Which of these choices best describes the foll...   \n",
       "1259  Which of these choices best describes the foll...   \n",
       "\n",
       "                              prompted_representation_3  \\\n",
       "0     How is the component best described?: \"MajorCl...   \n",
       "1     How is the component best described?: \"MajorCl...   \n",
       "2     How is the component best described?: \"MajorCl...   \n",
       "3     How is the component best described?: \"MajorCl...   \n",
       "4     How is the component best described?: \"MajorCl...   \n",
       "...                                                 ...   \n",
       "1255  How is the component best described?: \"MajorCl...   \n",
       "1256  How is the component best described?: \"MajorCl...   \n",
       "1257  How is the component best described?: \"MajorCl...   \n",
       "1258  How is the component best described?: \"MajorCl...   \n",
       "1259  How is the component best described?: \"MajorCl...   \n",
       "\n",
       "                              prompted_rep_2_w_modif_MC  \\\n",
       "0     Which of these choices best describes the foll...   \n",
       "1     Which of these choices best describes the foll...   \n",
       "2     Which of these choices best describes the foll...   \n",
       "3     Which of these choices best describes the foll...   \n",
       "4     Which of these choices best describes the foll...   \n",
       "...                                                 ...   \n",
       "1255  Which of these choices best describes the foll...   \n",
       "1256  Which of these choices best describes the foll...   \n",
       "1257  Which of these choices best describes the foll...   \n",
       "1258  Which of these choices best describes the foll...   \n",
       "1259  Which of these choices best describes the foll...   \n",
       "\n",
       "                    prompted_rep_2_w_modif_MC_corrected  \n",
       "0     Which of these choices best describes the foll...  \n",
       "1     Which of these choices best describes the foll...  \n",
       "2     Which of these choices best describes the foll...  \n",
       "3     Which of these choices best describes the foll...  \n",
       "4     Which of these choices best describes the foll...  \n",
       "...                                                 ...  \n",
       "1255  Which of these choices best describes the foll...  \n",
       "1256  Which of these choices best describes the foll...  \n",
       "1257  Which of these choices best describes the foll...  \n",
       "1258  Which of these choices best describes the foll...  \n",
       "1259  Which of these choices best describes the foll...  \n",
       "\n",
       "[1260 rows x 43 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "511edf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['masked_representation_2_for_pipeline'] = df_test.apply(lambda x: get_masked_components(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "195da7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which of these choices best describes the following component? \"Stance\", \"Claim\" or \"Premise\". Component: Topic: International tourism is now more common than ever before, Sentence: While some might think the tourism bring large profit for the destination countries, I would contend that this industry has affected the cultural attributes and damaged the natural environment of the tourist destinations., First or last in essay: Yes, First in paragraph: No, Last in paragraph: Yes, In in introduction: Yes, Is in conclusion: No. Part Of Speech tags: DET, NOUN, AUX, VERB, DET, ADJ, NOUN, CCONJ, VERB, DET, ADJ, NOUN, ADP, DET, NOUN, NOUN. [MASK].'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['masked_representation_2_for_pipeline'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "98f09af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok now do a sanity check to see that they are done correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "833da900",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_tokens_mask_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7fbc9c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_token(x):\n",
    "    \n",
    "    prompted_rep = x.masked_representation_2_for_pipeline\n",
    "    \n",
    "    last_token = prompted_rep.split()[-1]\n",
    "    \n",
    "    last_tokens_mask_list.append(last_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e5f22e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       None\n",
       "1       None\n",
       "2       None\n",
       "3       None\n",
       "4       None\n",
       "        ... \n",
       "1255    None\n",
       "1256    None\n",
       "1257    None\n",
       "1258    None\n",
       "1259    None\n",
       "Length: 1260, dtype: object"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.apply(lambda x: get_last_token(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f7f40cab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " '[MASK].',\n",
       " ...]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_tokens_mask_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "706331e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[MASK].'}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(last_tokens_mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "eeba55ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### YASSSSS SIRRRRRRRRRRR # correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "aab508f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok now see how we can give all these 1260 statements to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "35be15d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_components_list = df_test['masked_representation_2_for_pipeline'][:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "90ad64f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_components_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9785b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok now give it to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f54b3e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling tokenizer parallelism, we're using DataLoader multithreading already\n"
     ]
    }
   ],
   "source": [
    "classifier_output = classifier(test_components_list, targets=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7c9a47cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11032"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_output[0][0]['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "44206e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_test = []\n",
    "\n",
    "for idx in range(1260):\n",
    "    \n",
    "    predicted_token = classifier_output[idx][0]['token']\n",
    "    predicted_labels_test.append(predicted_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3adcc83c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7ccbafba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4366, 11032, 18458}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "set(predicted_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4ca1656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3377366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_str = df_test.label_ComponentType[:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "cdfb03c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'MajorClaim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'MajorClaim',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Claim',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " 'Premise',\n",
       " ...]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1bebe197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Claim', 'MajorClaim', 'Premise'}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "93c3549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_int = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "351219e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_int_labels():\n",
    "    \n",
    "    for idx, val in enumerate(test_labels_str):\n",
    "        \n",
    "        if val == 'MajorClaim':\n",
    "            \n",
    "            test_labels_int.append(11032)\n",
    "            \n",
    "        elif val == 'Claim':\n",
    "            \n",
    "            test_labels_int.append(4366)\n",
    "            \n",
    "        elif val == 'Premise':\n",
    "            \n",
    "            test_labels_int.append(18458)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2eea95bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_int_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c387df16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 4366,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 4366,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 11032,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 11032,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 11032,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 11032,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 4366,\n",
       " 11032,\n",
       " 11032,\n",
       " 11032,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 11032,\n",
       " 18458,\n",
       " 4366,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 4366,\n",
       " 11032,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 4366,\n",
       " 11032,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 11032,\n",
       " 11032,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 11032,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 4366,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 4366,\n",
       " 11032,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 11032,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 11032,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 4366,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " 18458,\n",
       " ...]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "0addd002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1a1d141a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4366, 11032, 18458}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_labels_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "986244d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b16df288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "0bcb16ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        4366      0.668     0.685     0.676       302\n",
      "       11032      0.767     0.948     0.848       153\n",
      "       18458      0.928     0.877     0.902       805\n",
      "\n",
      "    accuracy                          0.840      1260\n",
      "   macro avg      0.788     0.837     0.809      1260\n",
      "weighted avg      0.846     0.840     0.841      1260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels_int, predicted_labels_test, digits=3))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20f04887",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "        4366      0.668     0.685     0.676       302\n",
    "       11032      0.767     0.948     0.848       153\n",
    "       18458      0.928     0.877     0.902       805\n",
    "\n",
    "    accuracy                          0.840      1260\n",
    "   macro avg      0.788     0.837     0.809      1260\n",
    "weighted avg      0.846     0.840     0.841      1260\n",
    "\n",
    "prompt representation 2 with pipeline."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a214c6ce",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "        4366      0.661     0.536     0.592       302\n",
    "       11032      0.756     0.869     0.809       153\n",
    "       18458      0.881     0.918     0.899       805\n",
    "\n",
    "    accuracy                          0.821      1260\n",
    "   macro avg      0.766     0.775     0.767      1260\n",
    "weighted avg      0.813     0.821     0.815      1260\n",
    "\n",
    "old results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "60b4ae02",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "        4366      0.658     0.586     0.620       302\n",
    "       11032      0.723     0.954     0.823       153\n",
    "       18458      0.909     0.891     0.900       805\n",
    "\n",
    "    accuracy                          0.825      1260\n",
    "   macro avg      0.763     0.810     0.781      1260\n",
    "weighted avg      0.826     0.825     0.823      1260"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
