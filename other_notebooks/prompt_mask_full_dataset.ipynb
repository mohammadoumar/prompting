{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0781458d",
   "metadata": {},
   "source": [
    "# BERT masked model on the full PE dataset\n",
    "### try to check if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3229dc5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.21.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2021.10.8)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.0.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.28.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.2)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (58.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: IProgress in /opt/conda/lib/python3.8/site-packages (0.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from IProgress) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install ipywidgets\n",
    "!pip install IProgress\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "818cf1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecfdb664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5afbaf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4babd8",
   "metadata": {},
   "source": [
    "### make the train, test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe546f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"/notebooks/Prompting/dataset/pe_dataset_w_prompts_1_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c14e99c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sans_mc = df[df.label_ComponentType != 'MajorClaim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6cbf741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_nr</th>\n",
       "      <th>component_id</th>\n",
       "      <th>label_and_comp_idxs</th>\n",
       "      <th>text</th>\n",
       "      <th>label_x</th>\n",
       "      <th>label_ComponentType</th>\n",
       "      <th>relation_SupportAttack</th>\n",
       "      <th>label_RelationType</th>\n",
       "      <th>label_LinkedNotLinked</th>\n",
       "      <th>split</th>\n",
       "      <th>...</th>\n",
       "      <th>nr_preceeding_comps_in_para</th>\n",
       "      <th>nr_following_comps_in_para</th>\n",
       "      <th>structural_fts_as_text</th>\n",
       "      <th>structural_fts_as_text_combined</th>\n",
       "      <th>para_ratio</th>\n",
       "      <th>first_or_last</th>\n",
       "      <th>strct_fts_w_position_in_essay</th>\n",
       "      <th>component_pos_tags</th>\n",
       "      <th>strct_fts_essay_position_pos_tags</th>\n",
       "      <th>prompted_representation_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T3</td>\n",
       "      <td>Claim 591 714</td>\n",
       "      <td>through cooperation, children can learn about ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: ADP, NOUN, PUNCT, NOUN, V...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T4</td>\n",
       "      <td>Premise 716 851</td>\n",
       "      <td>What we acquired from team work is not only ho...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: PRON, PRON, VERB, ADP, NO...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T5</td>\n",
       "      <td>Premise 853 1086</td>\n",
       "      <td>During the process of cooperation, children ca...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: ADP, DET, NOUN, ADP, NOUN...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T6</td>\n",
       "      <td>Premise 1088 1191</td>\n",
       "      <td>All of these skills help them to get on well w...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: DET, ADP, DET, NOUN, VERB...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T7</td>\n",
       "      <td>Claim 1332 1376</td>\n",
       "      <td>competition makes the society more effective</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Attack</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: NOUN, VERB, DET, NOUN, AD...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5968</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T11</td>\n",
       "      <td>Premise 1275 1339</td>\n",
       "      <td>indirectly they will learn how to socialize ea...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: ADV, PRON, VERB, VERB, AD...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5969</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T12</td>\n",
       "      <td>Premise 1341 1388</td>\n",
       "      <td>That will make children getting lots of friends</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: DET, VERB, VERB, NOUN, VE...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T13</td>\n",
       "      <td>Premise 1393 1436</td>\n",
       "      <td>they can contribute positively to community</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: PRON, VERB, VERB, ADV, AD...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5971</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T14</td>\n",
       "      <td>Premise 1448 1525</td>\n",
       "      <td>playing sport makes children getting healthy a...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: VERB, NOUN, VERB, NOUN, V...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T15</td>\n",
       "      <td>Claim 916 965</td>\n",
       "      <td>playing sports will give good effects on children</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: VERB, NOUN, VERB, VERB, A...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5239 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_nr component_id label_and_comp_idxs  \\\n",
       "2     essay001           T3       Claim 591 714   \n",
       "3     essay001           T4     Premise 716 851   \n",
       "4     essay001           T5    Premise 853 1086   \n",
       "5     essay001           T6   Premise 1088 1191   \n",
       "6     essay001           T7     Claim 1332 1376   \n",
       "...        ...          ...                 ...   \n",
       "5968  essay402          T11   Premise 1275 1339   \n",
       "5969  essay402          T12   Premise 1341 1388   \n",
       "5970  essay402          T13   Premise 1393 1436   \n",
       "5971  essay402          T14   Premise 1448 1525   \n",
       "5972  essay402          T15       Claim 916 965   \n",
       "\n",
       "                                                   text  label_x  \\\n",
       "2     through cooperation, children can learn about ...    Claim   \n",
       "3     What we acquired from team work is not only ho...  Premise   \n",
       "4     During the process of cooperation, children ca...  Premise   \n",
       "5     All of these skills help them to get on well w...  Premise   \n",
       "6          competition makes the society more effective    Claim   \n",
       "...                                                 ...      ...   \n",
       "5968  indirectly they will learn how to socialize ea...  Premise   \n",
       "5969    That will make children getting lots of friends  Premise   \n",
       "5970        they can contribute positively to community  Premise   \n",
       "5971  playing sport makes children getting healthy a...  Premise   \n",
       "5972  playing sports will give good effects on children    Claim   \n",
       "\n",
       "     label_ComponentType relation_SupportAttack label_RelationType  \\\n",
       "2                  Claim                     []            Support   \n",
       "3                Premise                     []            Support   \n",
       "4                Premise                     []            Support   \n",
       "5                Premise                     []            Support   \n",
       "6                  Claim                     []             Attack   \n",
       "...                  ...                    ...                ...   \n",
       "5968             Premise                     []            Support   \n",
       "5969             Premise                     []            Support   \n",
       "5970             Premise                     []            Support   \n",
       "5971             Premise                     []            Support   \n",
       "5972               Claim                     []            Support   \n",
       "\n",
       "     label_LinkedNotLinked  split  ... nr_preceeding_comps_in_para  \\\n",
       "2                   Linked  TRAIN  ...                           0   \n",
       "3                NotLinked  TRAIN  ...                           1   \n",
       "4                NotLinked  TRAIN  ...                           2   \n",
       "5                NotLinked  TRAIN  ...                           3   \n",
       "6                   Linked  TRAIN  ...                           1   \n",
       "...                    ...    ...  ...                         ...   \n",
       "5968             NotLinked  TRAIN  ...                           4   \n",
       "5969             NotLinked  TRAIN  ...                           5   \n",
       "5970                Linked  TRAIN  ...                           6   \n",
       "5971             NotLinked  TRAIN  ...                           7   \n",
       "5972                Linked  TRAIN  ...                           0   \n",
       "\n",
       "      nr_following_comps_in_para  \\\n",
       "2                              3   \n",
       "3                              2   \n",
       "4                              1   \n",
       "5                              0   \n",
       "6                              3   \n",
       "...                          ...   \n",
       "5968                           3   \n",
       "5969                           2   \n",
       "5970                           1   \n",
       "5971                           0   \n",
       "5972                           7   \n",
       "\n",
       "                                 structural_fts_as_text  \\\n",
       "2     Topic: Should students be taught to compete or...   \n",
       "3     Topic: Should students be taught to compete or...   \n",
       "4     Topic: Should students be taught to compete or...   \n",
       "5     Topic: Should students be taught to compete or...   \n",
       "6     Topic: Should students be taught to compete or...   \n",
       "...                                                 ...   \n",
       "5968  Topic: Children should studying hard or playin...   \n",
       "5969  Topic: Children should studying hard or playin...   \n",
       "5970  Topic: Children should studying hard or playin...   \n",
       "5971  Topic: Children should studying hard or playin...   \n",
       "5972  Topic: Children should studying hard or playin...   \n",
       "\n",
       "                        structural_fts_as_text_combined para_ratio  \\\n",
       "2     Topic: Should students be taught to compete or...       0.50   \n",
       "3     Topic: Should students be taught to compete or...       0.50   \n",
       "4     Topic: Should students be taught to compete or...       0.50   \n",
       "5     Topic: Should students be taught to compete or...       0.50   \n",
       "6     Topic: Should students be taught to compete or...       0.75   \n",
       "...                                                 ...        ...   \n",
       "5968  Topic: Children should studying hard or playin...       0.75   \n",
       "5969  Topic: Children should studying hard or playin...       0.75   \n",
       "5970  Topic: Children should studying hard or playin...       0.75   \n",
       "5971  Topic: Children should studying hard or playin...       0.75   \n",
       "5972  Topic: Children should studying hard or playin...       0.75   \n",
       "\n",
       "     first_or_last                      strct_fts_w_position_in_essay  \\\n",
       "2                0  Topic: Should students be taught to compete or...   \n",
       "3                0  Topic: Should students be taught to compete or...   \n",
       "4                0  Topic: Should students be taught to compete or...   \n",
       "5                0  Topic: Should students be taught to compete or...   \n",
       "6                0  Topic: Should students be taught to compete or...   \n",
       "...            ...                                                ...   \n",
       "5968             0  Topic: Children should studying hard or playin...   \n",
       "5969             0  Topic: Children should studying hard or playin...   \n",
       "5970             0  Topic: Children should studying hard or playin...   \n",
       "5971             0  Topic: Children should studying hard or playin...   \n",
       "5972             0  Topic: Children should studying hard or playin...   \n",
       "\n",
       "                                     component_pos_tags  \\\n",
       "2     Part Of Speech tags: ADP, NOUN, PUNCT, NOUN, V...   \n",
       "3     Part Of Speech tags: PRON, PRON, VERB, ADP, NO...   \n",
       "4     Part Of Speech tags: ADP, DET, NOUN, ADP, NOUN...   \n",
       "5     Part Of Speech tags: DET, ADP, DET, NOUN, VERB...   \n",
       "6     Part Of Speech tags: NOUN, VERB, DET, NOUN, AD...   \n",
       "...                                                 ...   \n",
       "5968  Part Of Speech tags: ADV, PRON, VERB, VERB, AD...   \n",
       "5969  Part Of Speech tags: DET, VERB, VERB, NOUN, VE...   \n",
       "5970  Part Of Speech tags: PRON, VERB, VERB, ADV, AD...   \n",
       "5971  Part Of Speech tags: VERB, NOUN, VERB, NOUN, V...   \n",
       "5972  Part Of Speech tags: VERB, NOUN, VERB, VERB, A...   \n",
       "\n",
       "                      strct_fts_essay_position_pos_tags  \\\n",
       "2     Topic: Should students be taught to compete or...   \n",
       "3     Topic: Should students be taught to compete or...   \n",
       "4     Topic: Should students be taught to compete or...   \n",
       "5     Topic: Should students be taught to compete or...   \n",
       "6     Topic: Should students be taught to compete or...   \n",
       "...                                                 ...   \n",
       "5968  Topic: Children should studying hard or playin...   \n",
       "5969  Topic: Children should studying hard or playin...   \n",
       "5970  Topic: Children should studying hard or playin...   \n",
       "5971  Topic: Children should studying hard or playin...   \n",
       "5972  Topic: Children should studying hard or playin...   \n",
       "\n",
       "                              prompted_representation_1  \n",
       "2     Component: Topic: Should students be taught to...  \n",
       "3     Component: Topic: Should students be taught to...  \n",
       "4     Component: Topic: Should students be taught to...  \n",
       "5     Component: Topic: Should students be taught to...  \n",
       "6     Component: Topic: Should students be taught to...  \n",
       "...                                                 ...  \n",
       "5968  Component: Topic: Children should studying har...  \n",
       "5969  Component: Topic: Children should studying har...  \n",
       "5970  Component: Topic: Children should studying har...  \n",
       "5971  Component: Topic: Children should studying har...  \n",
       "5972  Component: Topic: Children should studying har...  \n",
       "\n",
       "[5239 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sans_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f69985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sans_mc = df_sans_mc.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "847a130a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_nr</th>\n",
       "      <th>component_id</th>\n",
       "      <th>label_and_comp_idxs</th>\n",
       "      <th>text</th>\n",
       "      <th>label_x</th>\n",
       "      <th>label_ComponentType</th>\n",
       "      <th>relation_SupportAttack</th>\n",
       "      <th>label_RelationType</th>\n",
       "      <th>label_LinkedNotLinked</th>\n",
       "      <th>split</th>\n",
       "      <th>...</th>\n",
       "      <th>nr_preceeding_comps_in_para</th>\n",
       "      <th>nr_following_comps_in_para</th>\n",
       "      <th>structural_fts_as_text</th>\n",
       "      <th>structural_fts_as_text_combined</th>\n",
       "      <th>para_ratio</th>\n",
       "      <th>first_or_last</th>\n",
       "      <th>strct_fts_w_position_in_essay</th>\n",
       "      <th>component_pos_tags</th>\n",
       "      <th>strct_fts_essay_position_pos_tags</th>\n",
       "      <th>prompted_representation_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T3</td>\n",
       "      <td>Claim 591 714</td>\n",
       "      <td>through cooperation, children can learn about ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: ADP, NOUN, PUNCT, NOUN, V...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T4</td>\n",
       "      <td>Premise 716 851</td>\n",
       "      <td>What we acquired from team work is not only ho...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: PRON, PRON, VERB, ADP, NO...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T5</td>\n",
       "      <td>Premise 853 1086</td>\n",
       "      <td>During the process of cooperation, children ca...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: ADP, DET, NOUN, ADP, NOUN...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T6</td>\n",
       "      <td>Premise 1088 1191</td>\n",
       "      <td>All of these skills help them to get on well w...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: DET, ADP, DET, NOUN, VERB...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T7</td>\n",
       "      <td>Claim 1332 1376</td>\n",
       "      <td>competition makes the society more effective</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Attack</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: NOUN, VERB, DET, NOUN, AD...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5234</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T11</td>\n",
       "      <td>Premise 1275 1339</td>\n",
       "      <td>indirectly they will learn how to socialize ea...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: ADV, PRON, VERB, VERB, AD...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5235</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T12</td>\n",
       "      <td>Premise 1341 1388</td>\n",
       "      <td>That will make children getting lots of friends</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: DET, VERB, VERB, NOUN, VE...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5236</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T13</td>\n",
       "      <td>Premise 1393 1436</td>\n",
       "      <td>they can contribute positively to community</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: PRON, VERB, VERB, ADV, AD...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T14</td>\n",
       "      <td>Premise 1448 1525</td>\n",
       "      <td>playing sport makes children getting healthy a...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: VERB, NOUN, VERB, NOUN, V...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T15</td>\n",
       "      <td>Claim 916 965</td>\n",
       "      <td>playing sports will give good effects on children</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: VERB, NOUN, VERB, VERB, A...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5239 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_nr component_id label_and_comp_idxs  \\\n",
       "0     essay001           T3       Claim 591 714   \n",
       "1     essay001           T4     Premise 716 851   \n",
       "2     essay001           T5    Premise 853 1086   \n",
       "3     essay001           T6   Premise 1088 1191   \n",
       "4     essay001           T7     Claim 1332 1376   \n",
       "...        ...          ...                 ...   \n",
       "5234  essay402          T11   Premise 1275 1339   \n",
       "5235  essay402          T12   Premise 1341 1388   \n",
       "5236  essay402          T13   Premise 1393 1436   \n",
       "5237  essay402          T14   Premise 1448 1525   \n",
       "5238  essay402          T15       Claim 916 965   \n",
       "\n",
       "                                                   text  label_x  \\\n",
       "0     through cooperation, children can learn about ...    Claim   \n",
       "1     What we acquired from team work is not only ho...  Premise   \n",
       "2     During the process of cooperation, children ca...  Premise   \n",
       "3     All of these skills help them to get on well w...  Premise   \n",
       "4          competition makes the society more effective    Claim   \n",
       "...                                                 ...      ...   \n",
       "5234  indirectly they will learn how to socialize ea...  Premise   \n",
       "5235    That will make children getting lots of friends  Premise   \n",
       "5236        they can contribute positively to community  Premise   \n",
       "5237  playing sport makes children getting healthy a...  Premise   \n",
       "5238  playing sports will give good effects on children    Claim   \n",
       "\n",
       "     label_ComponentType relation_SupportAttack label_RelationType  \\\n",
       "0                  Claim                     []            Support   \n",
       "1                Premise                     []            Support   \n",
       "2                Premise                     []            Support   \n",
       "3                Premise                     []            Support   \n",
       "4                  Claim                     []             Attack   \n",
       "...                  ...                    ...                ...   \n",
       "5234             Premise                     []            Support   \n",
       "5235             Premise                     []            Support   \n",
       "5236             Premise                     []            Support   \n",
       "5237             Premise                     []            Support   \n",
       "5238               Claim                     []            Support   \n",
       "\n",
       "     label_LinkedNotLinked  split  ... nr_preceeding_comps_in_para  \\\n",
       "0                   Linked  TRAIN  ...                           0   \n",
       "1                NotLinked  TRAIN  ...                           1   \n",
       "2                NotLinked  TRAIN  ...                           2   \n",
       "3                NotLinked  TRAIN  ...                           3   \n",
       "4                   Linked  TRAIN  ...                           1   \n",
       "...                    ...    ...  ...                         ...   \n",
       "5234             NotLinked  TRAIN  ...                           4   \n",
       "5235             NotLinked  TRAIN  ...                           5   \n",
       "5236                Linked  TRAIN  ...                           6   \n",
       "5237             NotLinked  TRAIN  ...                           7   \n",
       "5238                Linked  TRAIN  ...                           0   \n",
       "\n",
       "      nr_following_comps_in_para  \\\n",
       "0                              3   \n",
       "1                              2   \n",
       "2                              1   \n",
       "3                              0   \n",
       "4                              3   \n",
       "...                          ...   \n",
       "5234                           3   \n",
       "5235                           2   \n",
       "5236                           1   \n",
       "5237                           0   \n",
       "5238                           7   \n",
       "\n",
       "                                 structural_fts_as_text  \\\n",
       "0     Topic: Should students be taught to compete or...   \n",
       "1     Topic: Should students be taught to compete or...   \n",
       "2     Topic: Should students be taught to compete or...   \n",
       "3     Topic: Should students be taught to compete or...   \n",
       "4     Topic: Should students be taught to compete or...   \n",
       "...                                                 ...   \n",
       "5234  Topic: Children should studying hard or playin...   \n",
       "5235  Topic: Children should studying hard or playin...   \n",
       "5236  Topic: Children should studying hard or playin...   \n",
       "5237  Topic: Children should studying hard or playin...   \n",
       "5238  Topic: Children should studying hard or playin...   \n",
       "\n",
       "                        structural_fts_as_text_combined para_ratio  \\\n",
       "0     Topic: Should students be taught to compete or...       0.50   \n",
       "1     Topic: Should students be taught to compete or...       0.50   \n",
       "2     Topic: Should students be taught to compete or...       0.50   \n",
       "3     Topic: Should students be taught to compete or...       0.50   \n",
       "4     Topic: Should students be taught to compete or...       0.75   \n",
       "...                                                 ...        ...   \n",
       "5234  Topic: Children should studying hard or playin...       0.75   \n",
       "5235  Topic: Children should studying hard or playin...       0.75   \n",
       "5236  Topic: Children should studying hard or playin...       0.75   \n",
       "5237  Topic: Children should studying hard or playin...       0.75   \n",
       "5238  Topic: Children should studying hard or playin...       0.75   \n",
       "\n",
       "     first_or_last                      strct_fts_w_position_in_essay  \\\n",
       "0                0  Topic: Should students be taught to compete or...   \n",
       "1                0  Topic: Should students be taught to compete or...   \n",
       "2                0  Topic: Should students be taught to compete or...   \n",
       "3                0  Topic: Should students be taught to compete or...   \n",
       "4                0  Topic: Should students be taught to compete or...   \n",
       "...            ...                                                ...   \n",
       "5234             0  Topic: Children should studying hard or playin...   \n",
       "5235             0  Topic: Children should studying hard or playin...   \n",
       "5236             0  Topic: Children should studying hard or playin...   \n",
       "5237             0  Topic: Children should studying hard or playin...   \n",
       "5238             0  Topic: Children should studying hard or playin...   \n",
       "\n",
       "                                     component_pos_tags  \\\n",
       "0     Part Of Speech tags: ADP, NOUN, PUNCT, NOUN, V...   \n",
       "1     Part Of Speech tags: PRON, PRON, VERB, ADP, NO...   \n",
       "2     Part Of Speech tags: ADP, DET, NOUN, ADP, NOUN...   \n",
       "3     Part Of Speech tags: DET, ADP, DET, NOUN, VERB...   \n",
       "4     Part Of Speech tags: NOUN, VERB, DET, NOUN, AD...   \n",
       "...                                                 ...   \n",
       "5234  Part Of Speech tags: ADV, PRON, VERB, VERB, AD...   \n",
       "5235  Part Of Speech tags: DET, VERB, VERB, NOUN, VE...   \n",
       "5236  Part Of Speech tags: PRON, VERB, VERB, ADV, AD...   \n",
       "5237  Part Of Speech tags: VERB, NOUN, VERB, NOUN, V...   \n",
       "5238  Part Of Speech tags: VERB, NOUN, VERB, VERB, A...   \n",
       "\n",
       "                      strct_fts_essay_position_pos_tags  \\\n",
       "0     Topic: Should students be taught to compete or...   \n",
       "1     Topic: Should students be taught to compete or...   \n",
       "2     Topic: Should students be taught to compete or...   \n",
       "3     Topic: Should students be taught to compete or...   \n",
       "4     Topic: Should students be taught to compete or...   \n",
       "...                                                 ...   \n",
       "5234  Topic: Children should studying hard or playin...   \n",
       "5235  Topic: Children should studying hard or playin...   \n",
       "5236  Topic: Children should studying hard or playin...   \n",
       "5237  Topic: Children should studying hard or playin...   \n",
       "5238  Topic: Children should studying hard or playin...   \n",
       "\n",
       "                              prompted_representation_1  \n",
       "0     Component: Topic: Should students be taught to...  \n",
       "1     Component: Topic: Should students be taught to...  \n",
       "2     Component: Topic: Should students be taught to...  \n",
       "3     Component: Topic: Should students be taught to...  \n",
       "4     Component: Topic: Should students be taught to...  \n",
       "...                                                 ...  \n",
       "5234  Component: Topic: Children should studying har...  \n",
       "5235  Component: Topic: Children should studying har...  \n",
       "5236  Component: Topic: Children should studying har...  \n",
       "5237  Component: Topic: Children should studying har...  \n",
       "5238  Component: Topic: Children should studying har...  \n",
       "\n",
       "[5239 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sans_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58f67880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Premise    3763\n",
       "Claim      1476\n",
       "Name: label_ComponentType, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sans_mc.label_ComponentType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1999b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9bc4a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRAIN    4132\n",
       "TEST     1107\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sans_mc.split.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e675a21e",
   "metadata": {},
   "source": [
    "### get the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59690943",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d656608",
   "metadata": {},
   "source": [
    "## make train, test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0190122",
   "metadata": {},
   "source": [
    "### train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58d74245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_sans_mc[df_sans_mc.split == 'TRAIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b9a729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b66013a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_nr</th>\n",
       "      <th>component_id</th>\n",
       "      <th>label_and_comp_idxs</th>\n",
       "      <th>text</th>\n",
       "      <th>label_x</th>\n",
       "      <th>label_ComponentType</th>\n",
       "      <th>relation_SupportAttack</th>\n",
       "      <th>label_RelationType</th>\n",
       "      <th>label_LinkedNotLinked</th>\n",
       "      <th>split</th>\n",
       "      <th>...</th>\n",
       "      <th>nr_preceeding_comps_in_para</th>\n",
       "      <th>nr_following_comps_in_para</th>\n",
       "      <th>structural_fts_as_text</th>\n",
       "      <th>structural_fts_as_text_combined</th>\n",
       "      <th>para_ratio</th>\n",
       "      <th>first_or_last</th>\n",
       "      <th>strct_fts_w_position_in_essay</th>\n",
       "      <th>component_pos_tags</th>\n",
       "      <th>strct_fts_essay_position_pos_tags</th>\n",
       "      <th>prompted_representation_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T3</td>\n",
       "      <td>Claim 591 714</td>\n",
       "      <td>through cooperation, children can learn about ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: ADP, NOUN, PUNCT, NOUN, V...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T4</td>\n",
       "      <td>Premise 716 851</td>\n",
       "      <td>What we acquired from team work is not only ho...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: PRON, PRON, VERB, ADP, NO...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T5</td>\n",
       "      <td>Premise 853 1086</td>\n",
       "      <td>During the process of cooperation, children ca...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: ADP, DET, NOUN, ADP, NOUN...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T6</td>\n",
       "      <td>Premise 1088 1191</td>\n",
       "      <td>All of these skills help them to get on well w...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: DET, ADP, DET, NOUN, VERB...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T7</td>\n",
       "      <td>Claim 1332 1376</td>\n",
       "      <td>competition makes the society more effective</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Attack</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: NOUN, VERB, DET, NOUN, AD...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4127</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T11</td>\n",
       "      <td>Premise 1275 1339</td>\n",
       "      <td>indirectly they will learn how to socialize ea...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: ADV, PRON, VERB, VERB, AD...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T12</td>\n",
       "      <td>Premise 1341 1388</td>\n",
       "      <td>That will make children getting lots of friends</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: DET, VERB, VERB, NOUN, VE...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4129</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T13</td>\n",
       "      <td>Premise 1393 1436</td>\n",
       "      <td>they can contribute positively to community</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: PRON, VERB, VERB, ADV, AD...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T14</td>\n",
       "      <td>Premise 1448 1525</td>\n",
       "      <td>playing sport makes children getting healthy a...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: VERB, NOUN, VERB, NOUN, V...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4131</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T15</td>\n",
       "      <td>Claim 916 965</td>\n",
       "      <td>playing sports will give good effects on children</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: VERB, NOUN, VERB, VERB, A...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4132 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_nr component_id label_and_comp_idxs  \\\n",
       "0     essay001           T3       Claim 591 714   \n",
       "1     essay001           T4     Premise 716 851   \n",
       "2     essay001           T5    Premise 853 1086   \n",
       "3     essay001           T6   Premise 1088 1191   \n",
       "4     essay001           T7     Claim 1332 1376   \n",
       "...        ...          ...                 ...   \n",
       "4127  essay402          T11   Premise 1275 1339   \n",
       "4128  essay402          T12   Premise 1341 1388   \n",
       "4129  essay402          T13   Premise 1393 1436   \n",
       "4130  essay402          T14   Premise 1448 1525   \n",
       "4131  essay402          T15       Claim 916 965   \n",
       "\n",
       "                                                   text  label_x  \\\n",
       "0     through cooperation, children can learn about ...    Claim   \n",
       "1     What we acquired from team work is not only ho...  Premise   \n",
       "2     During the process of cooperation, children ca...  Premise   \n",
       "3     All of these skills help them to get on well w...  Premise   \n",
       "4          competition makes the society more effective    Claim   \n",
       "...                                                 ...      ...   \n",
       "4127  indirectly they will learn how to socialize ea...  Premise   \n",
       "4128    That will make children getting lots of friends  Premise   \n",
       "4129        they can contribute positively to community  Premise   \n",
       "4130  playing sport makes children getting healthy a...  Premise   \n",
       "4131  playing sports will give good effects on children    Claim   \n",
       "\n",
       "     label_ComponentType relation_SupportAttack label_RelationType  \\\n",
       "0                  Claim                     []            Support   \n",
       "1                Premise                     []            Support   \n",
       "2                Premise                     []            Support   \n",
       "3                Premise                     []            Support   \n",
       "4                  Claim                     []             Attack   \n",
       "...                  ...                    ...                ...   \n",
       "4127             Premise                     []            Support   \n",
       "4128             Premise                     []            Support   \n",
       "4129             Premise                     []            Support   \n",
       "4130             Premise                     []            Support   \n",
       "4131               Claim                     []            Support   \n",
       "\n",
       "     label_LinkedNotLinked  split  ... nr_preceeding_comps_in_para  \\\n",
       "0                   Linked  TRAIN  ...                           0   \n",
       "1                NotLinked  TRAIN  ...                           1   \n",
       "2                NotLinked  TRAIN  ...                           2   \n",
       "3                NotLinked  TRAIN  ...                           3   \n",
       "4                   Linked  TRAIN  ...                           1   \n",
       "...                    ...    ...  ...                         ...   \n",
       "4127             NotLinked  TRAIN  ...                           4   \n",
       "4128             NotLinked  TRAIN  ...                           5   \n",
       "4129                Linked  TRAIN  ...                           6   \n",
       "4130             NotLinked  TRAIN  ...                           7   \n",
       "4131                Linked  TRAIN  ...                           0   \n",
       "\n",
       "      nr_following_comps_in_para  \\\n",
       "0                              3   \n",
       "1                              2   \n",
       "2                              1   \n",
       "3                              0   \n",
       "4                              3   \n",
       "...                          ...   \n",
       "4127                           3   \n",
       "4128                           2   \n",
       "4129                           1   \n",
       "4130                           0   \n",
       "4131                           7   \n",
       "\n",
       "                                 structural_fts_as_text  \\\n",
       "0     Topic: Should students be taught to compete or...   \n",
       "1     Topic: Should students be taught to compete or...   \n",
       "2     Topic: Should students be taught to compete or...   \n",
       "3     Topic: Should students be taught to compete or...   \n",
       "4     Topic: Should students be taught to compete or...   \n",
       "...                                                 ...   \n",
       "4127  Topic: Children should studying hard or playin...   \n",
       "4128  Topic: Children should studying hard or playin...   \n",
       "4129  Topic: Children should studying hard or playin...   \n",
       "4130  Topic: Children should studying hard or playin...   \n",
       "4131  Topic: Children should studying hard or playin...   \n",
       "\n",
       "                        structural_fts_as_text_combined para_ratio  \\\n",
       "0     Topic: Should students be taught to compete or...       0.50   \n",
       "1     Topic: Should students be taught to compete or...       0.50   \n",
       "2     Topic: Should students be taught to compete or...       0.50   \n",
       "3     Topic: Should students be taught to compete or...       0.50   \n",
       "4     Topic: Should students be taught to compete or...       0.75   \n",
       "...                                                 ...        ...   \n",
       "4127  Topic: Children should studying hard or playin...       0.75   \n",
       "4128  Topic: Children should studying hard or playin...       0.75   \n",
       "4129  Topic: Children should studying hard or playin...       0.75   \n",
       "4130  Topic: Children should studying hard or playin...       0.75   \n",
       "4131  Topic: Children should studying hard or playin...       0.75   \n",
       "\n",
       "     first_or_last                      strct_fts_w_position_in_essay  \\\n",
       "0                0  Topic: Should students be taught to compete or...   \n",
       "1                0  Topic: Should students be taught to compete or...   \n",
       "2                0  Topic: Should students be taught to compete or...   \n",
       "3                0  Topic: Should students be taught to compete or...   \n",
       "4                0  Topic: Should students be taught to compete or...   \n",
       "...            ...                                                ...   \n",
       "4127             0  Topic: Children should studying hard or playin...   \n",
       "4128             0  Topic: Children should studying hard or playin...   \n",
       "4129             0  Topic: Children should studying hard or playin...   \n",
       "4130             0  Topic: Children should studying hard or playin...   \n",
       "4131             0  Topic: Children should studying hard or playin...   \n",
       "\n",
       "                                     component_pos_tags  \\\n",
       "0     Part Of Speech tags: ADP, NOUN, PUNCT, NOUN, V...   \n",
       "1     Part Of Speech tags: PRON, PRON, VERB, ADP, NO...   \n",
       "2     Part Of Speech tags: ADP, DET, NOUN, ADP, NOUN...   \n",
       "3     Part Of Speech tags: DET, ADP, DET, NOUN, VERB...   \n",
       "4     Part Of Speech tags: NOUN, VERB, DET, NOUN, AD...   \n",
       "...                                                 ...   \n",
       "4127  Part Of Speech tags: ADV, PRON, VERB, VERB, AD...   \n",
       "4128  Part Of Speech tags: DET, VERB, VERB, NOUN, VE...   \n",
       "4129  Part Of Speech tags: PRON, VERB, VERB, ADV, AD...   \n",
       "4130  Part Of Speech tags: VERB, NOUN, VERB, NOUN, V...   \n",
       "4131  Part Of Speech tags: VERB, NOUN, VERB, VERB, A...   \n",
       "\n",
       "                      strct_fts_essay_position_pos_tags  \\\n",
       "0     Topic: Should students be taught to compete or...   \n",
       "1     Topic: Should students be taught to compete or...   \n",
       "2     Topic: Should students be taught to compete or...   \n",
       "3     Topic: Should students be taught to compete or...   \n",
       "4     Topic: Should students be taught to compete or...   \n",
       "...                                                 ...   \n",
       "4127  Topic: Children should studying hard or playin...   \n",
       "4128  Topic: Children should studying hard or playin...   \n",
       "4129  Topic: Children should studying hard or playin...   \n",
       "4130  Topic: Children should studying hard or playin...   \n",
       "4131  Topic: Children should studying hard or playin...   \n",
       "\n",
       "                              prompted_representation_1  \n",
       "0     Component: Topic: Should students be taught to...  \n",
       "1     Component: Topic: Should students be taught to...  \n",
       "2     Component: Topic: Should students be taught to...  \n",
       "3     Component: Topic: Should students be taught to...  \n",
       "4     Component: Topic: Should students be taught to...  \n",
       "...                                                 ...  \n",
       "4127  Component: Topic: Children should studying har...  \n",
       "4128  Component: Topic: Children should studying har...  \n",
       "4129  Component: Topic: Children should studying har...  \n",
       "4130  Component: Topic: Children should studying har...  \n",
       "4131  Component: Topic: Children should studying har...  \n",
       "\n",
       "[4132 rows x 40 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a39c4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRAIN    4132\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57263bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompted_texts_l = df_train['prompted_representation_1'][:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c105823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4132"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompted_texts_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8cef3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = tokenizer(prompted_texts_l, return_tensors='pt', max_length=512, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "253c8d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24dfdbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4132, 512])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "144da00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training we will need labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "546be109",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train['labels'] = inputs_train.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da4c8c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7e51777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4132, 512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "095a7b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find where the last 102 is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71d6474a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inputs_train['input_ids'][0] == 102).nonzero(as_tuple=True)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee77a476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c l a i m'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(4366)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6dda1f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p r e m i s e'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(18458)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66b28ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# claim = 4366, premise = 18458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43a030ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inputs_train['input_ids'][1] == 102).nonzero(as_tuple=True)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38479aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18458)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train['input_ids'][1][169]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c73deccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that all at [len-2] indices are either claim or premise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "802165f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_indices_list = []\n",
    "\n",
    "for i in range(len(prompted_texts_l)):\n",
    "    cls_idx = (inputs_train['input_ids'][i] == 102).nonzero(as_tuple=True)[0].item()\n",
    "    cls_indices_list.append(cls_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ffb91336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[145,\n",
       " 171,\n",
       " 220,\n",
       " 150,\n",
       " 101,\n",
       " 130,\n",
       " 152,\n",
       " 288,\n",
       " 114,\n",
       " 143,\n",
       " 113,\n",
       " 188,\n",
       " 139,\n",
       " 149,\n",
       " 124,\n",
       " 149,\n",
       " 119,\n",
       " 129,\n",
       " 176,\n",
       " 142,\n",
       " 135,\n",
       " 105,\n",
       " 140,\n",
       " 179,\n",
       " 151,\n",
       " 131,\n",
       " 119,\n",
       " 208,\n",
       " 141,\n",
       " 125,\n",
       " 131,\n",
       " 221,\n",
       " 207,\n",
       " 161,\n",
       " 153,\n",
       " 136,\n",
       " 119,\n",
       " 124,\n",
       " 157,\n",
       " 127,\n",
       " 136,\n",
       " 198,\n",
       " 180,\n",
       " 170,\n",
       " 148,\n",
       " 170,\n",
       " 143,\n",
       " 170,\n",
       " 165,\n",
       " 127,\n",
       " 104,\n",
       " 92,\n",
       " 111,\n",
       " 133,\n",
       " 155,\n",
       " 109,\n",
       " 131,\n",
       " 100,\n",
       " 124,\n",
       " 98,\n",
       " 128,\n",
       " 131,\n",
       " 156,\n",
       " 102,\n",
       " 140,\n",
       " 138,\n",
       " 128,\n",
       " 177,\n",
       " 112,\n",
       " 139,\n",
       " 151,\n",
       " 152,\n",
       " 117,\n",
       " 129,\n",
       " 133,\n",
       " 143,\n",
       " 115,\n",
       " 126,\n",
       " 113,\n",
       " 148,\n",
       " 163,\n",
       " 117,\n",
       " 124,\n",
       " 99,\n",
       " 161,\n",
       " 116,\n",
       " 130,\n",
       " 160,\n",
       " 130,\n",
       " 118,\n",
       " 117,\n",
       " 102,\n",
       " 115,\n",
       " 109,\n",
       " 126,\n",
       " 96,\n",
       " 130,\n",
       " 231,\n",
       " 215,\n",
       " 102,\n",
       " 120,\n",
       " 146,\n",
       " 127,\n",
       " 145,\n",
       " 144,\n",
       " 170,\n",
       " 150,\n",
       " 119,\n",
       " 123,\n",
       " 119,\n",
       " 102,\n",
       " 107,\n",
       " 142,\n",
       " 101,\n",
       " 95,\n",
       " 186,\n",
       " 133,\n",
       " 154,\n",
       " 130,\n",
       " 132,\n",
       " 134,\n",
       " 124,\n",
       " 128,\n",
       " 150,\n",
       " 95,\n",
       " 153,\n",
       " 139,\n",
       " 122,\n",
       " 127,\n",
       " 149,\n",
       " 105,\n",
       " 149,\n",
       " 119,\n",
       " 155,\n",
       " 88,\n",
       " 104,\n",
       " 98,\n",
       " 105,\n",
       " 147,\n",
       " 143,\n",
       " 165,\n",
       " 151,\n",
       " 150,\n",
       " 116,\n",
       " 196,\n",
       " 137,\n",
       " 104,\n",
       " 145,\n",
       " 145,\n",
       " 106,\n",
       " 177,\n",
       " 136,\n",
       " 145,\n",
       " 126,\n",
       " 127,\n",
       " 138,\n",
       " 189,\n",
       " 109,\n",
       " 119,\n",
       " 130,\n",
       " 209,\n",
       " 124,\n",
       " 147,\n",
       " 118,\n",
       " 137,\n",
       " 163,\n",
       " 125,\n",
       " 113,\n",
       " 160,\n",
       " 111,\n",
       " 121,\n",
       " 102,\n",
       " 181,\n",
       " 150,\n",
       " 161,\n",
       " 112,\n",
       " 126,\n",
       " 115,\n",
       " 128,\n",
       " 101,\n",
       " 100,\n",
       " 104,\n",
       " 124,\n",
       " 104,\n",
       " 127,\n",
       " 116,\n",
       " 118,\n",
       " 112,\n",
       " 119,\n",
       " 121,\n",
       " 101,\n",
       " 105,\n",
       " 91,\n",
       " 130,\n",
       " 94,\n",
       " 125,\n",
       " 136,\n",
       " 142,\n",
       " 210,\n",
       " 143,\n",
       " 120,\n",
       " 159,\n",
       " 133,\n",
       " 120,\n",
       " 130,\n",
       " 110,\n",
       " 123,\n",
       " 143,\n",
       " 197,\n",
       " 120,\n",
       " 158,\n",
       " 129,\n",
       " 168,\n",
       " 167,\n",
       " 132,\n",
       " 124,\n",
       " 164,\n",
       " 141,\n",
       " 132,\n",
       " 163,\n",
       " 101,\n",
       " 127,\n",
       " 162,\n",
       " 137,\n",
       " 175,\n",
       " 187,\n",
       " 139,\n",
       " 140,\n",
       " 187,\n",
       " 110,\n",
       " 144,\n",
       " 146,\n",
       " 162,\n",
       " 132,\n",
       " 119,\n",
       " 156,\n",
       " 159,\n",
       " 142,\n",
       " 102,\n",
       " 183,\n",
       " 120,\n",
       " 87,\n",
       " 130,\n",
       " 125,\n",
       " 161,\n",
       " 131,\n",
       " 107,\n",
       " 169,\n",
       " 126,\n",
       " 135,\n",
       " 136,\n",
       " 157,\n",
       " 140,\n",
       " 172,\n",
       " 121,\n",
       " 140,\n",
       " 115,\n",
       " 117,\n",
       " 132,\n",
       " 149,\n",
       " 119,\n",
       " 169,\n",
       " 181,\n",
       " 85,\n",
       " 135,\n",
       " 127,\n",
       " 140,\n",
       " 132,\n",
       " 119,\n",
       " 181,\n",
       " 90,\n",
       " 147,\n",
       " 107,\n",
       " 156,\n",
       " 140,\n",
       " 108,\n",
       " 158,\n",
       " 164,\n",
       " 173,\n",
       " 155,\n",
       " 95,\n",
       " 169,\n",
       " 186,\n",
       " 117,\n",
       " 148,\n",
       " 129,\n",
       " 135,\n",
       " 135,\n",
       " 144,\n",
       " 134,\n",
       " 139,\n",
       " 147,\n",
       " 126,\n",
       " 151,\n",
       " 129,\n",
       " 119,\n",
       " 149,\n",
       " 128,\n",
       " 130,\n",
       " 123,\n",
       " 151,\n",
       " 117,\n",
       " 131,\n",
       " 156,\n",
       " 138,\n",
       " 155,\n",
       " 115,\n",
       " 108,\n",
       " 124,\n",
       " 182,\n",
       " 149,\n",
       " 129,\n",
       " 175,\n",
       " 112,\n",
       " 174,\n",
       " 168,\n",
       " 182,\n",
       " 117,\n",
       " 133,\n",
       " 131,\n",
       " 139,\n",
       " 112,\n",
       " 132,\n",
       " 141,\n",
       " 147,\n",
       " 111,\n",
       " 135,\n",
       " 138,\n",
       " 128,\n",
       " 110,\n",
       " 176,\n",
       " 118,\n",
       " 121,\n",
       " 136,\n",
       " 115,\n",
       " 110,\n",
       " 146,\n",
       " 191,\n",
       " 125,\n",
       " 145,\n",
       " 131,\n",
       " 142,\n",
       " 195,\n",
       " 146,\n",
       " 146,\n",
       " 112,\n",
       " 155,\n",
       " 165,\n",
       " 98,\n",
       " 148,\n",
       " 183,\n",
       " 156,\n",
       " 134,\n",
       " 119,\n",
       " 178,\n",
       " 164,\n",
       " 123,\n",
       " 138,\n",
       " 124,\n",
       " 128,\n",
       " 139,\n",
       " 130,\n",
       " 128,\n",
       " 133,\n",
       " 104,\n",
       " 114,\n",
       " 164,\n",
       " 116,\n",
       " 116,\n",
       " 134,\n",
       " 108,\n",
       " 112,\n",
       " 140,\n",
       " 165,\n",
       " 137,\n",
       " 115,\n",
       " 150,\n",
       " 127,\n",
       " 104,\n",
       " 109,\n",
       " 118,\n",
       " 115,\n",
       " 149,\n",
       " 117,\n",
       " 134,\n",
       " 150,\n",
       " 140,\n",
       " 142,\n",
       " 102,\n",
       " 153,\n",
       " 140,\n",
       " 136,\n",
       " 122,\n",
       " 129,\n",
       " 106,\n",
       " 134,\n",
       " 130,\n",
       " 102,\n",
       " 97,\n",
       " 108,\n",
       " 105,\n",
       " 138,\n",
       " 133,\n",
       " 150,\n",
       " 104,\n",
       " 118,\n",
       " 110,\n",
       " 124,\n",
       " 125,\n",
       " 156,\n",
       " 146,\n",
       " 117,\n",
       " 141,\n",
       " 125,\n",
       " 114,\n",
       " 137,\n",
       " 150,\n",
       " 141,\n",
       " 142,\n",
       " 179,\n",
       " 153,\n",
       " 118,\n",
       " 117,\n",
       " 150,\n",
       " 176,\n",
       " 160,\n",
       " 145,\n",
       " 146,\n",
       " 181,\n",
       " 155,\n",
       " 103,\n",
       " 125,\n",
       " 122,\n",
       " 127,\n",
       " 106,\n",
       " 152,\n",
       " 134,\n",
       " 106,\n",
       " 165,\n",
       " 136,\n",
       " 125,\n",
       " 152,\n",
       " 127,\n",
       " 141,\n",
       " 134,\n",
       " 129,\n",
       " 134,\n",
       " 135,\n",
       " 170,\n",
       " 177,\n",
       " 106,\n",
       " 126,\n",
       " 143,\n",
       " 157,\n",
       " 138,\n",
       " 144,\n",
       " 142,\n",
       " 132,\n",
       " 121,\n",
       " 120,\n",
       " 110,\n",
       " 214,\n",
       " 126,\n",
       " 190,\n",
       " 174,\n",
       " 163,\n",
       " 132,\n",
       " 125,\n",
       " 185,\n",
       " 124,\n",
       " 149,\n",
       " 129,\n",
       " 132,\n",
       " 133,\n",
       " 104,\n",
       " 137,\n",
       " 115,\n",
       " 137,\n",
       " 161,\n",
       " 148,\n",
       " 139,\n",
       " 146,\n",
       " 140,\n",
       " 109,\n",
       " 101,\n",
       " 132,\n",
       " 146,\n",
       " 116,\n",
       " 141,\n",
       " 158,\n",
       " 135,\n",
       " 120,\n",
       " 151,\n",
       " 193,\n",
       " 130,\n",
       " 129,\n",
       " 220,\n",
       " 117,\n",
       " 148,\n",
       " 110,\n",
       " 194,\n",
       " 153,\n",
       " 133,\n",
       " 174,\n",
       " 135,\n",
       " 109,\n",
       " 177,\n",
       " 138,\n",
       " 148,\n",
       " 121,\n",
       " 139,\n",
       " 132,\n",
       " 150,\n",
       " 121,\n",
       " 125,\n",
       " 184,\n",
       " 168,\n",
       " 127,\n",
       " 194,\n",
       " 134,\n",
       " 148,\n",
       " 125,\n",
       " 123,\n",
       " 125,\n",
       " 162,\n",
       " 156,\n",
       " 143,\n",
       " 177,\n",
       " 126,\n",
       " 111,\n",
       " 140,\n",
       " 180,\n",
       " 104,\n",
       " 114,\n",
       " 117,\n",
       " 139,\n",
       " 166,\n",
       " 104,\n",
       " 187,\n",
       " 120,\n",
       " 104,\n",
       " 121,\n",
       " 103,\n",
       " 117,\n",
       " 156,\n",
       " 129,\n",
       " 114,\n",
       " 128,\n",
       " 130,\n",
       " 114,\n",
       " 135,\n",
       " 124,\n",
       " 96,\n",
       " 112,\n",
       " 103,\n",
       " 139,\n",
       " 96,\n",
       " 109,\n",
       " 95,\n",
       " 174,\n",
       " 109,\n",
       " 129,\n",
       " 108,\n",
       " 109,\n",
       " 128,\n",
       " 131,\n",
       " 109,\n",
       " 166,\n",
       " 121,\n",
       " 162,\n",
       " 162,\n",
       " 189,\n",
       " 105,\n",
       " 113,\n",
       " 137,\n",
       " 122,\n",
       " 149,\n",
       " 115,\n",
       " 166,\n",
       " 108,\n",
       " 150,\n",
       " 109,\n",
       " 181,\n",
       " 151,\n",
       " 141,\n",
       " 131,\n",
       " 120,\n",
       " 116,\n",
       " 118,\n",
       " 193,\n",
       " 175,\n",
       " 109,\n",
       " 155,\n",
       " 130,\n",
       " 162,\n",
       " 173,\n",
       " 128,\n",
       " 140,\n",
       " 137,\n",
       " 168,\n",
       " 116,\n",
       " 128,\n",
       " 105,\n",
       " 117,\n",
       " 112,\n",
       " 158,\n",
       " 104,\n",
       " 162,\n",
       " 124,\n",
       " 144,\n",
       " 121,\n",
       " 101,\n",
       " 117,\n",
       " 137,\n",
       " 94,\n",
       " 115,\n",
       " 174,\n",
       " 162,\n",
       " 132,\n",
       " 120,\n",
       " 148,\n",
       " 110,\n",
       " 95,\n",
       " 128,\n",
       " 152,\n",
       " 124,\n",
       " 107,\n",
       " 150,\n",
       " 144,\n",
       " 114,\n",
       " 142,\n",
       " 98,\n",
       " 113,\n",
       " 129,\n",
       " 109,\n",
       " 94,\n",
       " 143,\n",
       " 135,\n",
       " 123,\n",
       " 121,\n",
       " 132,\n",
       " 109,\n",
       " 95,\n",
       " 122,\n",
       " 104,\n",
       " 133,\n",
       " 101,\n",
       " 107,\n",
       " 99,\n",
       " 137,\n",
       " 129,\n",
       " 117,\n",
       " 101,\n",
       " 156,\n",
       " 121,\n",
       " 111,\n",
       " 105,\n",
       " 114,\n",
       " 133,\n",
       " 130,\n",
       " 159,\n",
       " 124,\n",
       " 98,\n",
       " 104,\n",
       " 117,\n",
       " 136,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 158,\n",
       " 127,\n",
       " 145,\n",
       " 145,\n",
       " 114,\n",
       " 131,\n",
       " 119,\n",
       " 113,\n",
       " 116,\n",
       " 173,\n",
       " 129,\n",
       " 113,\n",
       " 105,\n",
       " 118,\n",
       " 109,\n",
       " 136,\n",
       " 116,\n",
       " 113,\n",
       " 126,\n",
       " 164,\n",
       " 147,\n",
       " 116,\n",
       " 117,\n",
       " 155,\n",
       " 121,\n",
       " 120,\n",
       " 154,\n",
       " 123,\n",
       " 106,\n",
       " 157,\n",
       " 136,\n",
       " 159,\n",
       " 228,\n",
       " 178,\n",
       " 128,\n",
       " 115,\n",
       " 256,\n",
       " 126,\n",
       " 158,\n",
       " 150,\n",
       " 140,\n",
       " 144,\n",
       " 129,\n",
       " 181,\n",
       " 169,\n",
       " 136,\n",
       " 129,\n",
       " 188,\n",
       " 197,\n",
       " 167,\n",
       " 169,\n",
       " 126,\n",
       " 193,\n",
       " 134,\n",
       " 122,\n",
       " 167,\n",
       " 119,\n",
       " 188,\n",
       " 182,\n",
       " 129,\n",
       " 165,\n",
       " 189,\n",
       " 130,\n",
       " 138,\n",
       " 153,\n",
       " 177,\n",
       " 150,\n",
       " 139,\n",
       " 140,\n",
       " 142,\n",
       " 116,\n",
       " 161,\n",
       " 175,\n",
       " 144,\n",
       " 179,\n",
       " 139,\n",
       " 196,\n",
       " 145,\n",
       " 134,\n",
       " 169,\n",
       " 133,\n",
       " 130,\n",
       " 168,\n",
       " 162,\n",
       " 212,\n",
       " 176,\n",
       " 109,\n",
       " 158,\n",
       " 132,\n",
       " 172,\n",
       " 251,\n",
       " 169,\n",
       " 227,\n",
       " 150,\n",
       " 126,\n",
       " 150,\n",
       " 158,\n",
       " 162,\n",
       " 154,\n",
       " 154,\n",
       " 133,\n",
       " 160,\n",
       " 185,\n",
       " 108,\n",
       " 138,\n",
       " 163,\n",
       " 162,\n",
       " 127,\n",
       " 171,\n",
       " 166,\n",
       " 108,\n",
       " 194,\n",
       " 139,\n",
       " 97,\n",
       " 129,\n",
       " 151,\n",
       " 177,\n",
       " 117,\n",
       " 120,\n",
       " 134,\n",
       " 122,\n",
       " 113,\n",
       " 132,\n",
       " 154,\n",
       " 146,\n",
       " 114,\n",
       " 135,\n",
       " 152,\n",
       " 104,\n",
       " 123,\n",
       " 143,\n",
       " 105,\n",
       " 144,\n",
       " 132,\n",
       " 159,\n",
       " 157,\n",
       " 123,\n",
       " 187,\n",
       " 159,\n",
       " 163,\n",
       " 176,\n",
       " 221,\n",
       " 128,\n",
       " 162,\n",
       " 152,\n",
       " 142,\n",
       " 161,\n",
       " 138,\n",
       " 168,\n",
       " 184,\n",
       " 179,\n",
       " 218,\n",
       " 148,\n",
       " 132,\n",
       " 105,\n",
       " 127,\n",
       " 124,\n",
       " 135,\n",
       " 115,\n",
       " 201,\n",
       " 128,\n",
       " 91,\n",
       " 167,\n",
       " 100,\n",
       " 190,\n",
       " 114,\n",
       " 134,\n",
       " 180,\n",
       " 199,\n",
       " 117,\n",
       " 103,\n",
       " 134,\n",
       " 148,\n",
       " 119,\n",
       " 125,\n",
       " 104,\n",
       " 195,\n",
       " 104,\n",
       " 111,\n",
       " 115,\n",
       " 142,\n",
       " 146,\n",
       " 142,\n",
       " 130,\n",
       " 131,\n",
       " 141,\n",
       " 185,\n",
       " 115,\n",
       " 140,\n",
       " 166,\n",
       " 98,\n",
       " 153,\n",
       " 124,\n",
       " 115,\n",
       " 143,\n",
       " 122,\n",
       " 148,\n",
       " 182,\n",
       " 148,\n",
       " 171,\n",
       " 120,\n",
       " 120,\n",
       " 142,\n",
       " 183,\n",
       " 174,\n",
       " 154,\n",
       " 118,\n",
       " 130,\n",
       " 126,\n",
       " 103,\n",
       " 144,\n",
       " 128,\n",
       " 164,\n",
       " 133,\n",
       " 145,\n",
       " 168,\n",
       " 134,\n",
       " 165,\n",
       " 168,\n",
       " 139,\n",
       " 186,\n",
       " 144,\n",
       " 122,\n",
       " 130,\n",
       " 145,\n",
       " 176,\n",
       " 130,\n",
       " 136,\n",
       " 146,\n",
       " 99,\n",
       " 152,\n",
       " 119,\n",
       " 104,\n",
       " 106,\n",
       " 127,\n",
       " 126,\n",
       " 161,\n",
       " 183,\n",
       " 143,\n",
       " 122,\n",
       " 125,\n",
       " 120,\n",
       " 121,\n",
       " 130,\n",
       " 133,\n",
       " 151,\n",
       " 143,\n",
       " 136,\n",
       " 122,\n",
       " 113,\n",
       " 159,\n",
       " 153,\n",
       " 156,\n",
       " 182,\n",
       " 182,\n",
       " 156,\n",
       " 135,\n",
       " 154,\n",
       " 154,\n",
       " 139,\n",
       " 196,\n",
       " 189,\n",
       " 189,\n",
       " 175,\n",
       " 106,\n",
       " 110,\n",
       " 117,\n",
       " 133,\n",
       " 131,\n",
       " 132,\n",
       " 104,\n",
       " 182,\n",
       " 153,\n",
       " 131,\n",
       " 130,\n",
       " 103,\n",
       " 150,\n",
       " 122,\n",
       " 109,\n",
       " 125,\n",
       " 141,\n",
       " 151,\n",
       " 177,\n",
       " 209,\n",
       " 156,\n",
       " 169,\n",
       " 172,\n",
       " 120,\n",
       " 143,\n",
       " 195,\n",
       " 217,\n",
       " 174,\n",
       " 99,\n",
       " 151,\n",
       " 158,\n",
       " 113,\n",
       " 162,\n",
       " 97,\n",
       " 122,\n",
       " 183,\n",
       " 153,\n",
       " 108,\n",
       " 110,\n",
       " 154,\n",
       " 148,\n",
       " 148,\n",
       " 159,\n",
       " 168,\n",
       " 103,\n",
       " 97,\n",
       " 100,\n",
       " 112,\n",
       " 113,\n",
       " 171,\n",
       " 107,\n",
       " 142,\n",
       " 104,\n",
       " 98,\n",
       " 123,\n",
       " 186,\n",
       " 125,\n",
       " 111,\n",
       " 135,\n",
       " 133,\n",
       " 140,\n",
       " 127,\n",
       " 140,\n",
       " 131,\n",
       " 134,\n",
       " 114,\n",
       " 130,\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_indices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3eb3b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4132"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cls_indices_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61114a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tokens_indices_list = [x - 2 for x in cls_indices_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c237d95e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[143,\n",
       " 169,\n",
       " 218,\n",
       " 148,\n",
       " 99,\n",
       " 128,\n",
       " 150,\n",
       " 286,\n",
       " 112,\n",
       " 141,\n",
       " 111,\n",
       " 186,\n",
       " 137,\n",
       " 147,\n",
       " 122,\n",
       " 147,\n",
       " 117,\n",
       " 127,\n",
       " 174,\n",
       " 140,\n",
       " 133,\n",
       " 103,\n",
       " 138,\n",
       " 177,\n",
       " 149,\n",
       " 129,\n",
       " 117,\n",
       " 206,\n",
       " 139,\n",
       " 123,\n",
       " 129,\n",
       " 219,\n",
       " 205,\n",
       " 159,\n",
       " 151,\n",
       " 134,\n",
       " 117,\n",
       " 122,\n",
       " 155,\n",
       " 125,\n",
       " 134,\n",
       " 196,\n",
       " 178,\n",
       " 168,\n",
       " 146,\n",
       " 168,\n",
       " 141,\n",
       " 168,\n",
       " 163,\n",
       " 125,\n",
       " 102,\n",
       " 90,\n",
       " 109,\n",
       " 131,\n",
       " 153,\n",
       " 107,\n",
       " 129,\n",
       " 98,\n",
       " 122,\n",
       " 96,\n",
       " 126,\n",
       " 129,\n",
       " 154,\n",
       " 100,\n",
       " 138,\n",
       " 136,\n",
       " 126,\n",
       " 175,\n",
       " 110,\n",
       " 137,\n",
       " 149,\n",
       " 150,\n",
       " 115,\n",
       " 127,\n",
       " 131,\n",
       " 141,\n",
       " 113,\n",
       " 124,\n",
       " 111,\n",
       " 146,\n",
       " 161,\n",
       " 115,\n",
       " 122,\n",
       " 97,\n",
       " 159,\n",
       " 114,\n",
       " 128,\n",
       " 158,\n",
       " 128,\n",
       " 116,\n",
       " 115,\n",
       " 100,\n",
       " 113,\n",
       " 107,\n",
       " 124,\n",
       " 94,\n",
       " 128,\n",
       " 229,\n",
       " 213,\n",
       " 100,\n",
       " 118,\n",
       " 144,\n",
       " 125,\n",
       " 143,\n",
       " 142,\n",
       " 168,\n",
       " 148,\n",
       " 117,\n",
       " 121,\n",
       " 117,\n",
       " 100,\n",
       " 105,\n",
       " 140,\n",
       " 99,\n",
       " 93,\n",
       " 184,\n",
       " 131,\n",
       " 152,\n",
       " 128,\n",
       " 130,\n",
       " 132,\n",
       " 122,\n",
       " 126,\n",
       " 148,\n",
       " 93,\n",
       " 151,\n",
       " 137,\n",
       " 120,\n",
       " 125,\n",
       " 147,\n",
       " 103,\n",
       " 147,\n",
       " 117,\n",
       " 153,\n",
       " 86,\n",
       " 102,\n",
       " 96,\n",
       " 103,\n",
       " 145,\n",
       " 141,\n",
       " 163,\n",
       " 149,\n",
       " 148,\n",
       " 114,\n",
       " 194,\n",
       " 135,\n",
       " 102,\n",
       " 143,\n",
       " 143,\n",
       " 104,\n",
       " 175,\n",
       " 134,\n",
       " 143,\n",
       " 124,\n",
       " 125,\n",
       " 136,\n",
       " 187,\n",
       " 107,\n",
       " 117,\n",
       " 128,\n",
       " 207,\n",
       " 122,\n",
       " 145,\n",
       " 116,\n",
       " 135,\n",
       " 161,\n",
       " 123,\n",
       " 111,\n",
       " 158,\n",
       " 109,\n",
       " 119,\n",
       " 100,\n",
       " 179,\n",
       " 148,\n",
       " 159,\n",
       " 110,\n",
       " 124,\n",
       " 113,\n",
       " 126,\n",
       " 99,\n",
       " 98,\n",
       " 102,\n",
       " 122,\n",
       " 102,\n",
       " 125,\n",
       " 114,\n",
       " 116,\n",
       " 110,\n",
       " 117,\n",
       " 119,\n",
       " 99,\n",
       " 103,\n",
       " 89,\n",
       " 128,\n",
       " 92,\n",
       " 123,\n",
       " 134,\n",
       " 140,\n",
       " 208,\n",
       " 141,\n",
       " 118,\n",
       " 157,\n",
       " 131,\n",
       " 118,\n",
       " 128,\n",
       " 108,\n",
       " 121,\n",
       " 141,\n",
       " 195,\n",
       " 118,\n",
       " 156,\n",
       " 127,\n",
       " 166,\n",
       " 165,\n",
       " 130,\n",
       " 122,\n",
       " 162,\n",
       " 139,\n",
       " 130,\n",
       " 161,\n",
       " 99,\n",
       " 125,\n",
       " 160,\n",
       " 135,\n",
       " 173,\n",
       " 185,\n",
       " 137,\n",
       " 138,\n",
       " 185,\n",
       " 108,\n",
       " 142,\n",
       " 144,\n",
       " 160,\n",
       " 130,\n",
       " 117,\n",
       " 154,\n",
       " 157,\n",
       " 140,\n",
       " 100,\n",
       " 181,\n",
       " 118,\n",
       " 85,\n",
       " 128,\n",
       " 123,\n",
       " 159,\n",
       " 129,\n",
       " 105,\n",
       " 167,\n",
       " 124,\n",
       " 133,\n",
       " 134,\n",
       " 155,\n",
       " 138,\n",
       " 170,\n",
       " 119,\n",
       " 138,\n",
       " 113,\n",
       " 115,\n",
       " 130,\n",
       " 147,\n",
       " 117,\n",
       " 167,\n",
       " 179,\n",
       " 83,\n",
       " 133,\n",
       " 125,\n",
       " 138,\n",
       " 130,\n",
       " 117,\n",
       " 179,\n",
       " 88,\n",
       " 145,\n",
       " 105,\n",
       " 154,\n",
       " 138,\n",
       " 106,\n",
       " 156,\n",
       " 162,\n",
       " 171,\n",
       " 153,\n",
       " 93,\n",
       " 167,\n",
       " 184,\n",
       " 115,\n",
       " 146,\n",
       " 127,\n",
       " 133,\n",
       " 133,\n",
       " 142,\n",
       " 132,\n",
       " 137,\n",
       " 145,\n",
       " 124,\n",
       " 149,\n",
       " 127,\n",
       " 117,\n",
       " 147,\n",
       " 126,\n",
       " 128,\n",
       " 121,\n",
       " 149,\n",
       " 115,\n",
       " 129,\n",
       " 154,\n",
       " 136,\n",
       " 153,\n",
       " 113,\n",
       " 106,\n",
       " 122,\n",
       " 180,\n",
       " 147,\n",
       " 127,\n",
       " 173,\n",
       " 110,\n",
       " 172,\n",
       " 166,\n",
       " 180,\n",
       " 115,\n",
       " 131,\n",
       " 129,\n",
       " 137,\n",
       " 110,\n",
       " 130,\n",
       " 139,\n",
       " 145,\n",
       " 109,\n",
       " 133,\n",
       " 136,\n",
       " 126,\n",
       " 108,\n",
       " 174,\n",
       " 116,\n",
       " 119,\n",
       " 134,\n",
       " 113,\n",
       " 108,\n",
       " 144,\n",
       " 189,\n",
       " 123,\n",
       " 143,\n",
       " 129,\n",
       " 140,\n",
       " 193,\n",
       " 144,\n",
       " 144,\n",
       " 110,\n",
       " 153,\n",
       " 163,\n",
       " 96,\n",
       " 146,\n",
       " 181,\n",
       " 154,\n",
       " 132,\n",
       " 117,\n",
       " 176,\n",
       " 162,\n",
       " 121,\n",
       " 136,\n",
       " 122,\n",
       " 126,\n",
       " 137,\n",
       " 128,\n",
       " 126,\n",
       " 131,\n",
       " 102,\n",
       " 112,\n",
       " 162,\n",
       " 114,\n",
       " 114,\n",
       " 132,\n",
       " 106,\n",
       " 110,\n",
       " 138,\n",
       " 163,\n",
       " 135,\n",
       " 113,\n",
       " 148,\n",
       " 125,\n",
       " 102,\n",
       " 107,\n",
       " 116,\n",
       " 113,\n",
       " 147,\n",
       " 115,\n",
       " 132,\n",
       " 148,\n",
       " 138,\n",
       " 140,\n",
       " 100,\n",
       " 151,\n",
       " 138,\n",
       " 134,\n",
       " 120,\n",
       " 127,\n",
       " 104,\n",
       " 132,\n",
       " 128,\n",
       " 100,\n",
       " 95,\n",
       " 106,\n",
       " 103,\n",
       " 136,\n",
       " 131,\n",
       " 148,\n",
       " 102,\n",
       " 116,\n",
       " 108,\n",
       " 122,\n",
       " 123,\n",
       " 154,\n",
       " 144,\n",
       " 115,\n",
       " 139,\n",
       " 123,\n",
       " 112,\n",
       " 135,\n",
       " 148,\n",
       " 139,\n",
       " 140,\n",
       " 177,\n",
       " 151,\n",
       " 116,\n",
       " 115,\n",
       " 148,\n",
       " 174,\n",
       " 158,\n",
       " 143,\n",
       " 144,\n",
       " 179,\n",
       " 153,\n",
       " 101,\n",
       " 123,\n",
       " 120,\n",
       " 125,\n",
       " 104,\n",
       " 150,\n",
       " 132,\n",
       " 104,\n",
       " 163,\n",
       " 134,\n",
       " 123,\n",
       " 150,\n",
       " 125,\n",
       " 139,\n",
       " 132,\n",
       " 127,\n",
       " 132,\n",
       " 133,\n",
       " 168,\n",
       " 175,\n",
       " 104,\n",
       " 124,\n",
       " 141,\n",
       " 155,\n",
       " 136,\n",
       " 142,\n",
       " 140,\n",
       " 130,\n",
       " 119,\n",
       " 118,\n",
       " 108,\n",
       " 212,\n",
       " 124,\n",
       " 188,\n",
       " 172,\n",
       " 161,\n",
       " 130,\n",
       " 123,\n",
       " 183,\n",
       " 122,\n",
       " 147,\n",
       " 127,\n",
       " 130,\n",
       " 131,\n",
       " 102,\n",
       " 135,\n",
       " 113,\n",
       " 135,\n",
       " 159,\n",
       " 146,\n",
       " 137,\n",
       " 144,\n",
       " 138,\n",
       " 107,\n",
       " 99,\n",
       " 130,\n",
       " 144,\n",
       " 114,\n",
       " 139,\n",
       " 156,\n",
       " 133,\n",
       " 118,\n",
       " 149,\n",
       " 191,\n",
       " 128,\n",
       " 127,\n",
       " 218,\n",
       " 115,\n",
       " 146,\n",
       " 108,\n",
       " 192,\n",
       " 151,\n",
       " 131,\n",
       " 172,\n",
       " 133,\n",
       " 107,\n",
       " 175,\n",
       " 136,\n",
       " 146,\n",
       " 119,\n",
       " 137,\n",
       " 130,\n",
       " 148,\n",
       " 119,\n",
       " 123,\n",
       " 182,\n",
       " 166,\n",
       " 125,\n",
       " 192,\n",
       " 132,\n",
       " 146,\n",
       " 123,\n",
       " 121,\n",
       " 123,\n",
       " 160,\n",
       " 154,\n",
       " 141,\n",
       " 175,\n",
       " 124,\n",
       " 109,\n",
       " 138,\n",
       " 178,\n",
       " 102,\n",
       " 112,\n",
       " 115,\n",
       " 137,\n",
       " 164,\n",
       " 102,\n",
       " 185,\n",
       " 118,\n",
       " 102,\n",
       " 119,\n",
       " 101,\n",
       " 115,\n",
       " 154,\n",
       " 127,\n",
       " 112,\n",
       " 126,\n",
       " 128,\n",
       " 112,\n",
       " 133,\n",
       " 122,\n",
       " 94,\n",
       " 110,\n",
       " 101,\n",
       " 137,\n",
       " 94,\n",
       " 107,\n",
       " 93,\n",
       " 172,\n",
       " 107,\n",
       " 127,\n",
       " 106,\n",
       " 107,\n",
       " 126,\n",
       " 129,\n",
       " 107,\n",
       " 164,\n",
       " 119,\n",
       " 160,\n",
       " 160,\n",
       " 187,\n",
       " 103,\n",
       " 111,\n",
       " 135,\n",
       " 120,\n",
       " 147,\n",
       " 113,\n",
       " 164,\n",
       " 106,\n",
       " 148,\n",
       " 107,\n",
       " 179,\n",
       " 149,\n",
       " 139,\n",
       " 129,\n",
       " 118,\n",
       " 114,\n",
       " 116,\n",
       " 191,\n",
       " 173,\n",
       " 107,\n",
       " 153,\n",
       " 128,\n",
       " 160,\n",
       " 171,\n",
       " 126,\n",
       " 138,\n",
       " 135,\n",
       " 166,\n",
       " 114,\n",
       " 126,\n",
       " 103,\n",
       " 115,\n",
       " 110,\n",
       " 156,\n",
       " 102,\n",
       " 160,\n",
       " 122,\n",
       " 142,\n",
       " 119,\n",
       " 99,\n",
       " 115,\n",
       " 135,\n",
       " 92,\n",
       " 113,\n",
       " 172,\n",
       " 160,\n",
       " 130,\n",
       " 118,\n",
       " 146,\n",
       " 108,\n",
       " 93,\n",
       " 126,\n",
       " 150,\n",
       " 122,\n",
       " 105,\n",
       " 148,\n",
       " 142,\n",
       " 112,\n",
       " 140,\n",
       " 96,\n",
       " 111,\n",
       " 127,\n",
       " 107,\n",
       " 92,\n",
       " 141,\n",
       " 133,\n",
       " 121,\n",
       " 119,\n",
       " 130,\n",
       " 107,\n",
       " 93,\n",
       " 120,\n",
       " 102,\n",
       " 131,\n",
       " 99,\n",
       " 105,\n",
       " 97,\n",
       " 135,\n",
       " 127,\n",
       " 115,\n",
       " 99,\n",
       " 154,\n",
       " 119,\n",
       " 109,\n",
       " 103,\n",
       " 112,\n",
       " 131,\n",
       " 128,\n",
       " 157,\n",
       " 122,\n",
       " 96,\n",
       " 102,\n",
       " 115,\n",
       " 134,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 156,\n",
       " 125,\n",
       " 143,\n",
       " 143,\n",
       " 112,\n",
       " 129,\n",
       " 117,\n",
       " 111,\n",
       " 114,\n",
       " 171,\n",
       " 127,\n",
       " 111,\n",
       " 103,\n",
       " 116,\n",
       " 107,\n",
       " 134,\n",
       " 114,\n",
       " 111,\n",
       " 124,\n",
       " 162,\n",
       " 145,\n",
       " 114,\n",
       " 115,\n",
       " 153,\n",
       " 119,\n",
       " 118,\n",
       " 152,\n",
       " 121,\n",
       " 104,\n",
       " 155,\n",
       " 134,\n",
       " 157,\n",
       " 226,\n",
       " 176,\n",
       " 126,\n",
       " 113,\n",
       " 254,\n",
       " 124,\n",
       " 156,\n",
       " 148,\n",
       " 138,\n",
       " 142,\n",
       " 127,\n",
       " 179,\n",
       " 167,\n",
       " 134,\n",
       " 127,\n",
       " 186,\n",
       " 195,\n",
       " 165,\n",
       " 167,\n",
       " 124,\n",
       " 191,\n",
       " 132,\n",
       " 120,\n",
       " 165,\n",
       " 117,\n",
       " 186,\n",
       " 180,\n",
       " 127,\n",
       " 163,\n",
       " 187,\n",
       " 128,\n",
       " 136,\n",
       " 151,\n",
       " 175,\n",
       " 148,\n",
       " 137,\n",
       " 138,\n",
       " 140,\n",
       " 114,\n",
       " 159,\n",
       " 173,\n",
       " 142,\n",
       " 177,\n",
       " 137,\n",
       " 194,\n",
       " 143,\n",
       " 132,\n",
       " 167,\n",
       " 131,\n",
       " 128,\n",
       " 166,\n",
       " 160,\n",
       " 210,\n",
       " 174,\n",
       " 107,\n",
       " 156,\n",
       " 130,\n",
       " 170,\n",
       " 249,\n",
       " 167,\n",
       " 225,\n",
       " 148,\n",
       " 124,\n",
       " 148,\n",
       " 156,\n",
       " 160,\n",
       " 152,\n",
       " 152,\n",
       " 131,\n",
       " 158,\n",
       " 183,\n",
       " 106,\n",
       " 136,\n",
       " 161,\n",
       " 160,\n",
       " 125,\n",
       " 169,\n",
       " 164,\n",
       " 106,\n",
       " 192,\n",
       " 137,\n",
       " 95,\n",
       " 127,\n",
       " 149,\n",
       " 175,\n",
       " 115,\n",
       " 118,\n",
       " 132,\n",
       " 120,\n",
       " 111,\n",
       " 130,\n",
       " 152,\n",
       " 144,\n",
       " 112,\n",
       " 133,\n",
       " 150,\n",
       " 102,\n",
       " 121,\n",
       " 141,\n",
       " 103,\n",
       " 142,\n",
       " 130,\n",
       " 157,\n",
       " 155,\n",
       " 121,\n",
       " 185,\n",
       " 157,\n",
       " 161,\n",
       " 174,\n",
       " 219,\n",
       " 126,\n",
       " 160,\n",
       " 150,\n",
       " 140,\n",
       " 159,\n",
       " 136,\n",
       " 166,\n",
       " 182,\n",
       " 177,\n",
       " 216,\n",
       " 146,\n",
       " 130,\n",
       " 103,\n",
       " 125,\n",
       " 122,\n",
       " 133,\n",
       " 113,\n",
       " 199,\n",
       " 126,\n",
       " 89,\n",
       " 165,\n",
       " 98,\n",
       " 188,\n",
       " 112,\n",
       " 132,\n",
       " 178,\n",
       " 197,\n",
       " 115,\n",
       " 101,\n",
       " 132,\n",
       " 146,\n",
       " 117,\n",
       " 123,\n",
       " 102,\n",
       " 193,\n",
       " 102,\n",
       " 109,\n",
       " 113,\n",
       " 140,\n",
       " 144,\n",
       " 140,\n",
       " 128,\n",
       " 129,\n",
       " 139,\n",
       " 183,\n",
       " 113,\n",
       " 138,\n",
       " 164,\n",
       " 96,\n",
       " 151,\n",
       " 122,\n",
       " 113,\n",
       " 141,\n",
       " 120,\n",
       " 146,\n",
       " 180,\n",
       " 146,\n",
       " 169,\n",
       " 118,\n",
       " 118,\n",
       " 140,\n",
       " 181,\n",
       " 172,\n",
       " 152,\n",
       " 116,\n",
       " 128,\n",
       " 124,\n",
       " 101,\n",
       " 142,\n",
       " 126,\n",
       " 162,\n",
       " 131,\n",
       " 143,\n",
       " 166,\n",
       " 132,\n",
       " 163,\n",
       " 166,\n",
       " 137,\n",
       " 184,\n",
       " 142,\n",
       " 120,\n",
       " 128,\n",
       " 143,\n",
       " 174,\n",
       " 128,\n",
       " 134,\n",
       " 144,\n",
       " 97,\n",
       " 150,\n",
       " 117,\n",
       " 102,\n",
       " 104,\n",
       " 125,\n",
       " 124,\n",
       " 159,\n",
       " 181,\n",
       " 141,\n",
       " 120,\n",
       " 123,\n",
       " 118,\n",
       " 119,\n",
       " 128,\n",
       " 131,\n",
       " 149,\n",
       " 141,\n",
       " 134,\n",
       " 120,\n",
       " 111,\n",
       " 157,\n",
       " 151,\n",
       " 154,\n",
       " 180,\n",
       " 180,\n",
       " 154,\n",
       " 133,\n",
       " 152,\n",
       " 152,\n",
       " 137,\n",
       " 194,\n",
       " 187,\n",
       " 187,\n",
       " 173,\n",
       " 104,\n",
       " 108,\n",
       " 115,\n",
       " 131,\n",
       " 129,\n",
       " 130,\n",
       " 102,\n",
       " 180,\n",
       " 151,\n",
       " 129,\n",
       " 128,\n",
       " 101,\n",
       " 148,\n",
       " 120,\n",
       " 107,\n",
       " 123,\n",
       " 139,\n",
       " 149,\n",
       " 175,\n",
       " 207,\n",
       " 154,\n",
       " 167,\n",
       " 170,\n",
       " 118,\n",
       " 141,\n",
       " 193,\n",
       " 215,\n",
       " 172,\n",
       " 97,\n",
       " 149,\n",
       " 156,\n",
       " 111,\n",
       " 160,\n",
       " 95,\n",
       " 120,\n",
       " 181,\n",
       " 151,\n",
       " 106,\n",
       " 108,\n",
       " 152,\n",
       " 146,\n",
       " 146,\n",
       " 157,\n",
       " 166,\n",
       " 101,\n",
       " 95,\n",
       " 98,\n",
       " 110,\n",
       " 111,\n",
       " 169,\n",
       " 105,\n",
       " 140,\n",
       " 102,\n",
       " 96,\n",
       " 121,\n",
       " 184,\n",
       " 123,\n",
       " 109,\n",
       " 133,\n",
       " 131,\n",
       " 138,\n",
       " 125,\n",
       " 138,\n",
       " 129,\n",
       " 132,\n",
       " 112,\n",
       " 128,\n",
       " ...]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_tokens_indices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d29e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs_pe['input_ids'][0][143].item() # correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f944bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get a list of input ids at all these indics: they should be either claim = 4366, premise = 18458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "645f5374",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index_minus_2 = []\n",
    "\n",
    "for idx, val in enumerate(class_tokens_indices_list):\n",
    "    at_idx_minus_2 = inputs_train['input_ids'][idx][val].item()\n",
    "    list_index_minus_2.append(at_idx_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ffa6c5a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4366, 18458}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list_index_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cab51338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d25f608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make the class token indices 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2f70d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, val in enumerate(class_tokens_indices_list):\n",
    "    inputs_train['input_ids'][idx][val] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d46c3988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check if they are 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e82eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsontroi_check_list = []\n",
    "\n",
    "for idx, val in enumerate(class_tokens_indices_list):\n",
    "    at_idx_minus_2 = inputs_train['input_ids'][idx][val].item()\n",
    "    unsontroi_check_list.append(at_idx_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a56b5642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{103}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(unsontroi_check_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b4ae382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c11a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeMiniDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d055811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PeMiniDataset(inputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "398752a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284afad4",
   "metadata": {},
   "source": [
    "### test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f8fd10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_sans_mc[df_sans_mc.split == 'TEST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0c34386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e95c629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_nr</th>\n",
       "      <th>component_id</th>\n",
       "      <th>label_and_comp_idxs</th>\n",
       "      <th>text</th>\n",
       "      <th>label_x</th>\n",
       "      <th>label_ComponentType</th>\n",
       "      <th>relation_SupportAttack</th>\n",
       "      <th>label_RelationType</th>\n",
       "      <th>label_LinkedNotLinked</th>\n",
       "      <th>split</th>\n",
       "      <th>...</th>\n",
       "      <th>nr_preceeding_comps_in_para</th>\n",
       "      <th>nr_following_comps_in_para</th>\n",
       "      <th>structural_fts_as_text</th>\n",
       "      <th>structural_fts_as_text_combined</th>\n",
       "      <th>para_ratio</th>\n",
       "      <th>first_or_last</th>\n",
       "      <th>strct_fts_w_position_in_essay</th>\n",
       "      <th>component_pos_tags</th>\n",
       "      <th>strct_fts_essay_position_pos_tags</th>\n",
       "      <th>prompted_representation_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>essay004</td>\n",
       "      <td>T3</td>\n",
       "      <td>Claim 179 239</td>\n",
       "      <td>the tourism bring large profit for the destina...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Attack</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Part Of Speech tags: DET, NOUN, VERB, ADJ, NOU...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Component: Topic: International tourism is now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>essay004</td>\n",
       "      <td>T4</td>\n",
       "      <td>Claim 953 1031</td>\n",
       "      <td>international tourism can create negative impa...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Part Of Speech tags: ADJ, NOUN, VERB, VERB, AD...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Component: Topic: International tourism is now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>essay004</td>\n",
       "      <td>T5</td>\n",
       "      <td>Claim 1578 1624</td>\n",
       "      <td>tourism has threatened the nature environments</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Part Of Speech tags: NOUN, AUX, VERB, DET, NOU...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Component: Topic: International tourism is now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>essay004</td>\n",
       "      <td>T6</td>\n",
       "      <td>Premise 417 530</td>\n",
       "      <td>tourists from different cultures will probably...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Part Of Speech tags: NOUN, ADP, ADJ, NOUN, VER...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Component: Topic: International tourism is now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>essay004</td>\n",
       "      <td>T7</td>\n",
       "      <td>Premise 532 818</td>\n",
       "      <td>Take Thailand for example, in the Vietnam War,...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Part Of Speech tags: VERB, PROPN, ADP, NOUN, P...</td>\n",
       "      <td>Topic: International tourism is now more commo...</td>\n",
       "      <td>Component: Topic: International tourism is now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>essay398</td>\n",
       "      <td>T12</td>\n",
       "      <td>Claim 1484 1589</td>\n",
       "      <td>universities should encourage more girls to ch...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Part Of Speech tags: NOUN, VERB, VERB, ADJ, NO...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Component: Topic: We can not forcedly put the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>essay398</td>\n",
       "      <td>T13</td>\n",
       "      <td>Premise 1595 1648</td>\n",
       "      <td>this could avoid imbalance of gender in some s...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Part Of Speech tags: DET, VERB, VERB, NOUN, AD...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Component: Topic: We can not forcedly put the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>essay398</td>\n",
       "      <td>T14</td>\n",
       "      <td>Premise 1650 1734</td>\n",
       "      <td>It would affect students' mental health to stu...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Part Of Speech tags: PRON, VERB, VERB, NOUN, P...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Component: Topic: We can not forcedly put the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>essay398</td>\n",
       "      <td>T15</td>\n",
       "      <td>Premise 1349 1388</td>\n",
       "      <td>she is unlikely to focus on her subject</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Part Of Speech tags: PRON, AUX, ADJ, PART, VER...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Component: Topic: We can not forcedly put the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>essay398</td>\n",
       "      <td>T16</td>\n",
       "      <td>Premise 1394 1463</td>\n",
       "      <td>this also can block the girl's future developm...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TEST</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Part Of Speech tags: DET, ADV, VERB, VERB, DET...</td>\n",
       "      <td>Topic: We can not forcedly put the same number...</td>\n",
       "      <td>Component: Topic: We can not forcedly put the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1107 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_nr component_id label_and_comp_idxs  \\\n",
       "0     essay004           T3       Claim 179 239   \n",
       "1     essay004           T4      Claim 953 1031   \n",
       "2     essay004           T5     Claim 1578 1624   \n",
       "3     essay004           T6     Premise 417 530   \n",
       "4     essay004           T7     Premise 532 818   \n",
       "...        ...          ...                 ...   \n",
       "1102  essay398          T12     Claim 1484 1589   \n",
       "1103  essay398          T13   Premise 1595 1648   \n",
       "1104  essay398          T14   Premise 1650 1734   \n",
       "1105  essay398          T15   Premise 1349 1388   \n",
       "1106  essay398          T16   Premise 1394 1463   \n",
       "\n",
       "                                                   text  label_x  \\\n",
       "0     the tourism bring large profit for the destina...    Claim   \n",
       "1     international tourism can create negative impa...    Claim   \n",
       "2        tourism has threatened the nature environments    Claim   \n",
       "3     tourists from different cultures will probably...  Premise   \n",
       "4     Take Thailand for example, in the Vietnam War,...  Premise   \n",
       "...                                                 ...      ...   \n",
       "1102  universities should encourage more girls to ch...    Claim   \n",
       "1103  this could avoid imbalance of gender in some s...  Premise   \n",
       "1104  It would affect students' mental health to stu...  Premise   \n",
       "1105            she is unlikely to focus on her subject  Premise   \n",
       "1106  this also can block the girl's future developm...  Premise   \n",
       "\n",
       "     label_ComponentType relation_SupportAttack label_RelationType  \\\n",
       "0                  Claim                     []             Attack   \n",
       "1                  Claim                     []            Support   \n",
       "2                  Claim                     []            Support   \n",
       "3                Premise                     []            Support   \n",
       "4                Premise                     []            Support   \n",
       "...                  ...                    ...                ...   \n",
       "1102               Claim                     []            Support   \n",
       "1103             Premise                     []            Support   \n",
       "1104             Premise                     []            Support   \n",
       "1105             Premise                     []            Support   \n",
       "1106             Premise                     []            Support   \n",
       "\n",
       "     label_LinkedNotLinked split  ... nr_preceeding_comps_in_para  \\\n",
       "0                NotLinked  TEST  ...                           1   \n",
       "1                   Linked  TEST  ...                           7   \n",
       "2                   Linked  TEST  ...                           7   \n",
       "3                NotLinked  TEST  ...                           4   \n",
       "4                NotLinked  TEST  ...                           5   \n",
       "...                    ...   ...  ...                         ...   \n",
       "1102                Linked  TEST  ...                           0   \n",
       "1103             NotLinked  TEST  ...                           1   \n",
       "1104             NotLinked  TEST  ...                           2   \n",
       "1105             NotLinked  TEST  ...                           3   \n",
       "1106             NotLinked  TEST  ...                           4   \n",
       "\n",
       "      nr_following_comps_in_para  \\\n",
       "0                              1   \n",
       "1                              0   \n",
       "2                              0   \n",
       "3                              3   \n",
       "4                              2   \n",
       "...                          ...   \n",
       "1102                           2   \n",
       "1103                           1   \n",
       "1104                           0   \n",
       "1105                           1   \n",
       "1106                           0   \n",
       "\n",
       "                                 structural_fts_as_text  \\\n",
       "0     Topic: International tourism is now more commo...   \n",
       "1     Topic: International tourism is now more commo...   \n",
       "2     Topic: International tourism is now more commo...   \n",
       "3     Topic: International tourism is now more commo...   \n",
       "4     Topic: International tourism is now more commo...   \n",
       "...                                                 ...   \n",
       "1102  Topic: We can not forcedly put the same number...   \n",
       "1103  Topic: We can not forcedly put the same number...   \n",
       "1104  Topic: We can not forcedly put the same number...   \n",
       "1105  Topic: We can not forcedly put the same number...   \n",
       "1106  Topic: We can not forcedly put the same number...   \n",
       "\n",
       "                        structural_fts_as_text_combined para_ratio  \\\n",
       "0     Topic: International tourism is now more commo...       0.25   \n",
       "1     Topic: International tourism is now more commo...       0.50   \n",
       "2     Topic: International tourism is now more commo...       0.75   \n",
       "3     Topic: International tourism is now more commo...       0.50   \n",
       "4     Topic: International tourism is now more commo...       0.50   \n",
       "...                                                 ...        ...   \n",
       "1102  Topic: We can not forcedly put the same number...       0.80   \n",
       "1103  Topic: We can not forcedly put the same number...       0.80   \n",
       "1104  Topic: We can not forcedly put the same number...       0.80   \n",
       "1105  Topic: We can not forcedly put the same number...       0.60   \n",
       "1106  Topic: We can not forcedly put the same number...       0.60   \n",
       "\n",
       "     first_or_last                      strct_fts_w_position_in_essay  \\\n",
       "0                1  Topic: International tourism is now more commo...   \n",
       "1                0  Topic: International tourism is now more commo...   \n",
       "2                0  Topic: International tourism is now more commo...   \n",
       "3                0  Topic: International tourism is now more commo...   \n",
       "4                0  Topic: International tourism is now more commo...   \n",
       "...            ...                                                ...   \n",
       "1102             0  Topic: We can not forcedly put the same number...   \n",
       "1103             0  Topic: We can not forcedly put the same number...   \n",
       "1104             0  Topic: We can not forcedly put the same number...   \n",
       "1105             0  Topic: We can not forcedly put the same number...   \n",
       "1106             0  Topic: We can not forcedly put the same number...   \n",
       "\n",
       "                                     component_pos_tags  \\\n",
       "0     Part Of Speech tags: DET, NOUN, VERB, ADJ, NOU...   \n",
       "1     Part Of Speech tags: ADJ, NOUN, VERB, VERB, AD...   \n",
       "2     Part Of Speech tags: NOUN, AUX, VERB, DET, NOU...   \n",
       "3     Part Of Speech tags: NOUN, ADP, ADJ, NOUN, VER...   \n",
       "4     Part Of Speech tags: VERB, PROPN, ADP, NOUN, P...   \n",
       "...                                                 ...   \n",
       "1102  Part Of Speech tags: NOUN, VERB, VERB, ADJ, NO...   \n",
       "1103  Part Of Speech tags: DET, VERB, VERB, NOUN, AD...   \n",
       "1104  Part Of Speech tags: PRON, VERB, VERB, NOUN, P...   \n",
       "1105  Part Of Speech tags: PRON, AUX, ADJ, PART, VER...   \n",
       "1106  Part Of Speech tags: DET, ADV, VERB, VERB, DET...   \n",
       "\n",
       "                      strct_fts_essay_position_pos_tags  \\\n",
       "0     Topic: International tourism is now more commo...   \n",
       "1     Topic: International tourism is now more commo...   \n",
       "2     Topic: International tourism is now more commo...   \n",
       "3     Topic: International tourism is now more commo...   \n",
       "4     Topic: International tourism is now more commo...   \n",
       "...                                                 ...   \n",
       "1102  Topic: We can not forcedly put the same number...   \n",
       "1103  Topic: We can not forcedly put the same number...   \n",
       "1104  Topic: We can not forcedly put the same number...   \n",
       "1105  Topic: We can not forcedly put the same number...   \n",
       "1106  Topic: We can not forcedly put the same number...   \n",
       "\n",
       "                              prompted_representation_1  \n",
       "0     Component: Topic: International tourism is now...  \n",
       "1     Component: Topic: International tourism is now...  \n",
       "2     Component: Topic: International tourism is now...  \n",
       "3     Component: Topic: International tourism is now...  \n",
       "4     Component: Topic: International tourism is now...  \n",
       "...                                                 ...  \n",
       "1102  Component: Topic: We can not forcedly put the ...  \n",
       "1103  Component: Topic: We can not forcedly put the ...  \n",
       "1104  Component: Topic: We can not forcedly put the ...  \n",
       "1105  Component: Topic: We can not forcedly put the ...  \n",
       "1106  Component: Topic: We can not forcedly put the ...  \n",
       "\n",
       "[1107 rows x 40 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd5cbb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TEST    1107\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e66032c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompted_texts_test_l = df_test['prompted_representation_1'][:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "37a2d890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1107"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompted_texts_test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f74c5b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test = tokenizer(prompted_texts_test_l, return_tensors='pt', max_length=512, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b3d7590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b0aa03cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1107, 512])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aac6691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test we do not need labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8b67b416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_train['labels'] = inputs_train.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eed2d1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5b3f3e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_train['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e5ec6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find where the last 102 is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5aed7a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(inputs_train['input_ids'][0] == 102).nonzero(as_tuple=True)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c6038624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.decode(4366)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "26747eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.decode(18458)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ea9f38a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# claim = 4366, premise = 18458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb79c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(inputs_train['input_ids'][1] == 102).nonzero(as_tuple=True)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b1e2e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_train['input_ids'][1][169]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "59b403d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that all at [len-2] indices are either claim or premise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c54df84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_indices_list_test = []\n",
    "\n",
    "for i in range(len(prompted_texts_test_l)):\n",
    "    cls_idx = (inputs_test['input_ids'][i] == 102).nonzero(as_tuple=True)[0].item()\n",
    "    cls_indices_list_test.append(cls_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d02c6dd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[129,\n",
       " 112,\n",
       " 99,\n",
       " 138,\n",
       " 254,\n",
       " 145,\n",
       " 123,\n",
       " 231,\n",
       " 150,\n",
       " 154,\n",
       " 137,\n",
       " 140,\n",
       " 200,\n",
       " 147,\n",
       " 131,\n",
       " 106,\n",
       " 113,\n",
       " 114,\n",
       " 117,\n",
       " 128,\n",
       " 134,\n",
       " 138,\n",
       " 105,\n",
       " 134,\n",
       " 106,\n",
       " 119,\n",
       " 122,\n",
       " 108,\n",
       " 144,\n",
       " 135,\n",
       " 103,\n",
       " 138,\n",
       " 101,\n",
       " 127,\n",
       " 127,\n",
       " 111,\n",
       " 115,\n",
       " 94,\n",
       " 102,\n",
       " 118,\n",
       " 113,\n",
       " 88,\n",
       " 98,\n",
       " 161,\n",
       " 123,\n",
       " 144,\n",
       " 104,\n",
       " 136,\n",
       " 151,\n",
       " 141,\n",
       " 103,\n",
       " 115,\n",
       " 148,\n",
       " 127,\n",
       " 158,\n",
       " 138,\n",
       " 191,\n",
       " 174,\n",
       " 220,\n",
       " 165,\n",
       " 165,\n",
       " 119,\n",
       " 139,\n",
       " 112,\n",
       " 128,\n",
       " 143,\n",
       " 110,\n",
       " 132,\n",
       " 138,\n",
       " 122,\n",
       " 147,\n",
       " 155,\n",
       " 145,\n",
       " 131,\n",
       " 109,\n",
       " 155,\n",
       " 102,\n",
       " 99,\n",
       " 106,\n",
       " 119,\n",
       " 129,\n",
       " 119,\n",
       " 156,\n",
       " 132,\n",
       " 146,\n",
       " 116,\n",
       " 124,\n",
       " 106,\n",
       " 182,\n",
       " 95,\n",
       " 171,\n",
       " 142,\n",
       " 138,\n",
       " 116,\n",
       " 226,\n",
       " 135,\n",
       " 147,\n",
       " 143,\n",
       " 108,\n",
       " 130,\n",
       " 182,\n",
       " 147,\n",
       " 123,\n",
       " 130,\n",
       " 160,\n",
       " 188,\n",
       " 129,\n",
       " 181,\n",
       " 97,\n",
       " 97,\n",
       " 111,\n",
       " 157,\n",
       " 125,\n",
       " 135,\n",
       " 163,\n",
       " 113,\n",
       " 156,\n",
       " 110,\n",
       " 129,\n",
       " 94,\n",
       " 112,\n",
       " 131,\n",
       " 107,\n",
       " 137,\n",
       " 160,\n",
       " 196,\n",
       " 114,\n",
       " 113,\n",
       " 119,\n",
       " 142,\n",
       " 180,\n",
       " 129,\n",
       " 128,\n",
       " 132,\n",
       " 151,\n",
       " 107,\n",
       " 147,\n",
       " 158,\n",
       " 207,\n",
       " 138,\n",
       " 115,\n",
       " 139,\n",
       " 115,\n",
       " 145,\n",
       " 137,\n",
       " 135,\n",
       " 128,\n",
       " 191,\n",
       " 136,\n",
       " 115,\n",
       " 115,\n",
       " 135,\n",
       " 129,\n",
       " 145,\n",
       " 124,\n",
       " 102,\n",
       " 186,\n",
       " 172,\n",
       " 116,\n",
       " 234,\n",
       " 192,\n",
       " 124,\n",
       " 136,\n",
       " 144,\n",
       " 152,\n",
       " 187,\n",
       " 144,\n",
       " 147,\n",
       " 122,\n",
       " 150,\n",
       " 127,\n",
       " 118,\n",
       " 184,\n",
       " 123,\n",
       " 116,\n",
       " 143,\n",
       " 140,\n",
       " 149,\n",
       " 153,\n",
       " 94,\n",
       " 133,\n",
       " 101,\n",
       " 150,\n",
       " 103,\n",
       " 220,\n",
       " 126,\n",
       " 141,\n",
       " 120,\n",
       " 179,\n",
       " 136,\n",
       " 174,\n",
       " 141,\n",
       " 180,\n",
       " 113,\n",
       " 134,\n",
       " 150,\n",
       " 118,\n",
       " 165,\n",
       " 124,\n",
       " 123,\n",
       " 160,\n",
       " 147,\n",
       " 138,\n",
       " 146,\n",
       " 131,\n",
       " 149,\n",
       " 124,\n",
       " 166,\n",
       " 151,\n",
       " 133,\n",
       " 143,\n",
       " 169,\n",
       " 123,\n",
       " 135,\n",
       " 181,\n",
       " 146,\n",
       " 112,\n",
       " 226,\n",
       " 105,\n",
       " 135,\n",
       " 141,\n",
       " 127,\n",
       " 129,\n",
       " 187,\n",
       " 122,\n",
       " 165,\n",
       " 115,\n",
       " 115,\n",
       " 97,\n",
       " 128,\n",
       " 166,\n",
       " 178,\n",
       " 126,\n",
       " 100,\n",
       " 140,\n",
       " 140,\n",
       " 203,\n",
       " 102,\n",
       " 131,\n",
       " 125,\n",
       " 112,\n",
       " 114,\n",
       " 193,\n",
       " 95,\n",
       " 114,\n",
       " 106,\n",
       " 125,\n",
       " 113,\n",
       " 120,\n",
       " 135,\n",
       " 192,\n",
       " 206,\n",
       " 108,\n",
       " 107,\n",
       " 135,\n",
       " 135,\n",
       " 172,\n",
       " 107,\n",
       " 136,\n",
       " 189,\n",
       " 124,\n",
       " 143,\n",
       " 158,\n",
       " 103,\n",
       " 136,\n",
       " 156,\n",
       " 133,\n",
       " 142,\n",
       " 145,\n",
       " 96,\n",
       " 137,\n",
       " 179,\n",
       " 168,\n",
       " 167,\n",
       " 163,\n",
       " 96,\n",
       " 152,\n",
       " 188,\n",
       " 110,\n",
       " 176,\n",
       " 123,\n",
       " 113,\n",
       " 128,\n",
       " 112,\n",
       " 111,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 183,\n",
       " 129,\n",
       " 114,\n",
       " 151,\n",
       " 109,\n",
       " 99,\n",
       " 128,\n",
       " 122,\n",
       " 148,\n",
       " 113,\n",
       " 139,\n",
       " 152,\n",
       " 146,\n",
       " 123,\n",
       " 147,\n",
       " 130,\n",
       " 161,\n",
       " 117,\n",
       " 115,\n",
       " 119,\n",
       " 115,\n",
       " 135,\n",
       " 87,\n",
       " 111,\n",
       " 117,\n",
       " 99,\n",
       " 98,\n",
       " 107,\n",
       " 150,\n",
       " 120,\n",
       " 106,\n",
       " 108,\n",
       " 109,\n",
       " 108,\n",
       " 123,\n",
       " 135,\n",
       " 122,\n",
       " 144,\n",
       " 107,\n",
       " 126,\n",
       " 98,\n",
       " 238,\n",
       " 150,\n",
       " 121,\n",
       " 128,\n",
       " 126,\n",
       " 120,\n",
       " 147,\n",
       " 110,\n",
       " 133,\n",
       " 111,\n",
       " 105,\n",
       " 125,\n",
       " 131,\n",
       " 101,\n",
       " 134,\n",
       " 101,\n",
       " 126,\n",
       " 129,\n",
       " 170,\n",
       " 174,\n",
       " 140,\n",
       " 143,\n",
       " 140,\n",
       " 156,\n",
       " 135,\n",
       " 221,\n",
       " 150,\n",
       " 171,\n",
       " 141,\n",
       " 130,\n",
       " 132,\n",
       " 130,\n",
       " 118,\n",
       " 175,\n",
       " 119,\n",
       " 126,\n",
       " 150,\n",
       " 165,\n",
       " 238,\n",
       " 147,\n",
       " 187,\n",
       " 147,\n",
       " 116,\n",
       " 114,\n",
       " 117,\n",
       " 113,\n",
       " 118,\n",
       " 103,\n",
       " 103,\n",
       " 98,\n",
       " 125,\n",
       " 118,\n",
       " 167,\n",
       " 130,\n",
       " 149,\n",
       " 155,\n",
       " 132,\n",
       " 109,\n",
       " 107,\n",
       " 138,\n",
       " 99,\n",
       " 147,\n",
       " 133,\n",
       " 105,\n",
       " 108,\n",
       " 139,\n",
       " 99,\n",
       " 103,\n",
       " 107,\n",
       " 139,\n",
       " 132,\n",
       " 103,\n",
       " 125,\n",
       " 119,\n",
       " 102,\n",
       " 143,\n",
       " 126,\n",
       " 130,\n",
       " 126,\n",
       " 120,\n",
       " 138,\n",
       " 142,\n",
       " 120,\n",
       " 123,\n",
       " 116,\n",
       " 168,\n",
       " 89,\n",
       " 172,\n",
       " 109,\n",
       " 133,\n",
       " 170,\n",
       " 133,\n",
       " 165,\n",
       " 133,\n",
       " 145,\n",
       " 138,\n",
       " 146,\n",
       " 171,\n",
       " 137,\n",
       " 119,\n",
       " 173,\n",
       " 109,\n",
       " 139,\n",
       " 141,\n",
       " 129,\n",
       " 136,\n",
       " 103,\n",
       " 170,\n",
       " 114,\n",
       " 130,\n",
       " 101,\n",
       " 135,\n",
       " 155,\n",
       " 122,\n",
       " 124,\n",
       " 107,\n",
       " 98,\n",
       " 147,\n",
       " 130,\n",
       " 140,\n",
       " 108,\n",
       " 148,\n",
       " 97,\n",
       " 123,\n",
       " 96,\n",
       " 176,\n",
       " 168,\n",
       " 134,\n",
       " 107,\n",
       " 119,\n",
       " 135,\n",
       " 225,\n",
       " 118,\n",
       " 161,\n",
       " 103,\n",
       " 150,\n",
       " 125,\n",
       " 159,\n",
       " 152,\n",
       " 238,\n",
       " 172,\n",
       " 223,\n",
       " 206,\n",
       " 177,\n",
       " 160,\n",
       " 161,\n",
       " 136,\n",
       " 131,\n",
       " 104,\n",
       " 142,\n",
       " 214,\n",
       " 113,\n",
       " 144,\n",
       " 106,\n",
       " 123,\n",
       " 140,\n",
       " 128,\n",
       " 113,\n",
       " 216,\n",
       " 154,\n",
       " 153,\n",
       " 133,\n",
       " 119,\n",
       " 105,\n",
       " 128,\n",
       " 120,\n",
       " 152,\n",
       " 117,\n",
       " 104,\n",
       " 117,\n",
       " 116,\n",
       " 176,\n",
       " 100,\n",
       " 125,\n",
       " 104,\n",
       " 124,\n",
       " 106,\n",
       " 101,\n",
       " 115,\n",
       " 93,\n",
       " 140,\n",
       " 114,\n",
       " 168,\n",
       " 137,\n",
       " 161,\n",
       " 177,\n",
       " 142,\n",
       " 106,\n",
       " 157,\n",
       " 148,\n",
       " 154,\n",
       " 126,\n",
       " 106,\n",
       " 132,\n",
       " 120,\n",
       " 129,\n",
       " 122,\n",
       " 101,\n",
       " 180,\n",
       " 104,\n",
       " 108,\n",
       " 113,\n",
       " 109,\n",
       " 138,\n",
       " 98,\n",
       " 139,\n",
       " 120,\n",
       " 99,\n",
       " 127,\n",
       " 137,\n",
       " 126,\n",
       " 143,\n",
       " 231,\n",
       " 158,\n",
       " 139,\n",
       " 153,\n",
       " 198,\n",
       " 120,\n",
       " 135,\n",
       " 116,\n",
       " 122,\n",
       " 159,\n",
       " 131,\n",
       " 149,\n",
       " 160,\n",
       " 152,\n",
       " 246,\n",
       " 127,\n",
       " 105,\n",
       " 170,\n",
       " 156,\n",
       " 124,\n",
       " 118,\n",
       " 148,\n",
       " 117,\n",
       " 132,\n",
       " 154,\n",
       " 189,\n",
       " 102,\n",
       " 130,\n",
       " 121,\n",
       " 105,\n",
       " 183,\n",
       " 133,\n",
       " 112,\n",
       " 125,\n",
       " 106,\n",
       " 113,\n",
       " 165,\n",
       " 113,\n",
       " 146,\n",
       " 139,\n",
       " 120,\n",
       " 97,\n",
       " 134,\n",
       " 125,\n",
       " 160,\n",
       " 106,\n",
       " 128,\n",
       " 104,\n",
       " 122,\n",
       " 124,\n",
       " 105,\n",
       " 117,\n",
       " 111,\n",
       " 127,\n",
       " 152,\n",
       " 129,\n",
       " 121,\n",
       " 102,\n",
       " 102,\n",
       " 103,\n",
       " 103,\n",
       " 112,\n",
       " 119,\n",
       " 114,\n",
       " 115,\n",
       " 135,\n",
       " 119,\n",
       " 131,\n",
       " 123,\n",
       " 125,\n",
       " 119,\n",
       " 162,\n",
       " 123,\n",
       " 160,\n",
       " 101,\n",
       " 119,\n",
       " 155,\n",
       " 116,\n",
       " 139,\n",
       " 154,\n",
       " 126,\n",
       " 165,\n",
       " 207,\n",
       " 144,\n",
       " 120,\n",
       " 128,\n",
       " 132,\n",
       " 123,\n",
       " 106,\n",
       " 130,\n",
       " 95,\n",
       " 124,\n",
       " 100,\n",
       " 121,\n",
       " 142,\n",
       " 113,\n",
       " 126,\n",
       " 154,\n",
       " 138,\n",
       " 135,\n",
       " 146,\n",
       " 91,\n",
       " 120,\n",
       " 139,\n",
       " 128,\n",
       " 104,\n",
       " 140,\n",
       " 132,\n",
       " 130,\n",
       " 131,\n",
       " 127,\n",
       " 97,\n",
       " 142,\n",
       " 122,\n",
       " 123,\n",
       " 133,\n",
       " 153,\n",
       " 136,\n",
       " 163,\n",
       " 112,\n",
       " 134,\n",
       " 187,\n",
       " 177,\n",
       " 137,\n",
       " 120,\n",
       " 134,\n",
       " 158,\n",
       " 126,\n",
       " 110,\n",
       " 150,\n",
       " 110,\n",
       " 129,\n",
       " 110,\n",
       " 100,\n",
       " 143,\n",
       " 152,\n",
       " 109,\n",
       " 125,\n",
       " 107,\n",
       " 128,\n",
       " 129,\n",
       " 112,\n",
       " 104,\n",
       " 187,\n",
       " 132,\n",
       " 121,\n",
       " 124,\n",
       " 121,\n",
       " 106,\n",
       " 119,\n",
       " 120,\n",
       " 185,\n",
       " 141,\n",
       " 134,\n",
       " 125,\n",
       " 109,\n",
       " 134,\n",
       " 136,\n",
       " 138,\n",
       " 145,\n",
       " 107,\n",
       " 92,\n",
       " 155,\n",
       " 128,\n",
       " 105,\n",
       " 128,\n",
       " 162,\n",
       " 136,\n",
       " 151,\n",
       " 145,\n",
       " 124,\n",
       " 142,\n",
       " 175,\n",
       " 181,\n",
       " 128,\n",
       " 126,\n",
       " 119,\n",
       " 148,\n",
       " 142,\n",
       " 116,\n",
       " 140,\n",
       " 136,\n",
       " 126,\n",
       " 118,\n",
       " 167,\n",
       " 163,\n",
       " 117,\n",
       " 125,\n",
       " 101,\n",
       " 137,\n",
       " 127,\n",
       " 132,\n",
       " 122,\n",
       " 166,\n",
       " 165,\n",
       " 107,\n",
       " 155,\n",
       " 107,\n",
       " 122,\n",
       " 155,\n",
       " 134,\n",
       " 158,\n",
       " 119,\n",
       " 205,\n",
       " 115,\n",
       " 116,\n",
       " 139,\n",
       " 238,\n",
       " 134,\n",
       " 106,\n",
       " 199,\n",
       " 120,\n",
       " 124,\n",
       " 149,\n",
       " 122,\n",
       " 126,\n",
       " 104,\n",
       " 143,\n",
       " 149,\n",
       " 158,\n",
       " 177,\n",
       " 140,\n",
       " 124,\n",
       " 151,\n",
       " 126,\n",
       " 150,\n",
       " 194,\n",
       " 108,\n",
       " 127,\n",
       " 137,\n",
       " 119,\n",
       " 94,\n",
       " 161,\n",
       " 141,\n",
       " 201,\n",
       " 94,\n",
       " 142,\n",
       " 149,\n",
       " 155,\n",
       " 109,\n",
       " 137,\n",
       " 191,\n",
       " 185,\n",
       " 113,\n",
       " 116,\n",
       " 176,\n",
       " 183,\n",
       " 132,\n",
       " 123,\n",
       " 147,\n",
       " 155,\n",
       " 146,\n",
       " 130,\n",
       " 159,\n",
       " 101,\n",
       " 148,\n",
       " 127,\n",
       " 113,\n",
       " 147,\n",
       " 119,\n",
       " 124,\n",
       " 158,\n",
       " 140,\n",
       " 114,\n",
       " 122,\n",
       " 106,\n",
       " 142,\n",
       " 128,\n",
       " 112,\n",
       " 105,\n",
       " 137,\n",
       " 114,\n",
       " 127,\n",
       " 142,\n",
       " 125,\n",
       " 183,\n",
       " 125,\n",
       " 128,\n",
       " 131,\n",
       " 128,\n",
       " 144,\n",
       " 141,\n",
       " 139,\n",
       " 133,\n",
       " 126,\n",
       " 154,\n",
       " 118,\n",
       " 116,\n",
       " 114,\n",
       " 111,\n",
       " 105,\n",
       " 104,\n",
       " 102,\n",
       " 106,\n",
       " 113,\n",
       " 153,\n",
       " 136,\n",
       " 150,\n",
       " 131,\n",
       " 134,\n",
       " 121,\n",
       " 110,\n",
       " 94,\n",
       " 126,\n",
       " 108,\n",
       " 145,\n",
       " 117,\n",
       " 166,\n",
       " 113,\n",
       " 125,\n",
       " 232,\n",
       " 138,\n",
       " 164,\n",
       " 102,\n",
       " 140,\n",
       " 145,\n",
       " 115,\n",
       " 158,\n",
       " 107,\n",
       " 97,\n",
       " 151,\n",
       " 107,\n",
       " 106,\n",
       " 156,\n",
       " 113,\n",
       " 117,\n",
       " 136,\n",
       " 191,\n",
       " 160,\n",
       " 182,\n",
       " 174,\n",
       " 195,\n",
       " 94,\n",
       " 192,\n",
       " 157,\n",
       " 157,\n",
       " 103,\n",
       " 109,\n",
       " 135,\n",
       " 181,\n",
       " 165,\n",
       " 140,\n",
       " 139,\n",
       " 108,\n",
       " 117,\n",
       " 138,\n",
       " 120,\n",
       " 120,\n",
       " 106,\n",
       " 118,\n",
       " 122,\n",
       " 126,\n",
       " 105,\n",
       " 99,\n",
       " 173,\n",
       " 139,\n",
       " 119,\n",
       " 148,\n",
       " 114,\n",
       " 167,\n",
       " 214,\n",
       " 142,\n",
       " 144,\n",
       " 175,\n",
       " 110,\n",
       " 136,\n",
       " 122,\n",
       " 130,\n",
       " 178,\n",
       " 106,\n",
       " 133,\n",
       " 109,\n",
       " 109,\n",
       " 112,\n",
       " 143,\n",
       " 165,\n",
       " 129,\n",
       " 125,\n",
       " 129,\n",
       " 143,\n",
       " 131,\n",
       " 140,\n",
       " 138,\n",
       " 129,\n",
       " 154,\n",
       " 149,\n",
       " 160,\n",
       " 134,\n",
       " 159,\n",
       " 146,\n",
       " 134,\n",
       " 116,\n",
       " 131,\n",
       " 128,\n",
       " 107,\n",
       " 130,\n",
       " 127,\n",
       " 106,\n",
       " 145,\n",
       " 122,\n",
       " 177,\n",
       " 111,\n",
       " 119,\n",
       " 185,\n",
       " 187,\n",
       " 196,\n",
       " 106,\n",
       " 146,\n",
       " 175,\n",
       " 178,\n",
       " 180,\n",
       " 140,\n",
       " 191,\n",
       " 153,\n",
       " 111,\n",
       " 131,\n",
       " 133,\n",
       " 119,\n",
       " 138,\n",
       " 112,\n",
       " 155,\n",
       " 148,\n",
       " 134,\n",
       " 167,\n",
       " 107,\n",
       " 149,\n",
       " 111,\n",
       " 134,\n",
       " 154,\n",
       " 144,\n",
       " 127,\n",
       " 152,\n",
       " 111,\n",
       " 100,\n",
       " 141,\n",
       " 131,\n",
       " 131,\n",
       " 134,\n",
       " 186,\n",
       " 155,\n",
       " 144,\n",
       " 128,\n",
       " 151,\n",
       " 110,\n",
       " 128,\n",
       " 140,\n",
       " 117,\n",
       " 134,\n",
       " 116,\n",
       " 118,\n",
       " 145,\n",
       " 123,\n",
       " 133,\n",
       " 178,\n",
       " 175,\n",
       " 105,\n",
       " 169,\n",
       " 178,\n",
       " 163,\n",
       " ...]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_indices_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "70374b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1107"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cls_indices_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fcafb2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tokens_indices_test_list = [x - 2 for x in cls_indices_list_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ef882b21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[127,\n",
       " 110,\n",
       " 97,\n",
       " 136,\n",
       " 252,\n",
       " 143,\n",
       " 121,\n",
       " 229,\n",
       " 148,\n",
       " 152,\n",
       " 135,\n",
       " 138,\n",
       " 198,\n",
       " 145,\n",
       " 129,\n",
       " 104,\n",
       " 111,\n",
       " 112,\n",
       " 115,\n",
       " 126,\n",
       " 132,\n",
       " 136,\n",
       " 103,\n",
       " 132,\n",
       " 104,\n",
       " 117,\n",
       " 120,\n",
       " 106,\n",
       " 142,\n",
       " 133,\n",
       " 101,\n",
       " 136,\n",
       " 99,\n",
       " 125,\n",
       " 125,\n",
       " 109,\n",
       " 113,\n",
       " 92,\n",
       " 100,\n",
       " 116,\n",
       " 111,\n",
       " 86,\n",
       " 96,\n",
       " 159,\n",
       " 121,\n",
       " 142,\n",
       " 102,\n",
       " 134,\n",
       " 149,\n",
       " 139,\n",
       " 101,\n",
       " 113,\n",
       " 146,\n",
       " 125,\n",
       " 156,\n",
       " 136,\n",
       " 189,\n",
       " 172,\n",
       " 218,\n",
       " 163,\n",
       " 163,\n",
       " 117,\n",
       " 137,\n",
       " 110,\n",
       " 126,\n",
       " 141,\n",
       " 108,\n",
       " 130,\n",
       " 136,\n",
       " 120,\n",
       " 145,\n",
       " 153,\n",
       " 143,\n",
       " 129,\n",
       " 107,\n",
       " 153,\n",
       " 100,\n",
       " 97,\n",
       " 104,\n",
       " 117,\n",
       " 127,\n",
       " 117,\n",
       " 154,\n",
       " 130,\n",
       " 144,\n",
       " 114,\n",
       " 122,\n",
       " 104,\n",
       " 180,\n",
       " 93,\n",
       " 169,\n",
       " 140,\n",
       " 136,\n",
       " 114,\n",
       " 224,\n",
       " 133,\n",
       " 145,\n",
       " 141,\n",
       " 106,\n",
       " 128,\n",
       " 180,\n",
       " 145,\n",
       " 121,\n",
       " 128,\n",
       " 158,\n",
       " 186,\n",
       " 127,\n",
       " 179,\n",
       " 95,\n",
       " 95,\n",
       " 109,\n",
       " 155,\n",
       " 123,\n",
       " 133,\n",
       " 161,\n",
       " 111,\n",
       " 154,\n",
       " 108,\n",
       " 127,\n",
       " 92,\n",
       " 110,\n",
       " 129,\n",
       " 105,\n",
       " 135,\n",
       " 158,\n",
       " 194,\n",
       " 112,\n",
       " 111,\n",
       " 117,\n",
       " 140,\n",
       " 178,\n",
       " 127,\n",
       " 126,\n",
       " 130,\n",
       " 149,\n",
       " 105,\n",
       " 145,\n",
       " 156,\n",
       " 205,\n",
       " 136,\n",
       " 113,\n",
       " 137,\n",
       " 113,\n",
       " 143,\n",
       " 135,\n",
       " 133,\n",
       " 126,\n",
       " 189,\n",
       " 134,\n",
       " 113,\n",
       " 113,\n",
       " 133,\n",
       " 127,\n",
       " 143,\n",
       " 122,\n",
       " 100,\n",
       " 184,\n",
       " 170,\n",
       " 114,\n",
       " 232,\n",
       " 190,\n",
       " 122,\n",
       " 134,\n",
       " 142,\n",
       " 150,\n",
       " 185,\n",
       " 142,\n",
       " 145,\n",
       " 120,\n",
       " 148,\n",
       " 125,\n",
       " 116,\n",
       " 182,\n",
       " 121,\n",
       " 114,\n",
       " 141,\n",
       " 138,\n",
       " 147,\n",
       " 151,\n",
       " 92,\n",
       " 131,\n",
       " 99,\n",
       " 148,\n",
       " 101,\n",
       " 218,\n",
       " 124,\n",
       " 139,\n",
       " 118,\n",
       " 177,\n",
       " 134,\n",
       " 172,\n",
       " 139,\n",
       " 178,\n",
       " 111,\n",
       " 132,\n",
       " 148,\n",
       " 116,\n",
       " 163,\n",
       " 122,\n",
       " 121,\n",
       " 158,\n",
       " 145,\n",
       " 136,\n",
       " 144,\n",
       " 129,\n",
       " 147,\n",
       " 122,\n",
       " 164,\n",
       " 149,\n",
       " 131,\n",
       " 141,\n",
       " 167,\n",
       " 121,\n",
       " 133,\n",
       " 179,\n",
       " 144,\n",
       " 110,\n",
       " 224,\n",
       " 103,\n",
       " 133,\n",
       " 139,\n",
       " 125,\n",
       " 127,\n",
       " 185,\n",
       " 120,\n",
       " 163,\n",
       " 113,\n",
       " 113,\n",
       " 95,\n",
       " 126,\n",
       " 164,\n",
       " 176,\n",
       " 124,\n",
       " 98,\n",
       " 138,\n",
       " 138,\n",
       " 201,\n",
       " 100,\n",
       " 129,\n",
       " 123,\n",
       " 110,\n",
       " 112,\n",
       " 191,\n",
       " 93,\n",
       " 112,\n",
       " 104,\n",
       " 123,\n",
       " 111,\n",
       " 118,\n",
       " 133,\n",
       " 190,\n",
       " 204,\n",
       " 106,\n",
       " 105,\n",
       " 133,\n",
       " 133,\n",
       " 170,\n",
       " 105,\n",
       " 134,\n",
       " 187,\n",
       " 122,\n",
       " 141,\n",
       " 156,\n",
       " 101,\n",
       " 134,\n",
       " 154,\n",
       " 131,\n",
       " 140,\n",
       " 143,\n",
       " 94,\n",
       " 135,\n",
       " 177,\n",
       " 166,\n",
       " 165,\n",
       " 161,\n",
       " 94,\n",
       " 150,\n",
       " 186,\n",
       " 108,\n",
       " 174,\n",
       " 121,\n",
       " 111,\n",
       " 126,\n",
       " 110,\n",
       " 109,\n",
       " 133,\n",
       " 133,\n",
       " 133,\n",
       " 181,\n",
       " 127,\n",
       " 112,\n",
       " 149,\n",
       " 107,\n",
       " 97,\n",
       " 126,\n",
       " 120,\n",
       " 146,\n",
       " 111,\n",
       " 137,\n",
       " 150,\n",
       " 144,\n",
       " 121,\n",
       " 145,\n",
       " 128,\n",
       " 159,\n",
       " 115,\n",
       " 113,\n",
       " 117,\n",
       " 113,\n",
       " 133,\n",
       " 85,\n",
       " 109,\n",
       " 115,\n",
       " 97,\n",
       " 96,\n",
       " 105,\n",
       " 148,\n",
       " 118,\n",
       " 104,\n",
       " 106,\n",
       " 107,\n",
       " 106,\n",
       " 121,\n",
       " 133,\n",
       " 120,\n",
       " 142,\n",
       " 105,\n",
       " 124,\n",
       " 96,\n",
       " 236,\n",
       " 148,\n",
       " 119,\n",
       " 126,\n",
       " 124,\n",
       " 118,\n",
       " 145,\n",
       " 108,\n",
       " 131,\n",
       " 109,\n",
       " 103,\n",
       " 123,\n",
       " 129,\n",
       " 99,\n",
       " 132,\n",
       " 99,\n",
       " 124,\n",
       " 127,\n",
       " 168,\n",
       " 172,\n",
       " 138,\n",
       " 141,\n",
       " 138,\n",
       " 154,\n",
       " 133,\n",
       " 219,\n",
       " 148,\n",
       " 169,\n",
       " 139,\n",
       " 128,\n",
       " 130,\n",
       " 128,\n",
       " 116,\n",
       " 173,\n",
       " 117,\n",
       " 124,\n",
       " 148,\n",
       " 163,\n",
       " 236,\n",
       " 145,\n",
       " 185,\n",
       " 145,\n",
       " 114,\n",
       " 112,\n",
       " 115,\n",
       " 111,\n",
       " 116,\n",
       " 101,\n",
       " 101,\n",
       " 96,\n",
       " 123,\n",
       " 116,\n",
       " 165,\n",
       " 128,\n",
       " 147,\n",
       " 153,\n",
       " 130,\n",
       " 107,\n",
       " 105,\n",
       " 136,\n",
       " 97,\n",
       " 145,\n",
       " 131,\n",
       " 103,\n",
       " 106,\n",
       " 137,\n",
       " 97,\n",
       " 101,\n",
       " 105,\n",
       " 137,\n",
       " 130,\n",
       " 101,\n",
       " 123,\n",
       " 117,\n",
       " 100,\n",
       " 141,\n",
       " 124,\n",
       " 128,\n",
       " 124,\n",
       " 118,\n",
       " 136,\n",
       " 140,\n",
       " 118,\n",
       " 121,\n",
       " 114,\n",
       " 166,\n",
       " 87,\n",
       " 170,\n",
       " 107,\n",
       " 131,\n",
       " 168,\n",
       " 131,\n",
       " 163,\n",
       " 131,\n",
       " 143,\n",
       " 136,\n",
       " 144,\n",
       " 169,\n",
       " 135,\n",
       " 117,\n",
       " 171,\n",
       " 107,\n",
       " 137,\n",
       " 139,\n",
       " 127,\n",
       " 134,\n",
       " 101,\n",
       " 168,\n",
       " 112,\n",
       " 128,\n",
       " 99,\n",
       " 133,\n",
       " 153,\n",
       " 120,\n",
       " 122,\n",
       " 105,\n",
       " 96,\n",
       " 145,\n",
       " 128,\n",
       " 138,\n",
       " 106,\n",
       " 146,\n",
       " 95,\n",
       " 121,\n",
       " 94,\n",
       " 174,\n",
       " 166,\n",
       " 132,\n",
       " 105,\n",
       " 117,\n",
       " 133,\n",
       " 223,\n",
       " 116,\n",
       " 159,\n",
       " 101,\n",
       " 148,\n",
       " 123,\n",
       " 157,\n",
       " 150,\n",
       " 236,\n",
       " 170,\n",
       " 221,\n",
       " 204,\n",
       " 175,\n",
       " 158,\n",
       " 159,\n",
       " 134,\n",
       " 129,\n",
       " 102,\n",
       " 140,\n",
       " 212,\n",
       " 111,\n",
       " 142,\n",
       " 104,\n",
       " 121,\n",
       " 138,\n",
       " 126,\n",
       " 111,\n",
       " 214,\n",
       " 152,\n",
       " 151,\n",
       " 131,\n",
       " 117,\n",
       " 103,\n",
       " 126,\n",
       " 118,\n",
       " 150,\n",
       " 115,\n",
       " 102,\n",
       " 115,\n",
       " 114,\n",
       " 174,\n",
       " 98,\n",
       " 123,\n",
       " 102,\n",
       " 122,\n",
       " 104,\n",
       " 99,\n",
       " 113,\n",
       " 91,\n",
       " 138,\n",
       " 112,\n",
       " 166,\n",
       " 135,\n",
       " 159,\n",
       " 175,\n",
       " 140,\n",
       " 104,\n",
       " 155,\n",
       " 146,\n",
       " 152,\n",
       " 124,\n",
       " 104,\n",
       " 130,\n",
       " 118,\n",
       " 127,\n",
       " 120,\n",
       " 99,\n",
       " 178,\n",
       " 102,\n",
       " 106,\n",
       " 111,\n",
       " 107,\n",
       " 136,\n",
       " 96,\n",
       " 137,\n",
       " 118,\n",
       " 97,\n",
       " 125,\n",
       " 135,\n",
       " 124,\n",
       " 141,\n",
       " 229,\n",
       " 156,\n",
       " 137,\n",
       " 151,\n",
       " 196,\n",
       " 118,\n",
       " 133,\n",
       " 114,\n",
       " 120,\n",
       " 157,\n",
       " 129,\n",
       " 147,\n",
       " 158,\n",
       " 150,\n",
       " 244,\n",
       " 125,\n",
       " 103,\n",
       " 168,\n",
       " 154,\n",
       " 122,\n",
       " 116,\n",
       " 146,\n",
       " 115,\n",
       " 130,\n",
       " 152,\n",
       " 187,\n",
       " 100,\n",
       " 128,\n",
       " 119,\n",
       " 103,\n",
       " 181,\n",
       " 131,\n",
       " 110,\n",
       " 123,\n",
       " 104,\n",
       " 111,\n",
       " 163,\n",
       " 111,\n",
       " 144,\n",
       " 137,\n",
       " 118,\n",
       " 95,\n",
       " 132,\n",
       " 123,\n",
       " 158,\n",
       " 104,\n",
       " 126,\n",
       " 102,\n",
       " 120,\n",
       " 122,\n",
       " 103,\n",
       " 115,\n",
       " 109,\n",
       " 125,\n",
       " 150,\n",
       " 127,\n",
       " 119,\n",
       " 100,\n",
       " 100,\n",
       " 101,\n",
       " 101,\n",
       " 110,\n",
       " 117,\n",
       " 112,\n",
       " 113,\n",
       " 133,\n",
       " 117,\n",
       " 129,\n",
       " 121,\n",
       " 123,\n",
       " 117,\n",
       " 160,\n",
       " 121,\n",
       " 158,\n",
       " 99,\n",
       " 117,\n",
       " 153,\n",
       " 114,\n",
       " 137,\n",
       " 152,\n",
       " 124,\n",
       " 163,\n",
       " 205,\n",
       " 142,\n",
       " 118,\n",
       " 126,\n",
       " 130,\n",
       " 121,\n",
       " 104,\n",
       " 128,\n",
       " 93,\n",
       " 122,\n",
       " 98,\n",
       " 119,\n",
       " 140,\n",
       " 111,\n",
       " 124,\n",
       " 152,\n",
       " 136,\n",
       " 133,\n",
       " 144,\n",
       " 89,\n",
       " 118,\n",
       " 137,\n",
       " 126,\n",
       " 102,\n",
       " 138,\n",
       " 130,\n",
       " 128,\n",
       " 129,\n",
       " 125,\n",
       " 95,\n",
       " 140,\n",
       " 120,\n",
       " 121,\n",
       " 131,\n",
       " 151,\n",
       " 134,\n",
       " 161,\n",
       " 110,\n",
       " 132,\n",
       " 185,\n",
       " 175,\n",
       " 135,\n",
       " 118,\n",
       " 132,\n",
       " 156,\n",
       " 124,\n",
       " 108,\n",
       " 148,\n",
       " 108,\n",
       " 127,\n",
       " 108,\n",
       " 98,\n",
       " 141,\n",
       " 150,\n",
       " 107,\n",
       " 123,\n",
       " 105,\n",
       " 126,\n",
       " 127,\n",
       " 110,\n",
       " 102,\n",
       " 185,\n",
       " 130,\n",
       " 119,\n",
       " 122,\n",
       " 119,\n",
       " 104,\n",
       " 117,\n",
       " 118,\n",
       " 183,\n",
       " 139,\n",
       " 132,\n",
       " 123,\n",
       " 107,\n",
       " 132,\n",
       " 134,\n",
       " 136,\n",
       " 143,\n",
       " 105,\n",
       " 90,\n",
       " 153,\n",
       " 126,\n",
       " 103,\n",
       " 126,\n",
       " 160,\n",
       " 134,\n",
       " 149,\n",
       " 143,\n",
       " 122,\n",
       " 140,\n",
       " 173,\n",
       " 179,\n",
       " 126,\n",
       " 124,\n",
       " 117,\n",
       " 146,\n",
       " 140,\n",
       " 114,\n",
       " 138,\n",
       " 134,\n",
       " 124,\n",
       " 116,\n",
       " 165,\n",
       " 161,\n",
       " 115,\n",
       " 123,\n",
       " 99,\n",
       " 135,\n",
       " 125,\n",
       " 130,\n",
       " 120,\n",
       " 164,\n",
       " 163,\n",
       " 105,\n",
       " 153,\n",
       " 105,\n",
       " 120,\n",
       " 153,\n",
       " 132,\n",
       " 156,\n",
       " 117,\n",
       " 203,\n",
       " 113,\n",
       " 114,\n",
       " 137,\n",
       " 236,\n",
       " 132,\n",
       " 104,\n",
       " 197,\n",
       " 118,\n",
       " 122,\n",
       " 147,\n",
       " 120,\n",
       " 124,\n",
       " 102,\n",
       " 141,\n",
       " 147,\n",
       " 156,\n",
       " 175,\n",
       " 138,\n",
       " 122,\n",
       " 149,\n",
       " 124,\n",
       " 148,\n",
       " 192,\n",
       " 106,\n",
       " 125,\n",
       " 135,\n",
       " 117,\n",
       " 92,\n",
       " 159,\n",
       " 139,\n",
       " 199,\n",
       " 92,\n",
       " 140,\n",
       " 147,\n",
       " 153,\n",
       " 107,\n",
       " 135,\n",
       " 189,\n",
       " 183,\n",
       " 111,\n",
       " 114,\n",
       " 174,\n",
       " 181,\n",
       " 130,\n",
       " 121,\n",
       " 145,\n",
       " 153,\n",
       " 144,\n",
       " 128,\n",
       " 157,\n",
       " 99,\n",
       " 146,\n",
       " 125,\n",
       " 111,\n",
       " 145,\n",
       " 117,\n",
       " 122,\n",
       " 156,\n",
       " 138,\n",
       " 112,\n",
       " 120,\n",
       " 104,\n",
       " 140,\n",
       " 126,\n",
       " 110,\n",
       " 103,\n",
       " 135,\n",
       " 112,\n",
       " 125,\n",
       " 140,\n",
       " 123,\n",
       " 181,\n",
       " 123,\n",
       " 126,\n",
       " 129,\n",
       " 126,\n",
       " 142,\n",
       " 139,\n",
       " 137,\n",
       " 131,\n",
       " 124,\n",
       " 152,\n",
       " 116,\n",
       " 114,\n",
       " 112,\n",
       " 109,\n",
       " 103,\n",
       " 102,\n",
       " 100,\n",
       " 104,\n",
       " 111,\n",
       " 151,\n",
       " 134,\n",
       " 148,\n",
       " 129,\n",
       " 132,\n",
       " 119,\n",
       " 108,\n",
       " 92,\n",
       " 124,\n",
       " 106,\n",
       " 143,\n",
       " 115,\n",
       " 164,\n",
       " 111,\n",
       " 123,\n",
       " 230,\n",
       " 136,\n",
       " 162,\n",
       " 100,\n",
       " 138,\n",
       " 143,\n",
       " 113,\n",
       " 156,\n",
       " 105,\n",
       " 95,\n",
       " 149,\n",
       " 105,\n",
       " 104,\n",
       " 154,\n",
       " 111,\n",
       " 115,\n",
       " 134,\n",
       " 189,\n",
       " 158,\n",
       " 180,\n",
       " 172,\n",
       " 193,\n",
       " 92,\n",
       " 190,\n",
       " 155,\n",
       " 155,\n",
       " 101,\n",
       " 107,\n",
       " 133,\n",
       " 179,\n",
       " 163,\n",
       " 138,\n",
       " 137,\n",
       " 106,\n",
       " 115,\n",
       " 136,\n",
       " 118,\n",
       " 118,\n",
       " 104,\n",
       " 116,\n",
       " 120,\n",
       " 124,\n",
       " 103,\n",
       " 97,\n",
       " 171,\n",
       " 137,\n",
       " 117,\n",
       " 146,\n",
       " 112,\n",
       " 165,\n",
       " 212,\n",
       " 140,\n",
       " 142,\n",
       " 173,\n",
       " 108,\n",
       " 134,\n",
       " 120,\n",
       " 128,\n",
       " 176,\n",
       " 104,\n",
       " 131,\n",
       " 107,\n",
       " 107,\n",
       " 110,\n",
       " 141,\n",
       " 163,\n",
       " 127,\n",
       " 123,\n",
       " 127,\n",
       " 141,\n",
       " 129,\n",
       " 138,\n",
       " 136,\n",
       " 127,\n",
       " 152,\n",
       " 147,\n",
       " 158,\n",
       " 132,\n",
       " 157,\n",
       " 144,\n",
       " 132,\n",
       " 114,\n",
       " 129,\n",
       " 126,\n",
       " 105,\n",
       " 128,\n",
       " 125,\n",
       " 104,\n",
       " 143,\n",
       " 120,\n",
       " 175,\n",
       " 109,\n",
       " 117,\n",
       " 183,\n",
       " 185,\n",
       " 194,\n",
       " 104,\n",
       " 144,\n",
       " 173,\n",
       " 176,\n",
       " 178,\n",
       " 138,\n",
       " 189,\n",
       " 151,\n",
       " 109,\n",
       " 129,\n",
       " 131,\n",
       " 117,\n",
       " 136,\n",
       " 110,\n",
       " 153,\n",
       " 146,\n",
       " 132,\n",
       " 165,\n",
       " 105,\n",
       " 147,\n",
       " 109,\n",
       " 132,\n",
       " 152,\n",
       " 142,\n",
       " 125,\n",
       " 150,\n",
       " 109,\n",
       " 98,\n",
       " 139,\n",
       " 129,\n",
       " 129,\n",
       " 132,\n",
       " 184,\n",
       " 153,\n",
       " 142,\n",
       " 126,\n",
       " 149,\n",
       " 108,\n",
       " 126,\n",
       " 138,\n",
       " 115,\n",
       " 132,\n",
       " 114,\n",
       " 116,\n",
       " 143,\n",
       " 121,\n",
       " 131,\n",
       " 176,\n",
       " 173,\n",
       " 103,\n",
       " 167,\n",
       " 176,\n",
       " 161,\n",
       " ...]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_tokens_indices_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5e4d0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs_pe['input_ids'][0][143].item() # correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ff1657c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get a list of input ids at all these indices: they should be either claim = 4366, premise = 18458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c5dae0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index_minus_2_test = []\n",
    "\n",
    "for idx, val in enumerate(class_tokens_indices_test_list):\n",
    "    at_idx_minus_2 = inputs_test['input_ids'][idx][val].item()\n",
    "    list_index_minus_2_test.append(at_idx_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aa1970ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4366, 18458}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list_index_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0d1b753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dbc18763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make the class token indices 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b8793eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, val in enumerate(class_tokens_indices_test_list):\n",
    "    inputs_test['input_ids'][idx][val] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7d02c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check if they are 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7c7050a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsontroi_check_list = []\n",
    "\n",
    "for idx, val in enumerate(class_tokens_indices_test_list):\n",
    "    at_idx_minus_2 = inputs_test['input_ids'][idx][val].item()\n",
    "    unsontroi_check_list.append(at_idx_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c61acc85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{103}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(unsontroi_check_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "91421cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8489ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeMiniDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cdd0bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PeMiniDataset(inputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "67fc724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fc1d6e",
   "metadata": {},
   "source": [
    "## get the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ede7e2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "18beb8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c3af7386",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d2efde04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = 'out',\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4487b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3edd5bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 4132\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 518\n",
      "/tmp/ipykernel_1023/3831771474.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='518' max='518' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [518/518 08:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.156500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to out/checkpoint-500\n",
      "Configuration saved in out/checkpoint-500/config.json\n",
      "Model weights saved in out/checkpoint-500/pytorch_model.bin\n",
      "/tmp/ipykernel_1023/3831771474.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=518, training_loss=0.15111377048144353, metrics={'train_runtime': 524.5492, 'train_samples_per_second': 15.754, 'train_steps_per_second': 0.988, 'total_flos': 2175124572979200.0, 'train_loss': 0.15111377048144353, 'epoch': 2.0})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "174dce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'mask_pe_model_trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fe30c94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to pe_mask_model\n",
      "Configuration saved in pe_mask_model/config.json\n",
      "Model weights saved in pe_mask_model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"pe_mask_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e936374c",
   "metadata": {},
   "source": [
    "### inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b53ac027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fa62c165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 16\n",
      "1 16\n",
      "2 16\n",
      "3 16\n",
      "4 16\n",
      "5 16\n",
      "6 16\n",
      "7 16\n",
      "8 16\n",
      "9 16\n",
      "10 16\n",
      "11 16\n",
      "12 16\n",
      "13 16\n",
      "14 16\n",
      "15 16\n",
      "16 16\n",
      "17 16\n",
      "18 16\n",
      "19 16\n",
      "20 16\n",
      "21 16\n",
      "22 16\n",
      "23 16\n",
      "24 16\n",
      "25 16\n",
      "26 16\n",
      "27 16\n",
      "28 16\n",
      "29 16\n",
      "30 16\n",
      "31 16\n",
      "32 16\n",
      "33 16\n",
      "34 16\n",
      "35 16\n",
      "36 16\n",
      "37 16\n",
      "38 16\n",
      "39 16\n",
      "40 16\n",
      "41 16\n",
      "42 16\n",
      "43 16\n",
      "44 16\n",
      "45 16\n",
      "46 16\n",
      "47 16\n",
      "48 16\n",
      "49 16\n",
      "50 16\n",
      "51 16\n",
      "52 16\n",
      "53 16\n",
      "54 16\n",
      "55 16\n",
      "56 16\n",
      "57 16\n",
      "58 16\n",
      "59 16\n",
      "60 16\n",
      "61 16\n",
      "62 16\n",
      "63 16\n",
      "64 16\n",
      "65 16\n",
      "66 16\n",
      "67 16\n",
      "68 16\n",
      "69 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_101/3831771474.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "# for idx, batch in enumerate(test_loader):\n",
    "#     print(idx, len(batch['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8dff37ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_101/3831771474.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "# for b in test_loader:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "12b47402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f5d002a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "499d7fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device_new = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "82f27e9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.to(device_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9f56cafc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bf1db22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tr_tst_dl = trainer.get_test_dataloader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6b856b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_101/3831771474.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "# for b in tr_tst_dl:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a46904f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "         [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "         [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "         [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "         [ 101, 6922, 1024,  ...,    0,    0,    0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b2b1246c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_101/3831771474.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  6922,  1024,  8476,  1024,  2248,  6813,  2003,  2085,  2062,\n",
       "          2691,  2084,  2412,  2077,  1010,  6251,  1024,  2096,  2070,  2453,\n",
       "          2228,  1996,  6813,  3288,  2312,  5618,  2005,  1996,  7688,  3032,\n",
       "          1010,  1045,  2052, 27481,  2008,  2023,  3068,  2038,  5360,  1996,\n",
       "          3451, 12332,  1998,  5591,  1996,  3019,  4044,  1997,  1996,  7538,\n",
       "         14345,  1012,  1010,  2034,  2030,  2197,  1999,  9491,  1024,  2748,\n",
       "          1010,  2034,  1999, 20423,  1024,  2053,  1010,  2197,  1999, 20423,\n",
       "          1024,  2053,  1010,  1999,  1999,  4955,  1024,  2748,  1010,  2003,\n",
       "          1999,  7091,  1024,  2053,  1012,  2112,  1997,  4613, 22073,  1024,\n",
       "         20010,  1010, 15156,  1010, 12034,  1010,  4748,  3501,  1010, 15156,\n",
       "          1010,  4748,  2361,  1010, 20010,  1010, 15156,  1010, 15156,  1012,\n",
       "          2003,  2023,  6922,  1037, 18458,  1010,  1037,  4366,  2030,  1037,\n",
       "          2350,  4366,  1029,  2023,  6922,  2003,  1037,   103,  1012,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a1c1af3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_590/3831771474.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "         [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "         [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "         [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "         [ 101, 6922, 1024,  ...,    0,    0,    0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_dataset[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4929a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BatchEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0c71977e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_590/3831771474.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "#whole_batch = BatchEncoding(test_dataset[:]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "360b9e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1107, 512])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#whole_batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0f48a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below thing is nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "984c6622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first_batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "869f2144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 8\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The batch received was empty, your model won't be able to train on it. Double-check that your training dataset contains keys expected by the model: input_ids,attention_mask,token_type_ids,position_ids,head_mask,inputs_embeds,encoder_hidden_states,encoder_attention_mask,labels,output_attentions,output_hidden_states,return_dict,label_ids,labels,label.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_590/1366708833.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2832\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   2833\u001b[0m             \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2834\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2936\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2937\u001b[0m             \u001b[0minputs_decode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_inputs_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   3137\u001b[0m         \"\"\"\n\u001b[1;32m   3138\u001b[0m         \u001b[0mhas_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3139\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_keys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_prepare_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2397\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2399\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2400\u001b[0m                 \u001b[0;34m\"The batch received was empty, your model won't be able to train on it. Double-check that your \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2401\u001b[0m                 \u001b[0;34mf\"training dataset contains keys expected by the model: {','.join(self._signature_columns)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The batch received was empty, your model won't be able to train on it. Double-check that your training dataset contains keys expected by the model: input_ids,attention_mask,token_type_ids,position_ids,head_mask,inputs_embeds,encoder_hidden_states,encoder_attention_mask,labels,output_attentions,output_hidden_states,return_dict,label_ids,labels,label."
     ]
    }
   ],
   "source": [
    "#test_outputs = trainer.predict(first_batch['input_ids'], first_batch['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "42a6d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_outputs = model(b['input_ids'], b['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8e0e9791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 30522])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_outputs['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "47d0ae43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.to(device_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2bf8d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_output_try = model(first_batch['input_ids'], first_batch['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a5d6d6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 30522])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch_output_try['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e12a146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c8f21dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_558/3608862229.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# for idx, batch in enumerate(test_loader):\n",
    "#     batch_outputs = model(batch['input_ids'], batch['attention_mask'])\n",
    "#     batch_predictions.append(batch_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c0d9b084",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 12.97 GiB (GPU 0; 23.88 GiB total capacity; 18.05 GiB already allocated; 5.01 GiB free; 18.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_590/365159582.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhole_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhole_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1351\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1352\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         )\n\u001b[0;32m-> 1018\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1019\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    605\u001b[0m                 )\n\u001b[1;32m    606\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    608\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    494\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 423\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    424\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key_query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 12.97 GiB (GPU 0; 23.88 GiB total capacity; 18.05 GiB already allocated; 5.01 GiB free; 18.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "#full_output = model(whole_batch['input_ids'], whole_batch['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "731b3098",
   "metadata": {},
   "outputs": [],
   "source": [
    "### new work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8e67cb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1107"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9419f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "nr_batches = len(test_dataset) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5ab8b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "dd1ff149",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "459eec8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_590/2308416924.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2e2f80e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_590/496341710.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "del train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "858c1a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_new = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "efd61889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a7699d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_590/3831771474.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "for i in range(nr_batches + 1):\n",
    "    print(i)\n",
    "    \n",
    "    if i != nr_batches:\n",
    "        \n",
    "        batch = BatchEncoding(test_dataset[i*batch_size:(i+1)*batch_size]).to(device_new)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        batch = BatchEncoding(test_dataset[i*batch_size:len(test_dataset)]).to(device_new)\n",
    "        \n",
    "    output = model(batch['input_ids'], batch['attention_mask'])['logits']\n",
    "    torch.cuda.empty_cache()\n",
    "    #del batch\n",
    "    complete_outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f4ff37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
