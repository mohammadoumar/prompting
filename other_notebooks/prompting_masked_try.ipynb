{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c487f6cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.21.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2021.10.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.0.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.28.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (58.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: IProgress in /opt/conda/lib/python3.8/site-packages (0.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from IProgress) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install ipywidgets\n",
    "!pip install IProgress\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3e5eef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "34e1ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f05ece43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8a23e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"Component: Topic: Should students be taught to compete or to cooperate?, Sentence: From this point of view, I firmly believe that we should attach more importance to cooperation during primary education., First or last in essay: Yes, First in paragraph: Yes, Last in paragraph: Yes, In in introduction: Yes, Is in conclusion: No. Part Of Speech tags: PRON, VERB, VERB, ADJ, NOUN, ADP, NOUN, ADP, ADJ, NOUN. Is this component a premise, a claim or a major claim? This component is a Claim.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "372623c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "19fd1d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "dc95a96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  6922,  1024,  8476,  1024,  2323,  2493,  2022,  4036,  2000,\n",
       "          5566,  2030,  2000, 17654,  1029,  1010,  6251,  1024,  2013,  2023,\n",
       "          2391,  1997,  3193,  1010,  1045,  7933,  2903,  2008,  2057,  2323,\n",
       "         22476,  2062,  5197,  2000,  6792,  2076,  3078,  2495,  1012,  1010,\n",
       "          2034,  2030,  2197,  1999,  9491,  1024,  2748,  1010,  2034,  1999,\n",
       "         20423,  1024,  2748,  1010,  2197,  1999, 20423,  1024,  2748,  1010,\n",
       "          1999,  1999,  4955,  1024,  2748,  1010,  2003,  1999,  7091,  1024,\n",
       "          2053,  1012,  2112,  1997,  4613, 22073,  1024,  4013,  2078,  1010,\n",
       "         12034,  1010, 12034,  1010,  4748,  3501,  1010, 15156,  1010,  4748,\n",
       "          2361,  1010, 15156,  1010,  4748,  2361,  1010,  4748,  3501,  1010,\n",
       "         15156,  1012,  2003,  2023,  6922,  1037, 18458,  1010,  1037,  4366,\n",
       "          2030,  1037,  2350,  4366,  1029,  2023,  6922,  2003,  1037,  4366,\n",
       "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1]])}"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9c212089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c l a i m'"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(4366)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "eb597853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c l a i m'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['input_ids'][0][119])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "a525906c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 122])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "d1682bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs['labels'] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "512f4ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "93c0f48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "0d9bac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs['labels'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "71a1fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "197b4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ids_randomlist = random.sample(range(0, 30522), 62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "359a1c84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ids_randomlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "80507985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(ids_randomlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "f32c3823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repetitive_list = [2044] * 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "51e4af3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#repetitive_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c6dff004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(repetitive_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "5c974190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_custom = torch.tensor([[5367, 1996, 4883]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "c2691379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_custom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "12f277d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_custom[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "9049f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all things seem correct now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "15a910ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give a set of custom/limited labels, see if it works\n",
    "#inputs['labels'] = torch.tensor([ids_randomlist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "65237ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs['labels'] = torch.tensor([repetitive_list])\n",
    "\n",
    "# optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "bdb5113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random array of floats in equal dimension to input_ids\n",
    "# rand = torch.rand(inputs.input_ids.shape)\n",
    "# # where the random array is less than 0.15, we set true\n",
    "# mask_arr = rand < 0.15\n",
    "# mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d444f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(inputs.input_ids != 101) * (inputs.input_ids != 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "d4593dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * (inputs.input_ids != 102)\n",
    "# mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "af85e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create selection from mask_arr\n",
    "# selection = torch.flatten((mask_arr[0]).nonzero()).tolist()\n",
    "# selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "b1ef1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply selection index to inputs.input_ids, adding MASK tokens\n",
    "inputs.input_ids[0][119] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "bf73d2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  6922,  1024,  8476,  1024,  2323,  2493,  2022,  4036,  2000,\n",
       "          5566,  2030,  2000, 17654,  1029,  1010,  6251,  1024,  2013,  2023,\n",
       "          2391,  1997,  3193,  1010,  1045,  7933,  2903,  2008,  2057,  2323,\n",
       "         22476,  2062,  5197,  2000,  6792,  2076,  3078,  2495,  1012,  1010,\n",
       "          2034,  2030,  2197,  1999,  9491,  1024,  2748,  1010,  2034,  1999,\n",
       "         20423,  1024,  2748,  1010,  2197,  1999, 20423,  1024,  2748,  1010,\n",
       "          1999,  1999,  4955,  1024,  2748,  1010,  2003,  1999,  7091,  1024,\n",
       "          2053,  1012,  2112,  1997,  4613, 22073,  1024,  4013,  2078,  1010,\n",
       "         12034,  1010, 12034,  1010,  4748,  3501,  1010, 15156,  1010,  4748,\n",
       "          2361,  1010, 15156,  1010,  4748,  2361,  1010,  4748,  3501,  1010,\n",
       "         15156,  1012,  2003,  2023,  6922,  1037, 18458,  1010,  1037,  4366,\n",
       "          2030,  1037,  2350,  4366,  1029,  2023,  6922,  2003,  1037,   103,\n",
       "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1]])}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "4959e1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  6922,  1024,  8476,  1024,  2323,  2493,  2022,  4036,  2000,\n",
       "         5566,  2030,  2000, 17654,  1029,  1010,  6251,  1024,  2013,  2023,\n",
       "         2391,  1997,  3193,  1010,  1045,  7933,  2903,  2008,  2057,  2323,\n",
       "        22476,  2062,  5197,  2000,  6792,  2076,  3078,  2495,  1012,  1010,\n",
       "         2034,  2030,  2197,  1999,  9491,  1024,  2748,  1010,  2034,  1999,\n",
       "        20423,  1024,  2748,  1010,  2197,  1999, 20423,  1024,  2748,  1010,\n",
       "         1999,  1999,  4955,  1024,  2748,  1010,  2003,  1999,  7091,  1024,\n",
       "         2053,  1012,  2112,  1997,  4613, 22073,  1024,  4013,  2078,  1010,\n",
       "        12034,  1010, 12034,  1010,  4748,  3501,  1010, 15156,  1010,  4748,\n",
       "         2361,  1010, 15156,  1010,  4748,  2361,  1010,  4748,  3501,  1010,\n",
       "        15156,  1012,  2003,  2023,  6922,  1037, 18458,  1010,  1037,  4366,\n",
       "         2030,  1037,  2350,  4366,  1029,  2023,  6922,  2003,  1037,   103,\n",
       "         1012,   102])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'][0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "c22bad1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a f t e r'"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(2044)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "fe1d099f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] component : topic : should students be taught to compete or to cooperate?, sentence : from this point of view, i firmly believe that we should attach more importance to cooperation during primary education., first or last in essay : yes, first in paragraph : yes, last in paragraph : yes, in in introduction : yes, is in conclusion : no. part of speech tags : pron, verb, verb, adj, noun, adp, noun, adp, adj, noun. is this component a premise, a claim or a major claim? this component is a [MASK]. [SEP]'"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['input_ids'][0][:])    #decode(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "bfe3a97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  6922,  1024,  8476,  1024,  2323,  2493,  2022,  4036,  2000,\n",
       "          5566,  2030,  2000, 17654,  1029,  1010,  6251,  1024,  2013,  2023,\n",
       "          2391,  1997,  3193,  1010,  1045,  7933,  2903,  2008,  2057,  2323,\n",
       "         22476,  2062,  5197,  2000,  6792,  2076,  3078,  2495,  1012,  1010,\n",
       "          2034,  2030,  2197,  1999,  9491,  1024,  2748,  1010,  2034,  1999,\n",
       "         20423,  1024,  2748,  1010,  2197,  1999, 20423,  1024,  2748,  1010,\n",
       "          1999,  1999,  4955,  1024,  2748,  1010,  2003,  1999,  7091,  1024,\n",
       "          2053,  1012,  2112,  1997,  4613, 22073,  1024,  4013,  2078,  1010,\n",
       "         12034,  1010, 12034,  1010,  4748,  3501,  1010, 15156,  1010,  4748,\n",
       "          2361,  1010, 15156,  1010,  4748,  2361,  1010,  4748,  3501,  1010,\n",
       "         15156,  1012,  2003,  2023,  6922,  1037, 18458,  1010,  1037,  4366,\n",
       "          2030,  1037,  2350,  4366,  1029,  2023,  6922,  2003,  1037,   103,\n",
       "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1]])}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "a6f8d98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass inputs as kwarg to model\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e7bf3c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits'])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we get two output tensors, loss and logits\n",
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "30155fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 122, 30522])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "2e8707e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_logits = outputs.logits[0][119]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "4c8e1237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30522])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "97ad6dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index from the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "5d073f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_dict = {v:k for k,v in tokenizer.get_vocab().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "bbb0b9b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#full_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "372edce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#claim_idx = {v for k,v in tokenizer.get_vocab().items() if k == 'claim'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "b2105bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#claim_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "a7947274",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prem_idx = {v for k,v in tokenizer.get_vocab().items() if k == 'premise'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "b65c679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prem_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "f27dc41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.7223, -2.7466, -2.7926,  ..., -1.8121, -2.5870, -5.4545],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "552420d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#desired_logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "d9baf02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#desired_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "282288f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#desired_logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "255a66cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_cl = desired_logits[0][4366]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "3c5ae917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "4c868d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_prem = desired_logits[0][18458]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "34816af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_prem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "53fd2250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.tensor([logit_cl,logit_prem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "94fd2fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing = torch.argmax(torch.tensor([logit_prem,logit_cl]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0dbdf2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "a27de4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### inference businsess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "bc2d4cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = torch.argmax(desired_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "e986b016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18458)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "98ac2ab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#full_dict = {v:k for k,v in tokenizer.get_vocab().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "164a1b87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#full_dict[2670]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "e208be5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p r e m i s e'"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(18458)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "e368f076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c l a i m'"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(4366)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "604a87d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p r e m i s e'"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "b34a313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok good. now try to do this thing for a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "ace12481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so it can be any random idsm but has to be one of equal lenght."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "e91939a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "70406b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "a3032f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get the answers for all masks\n",
    "# then, we do the decod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54428d3a",
   "metadata": {},
   "source": [
    "## with 10 argument components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "d5764f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 10 texts from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "6410004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "91c97c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"/notebooks/Prompting/dataset/pe_dataset_w_prompts_1_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "00e50e38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_nr</th>\n",
       "      <th>component_id</th>\n",
       "      <th>label_and_comp_idxs</th>\n",
       "      <th>text</th>\n",
       "      <th>label_x</th>\n",
       "      <th>label_ComponentType</th>\n",
       "      <th>relation_SupportAttack</th>\n",
       "      <th>label_RelationType</th>\n",
       "      <th>label_LinkedNotLinked</th>\n",
       "      <th>split</th>\n",
       "      <th>...</th>\n",
       "      <th>nr_preceeding_comps_in_para</th>\n",
       "      <th>nr_following_comps_in_para</th>\n",
       "      <th>structural_fts_as_text</th>\n",
       "      <th>structural_fts_as_text_combined</th>\n",
       "      <th>para_ratio</th>\n",
       "      <th>first_or_last</th>\n",
       "      <th>strct_fts_w_position_in_essay</th>\n",
       "      <th>component_pos_tags</th>\n",
       "      <th>strct_fts_essay_position_pos_tags</th>\n",
       "      <th>prompted_representation_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T1</td>\n",
       "      <td>MajorClaim 503 575</td>\n",
       "      <td>we should attach more importance to cooperatio...</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: PRON, VERB, VERB, ADJ, NO...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T2</td>\n",
       "      <td>MajorClaim 2154 2231</td>\n",
       "      <td>a more cooperative attitudes towards life is m...</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: DET, ADV, ADJ, NOUN, ADP,...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T3</td>\n",
       "      <td>Claim 591 714</td>\n",
       "      <td>through cooperation, children can learn about ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: ADP, NOUN, PUNCT, NOUN, V...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T4</td>\n",
       "      <td>Premise 716 851</td>\n",
       "      <td>What we acquired from team work is not only ho...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: PRON, PRON, VERB, ADP, NO...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>essay001</td>\n",
       "      <td>T5</td>\n",
       "      <td>Premise 853 1086</td>\n",
       "      <td>During the process of cooperation, children ca...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Part Of Speech tags: ADP, DET, NOUN, ADP, NOUN...</td>\n",
       "      <td>Topic: Should students be taught to compete or...</td>\n",
       "      <td>Component: Topic: Should students be taught to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5968</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T11</td>\n",
       "      <td>Premise 1275 1339</td>\n",
       "      <td>indirectly they will learn how to socialize ea...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: ADV, PRON, VERB, VERB, AD...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5969</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T12</td>\n",
       "      <td>Premise 1341 1388</td>\n",
       "      <td>That will make children getting lots of friends</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: DET, VERB, VERB, NOUN, VE...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T13</td>\n",
       "      <td>Premise 1393 1436</td>\n",
       "      <td>they can contribute positively to community</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: PRON, VERB, VERB, ADV, AD...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5971</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T14</td>\n",
       "      <td>Premise 1448 1525</td>\n",
       "      <td>playing sport makes children getting healthy a...</td>\n",
       "      <td>Premise</td>\n",
       "      <td>Premise</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>NotLinked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: VERB, NOUN, VERB, NOUN, V...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>essay402</td>\n",
       "      <td>T15</td>\n",
       "      <td>Claim 916 965</td>\n",
       "      <td>playing sports will give good effects on children</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim</td>\n",
       "      <td>[]</td>\n",
       "      <td>Support</td>\n",
       "      <td>Linked</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Part Of Speech tags: VERB, NOUN, VERB, VERB, A...</td>\n",
       "      <td>Topic: Children should studying hard or playin...</td>\n",
       "      <td>Component: Topic: Children should studying har...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5973 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_nr component_id   label_and_comp_idxs  \\\n",
       "0     essay001           T1    MajorClaim 503 575   \n",
       "1     essay001           T2  MajorClaim 2154 2231   \n",
       "2     essay001           T3         Claim 591 714   \n",
       "3     essay001           T4       Premise 716 851   \n",
       "4     essay001           T5      Premise 853 1086   \n",
       "...        ...          ...                   ...   \n",
       "5968  essay402          T11     Premise 1275 1339   \n",
       "5969  essay402          T12     Premise 1341 1388   \n",
       "5970  essay402          T13     Premise 1393 1436   \n",
       "5971  essay402          T14     Premise 1448 1525   \n",
       "5972  essay402          T15         Claim 916 965   \n",
       "\n",
       "                                                   text     label_x  \\\n",
       "0     we should attach more importance to cooperatio...  MajorClaim   \n",
       "1     a more cooperative attitudes towards life is m...  MajorClaim   \n",
       "2     through cooperation, children can learn about ...       Claim   \n",
       "3     What we acquired from team work is not only ho...     Premise   \n",
       "4     During the process of cooperation, children ca...     Premise   \n",
       "...                                                 ...         ...   \n",
       "5968  indirectly they will learn how to socialize ea...     Premise   \n",
       "5969    That will make children getting lots of friends     Premise   \n",
       "5970        they can contribute positively to community     Premise   \n",
       "5971  playing sport makes children getting healthy a...     Premise   \n",
       "5972  playing sports will give good effects on children       Claim   \n",
       "\n",
       "     label_ComponentType relation_SupportAttack label_RelationType  \\\n",
       "0             MajorClaim                     []                      \n",
       "1             MajorClaim                     []                      \n",
       "2                  Claim                     []            Support   \n",
       "3                Premise                     []            Support   \n",
       "4                Premise                     []            Support   \n",
       "...                  ...                    ...                ...   \n",
       "5968             Premise                     []            Support   \n",
       "5969             Premise                     []            Support   \n",
       "5970             Premise                     []            Support   \n",
       "5971             Premise                     []            Support   \n",
       "5972               Claim                     []            Support   \n",
       "\n",
       "     label_LinkedNotLinked  split  ... nr_preceeding_comps_in_para  \\\n",
       "0                   Linked  TRAIN  ...                           0   \n",
       "1                   Linked  TRAIN  ...                           0   \n",
       "2                   Linked  TRAIN  ...                           0   \n",
       "3                NotLinked  TRAIN  ...                           1   \n",
       "4                NotLinked  TRAIN  ...                           2   \n",
       "...                    ...    ...  ...                         ...   \n",
       "5968             NotLinked  TRAIN  ...                           4   \n",
       "5969             NotLinked  TRAIN  ...                           5   \n",
       "5970                Linked  TRAIN  ...                           6   \n",
       "5971             NotLinked  TRAIN  ...                           7   \n",
       "5972                Linked  TRAIN  ...                           0   \n",
       "\n",
       "      nr_following_comps_in_para  \\\n",
       "0                              0   \n",
       "1                              0   \n",
       "2                              3   \n",
       "3                              2   \n",
       "4                              1   \n",
       "...                          ...   \n",
       "5968                           3   \n",
       "5969                           2   \n",
       "5970                           1   \n",
       "5971                           0   \n",
       "5972                           7   \n",
       "\n",
       "                                 structural_fts_as_text  \\\n",
       "0     Topic: Should students be taught to compete or...   \n",
       "1     Topic: Should students be taught to compete or...   \n",
       "2     Topic: Should students be taught to compete or...   \n",
       "3     Topic: Should students be taught to compete or...   \n",
       "4     Topic: Should students be taught to compete or...   \n",
       "...                                                 ...   \n",
       "5968  Topic: Children should studying hard or playin...   \n",
       "5969  Topic: Children should studying hard or playin...   \n",
       "5970  Topic: Children should studying hard or playin...   \n",
       "5971  Topic: Children should studying hard or playin...   \n",
       "5972  Topic: Children should studying hard or playin...   \n",
       "\n",
       "                        structural_fts_as_text_combined para_ratio  \\\n",
       "0     Topic: Should students be taught to compete or...       0.25   \n",
       "1     Topic: Should students be taught to compete or...       1.00   \n",
       "2     Topic: Should students be taught to compete or...       0.50   \n",
       "3     Topic: Should students be taught to compete or...       0.50   \n",
       "4     Topic: Should students be taught to compete or...       0.50   \n",
       "...                                                 ...        ...   \n",
       "5968  Topic: Children should studying hard or playin...       0.75   \n",
       "5969  Topic: Children should studying hard or playin...       0.75   \n",
       "5970  Topic: Children should studying hard or playin...       0.75   \n",
       "5971  Topic: Children should studying hard or playin...       0.75   \n",
       "5972  Topic: Children should studying hard or playin...       0.75   \n",
       "\n",
       "     first_or_last                      strct_fts_w_position_in_essay  \\\n",
       "0                1  Topic: Should students be taught to compete or...   \n",
       "1                1  Topic: Should students be taught to compete or...   \n",
       "2                0  Topic: Should students be taught to compete or...   \n",
       "3                0  Topic: Should students be taught to compete or...   \n",
       "4                0  Topic: Should students be taught to compete or...   \n",
       "...            ...                                                ...   \n",
       "5968             0  Topic: Children should studying hard or playin...   \n",
       "5969             0  Topic: Children should studying hard or playin...   \n",
       "5970             0  Topic: Children should studying hard or playin...   \n",
       "5971             0  Topic: Children should studying hard or playin...   \n",
       "5972             0  Topic: Children should studying hard or playin...   \n",
       "\n",
       "                                     component_pos_tags  \\\n",
       "0     Part Of Speech tags: PRON, VERB, VERB, ADJ, NO...   \n",
       "1     Part Of Speech tags: DET, ADV, ADJ, NOUN, ADP,...   \n",
       "2     Part Of Speech tags: ADP, NOUN, PUNCT, NOUN, V...   \n",
       "3     Part Of Speech tags: PRON, PRON, VERB, ADP, NO...   \n",
       "4     Part Of Speech tags: ADP, DET, NOUN, ADP, NOUN...   \n",
       "...                                                 ...   \n",
       "5968  Part Of Speech tags: ADV, PRON, VERB, VERB, AD...   \n",
       "5969  Part Of Speech tags: DET, VERB, VERB, NOUN, VE...   \n",
       "5970  Part Of Speech tags: PRON, VERB, VERB, ADV, AD...   \n",
       "5971  Part Of Speech tags: VERB, NOUN, VERB, NOUN, V...   \n",
       "5972  Part Of Speech tags: VERB, NOUN, VERB, VERB, A...   \n",
       "\n",
       "                      strct_fts_essay_position_pos_tags  \\\n",
       "0     Topic: Should students be taught to compete or...   \n",
       "1     Topic: Should students be taught to compete or...   \n",
       "2     Topic: Should students be taught to compete or...   \n",
       "3     Topic: Should students be taught to compete or...   \n",
       "4     Topic: Should students be taught to compete or...   \n",
       "...                                                 ...   \n",
       "5968  Topic: Children should studying hard or playin...   \n",
       "5969  Topic: Children should studying hard or playin...   \n",
       "5970  Topic: Children should studying hard or playin...   \n",
       "5971  Topic: Children should studying hard or playin...   \n",
       "5972  Topic: Children should studying hard or playin...   \n",
       "\n",
       "                              prompted_representation_1  \n",
       "0     Component: Topic: Should students be taught to...  \n",
       "1     Component: Topic: Should students be taught to...  \n",
       "2     Component: Topic: Should students be taught to...  \n",
       "3     Component: Topic: Should students be taught to...  \n",
       "4     Component: Topic: Should students be taught to...  \n",
       "...                                                 ...  \n",
       "5968  Component: Topic: Children should studying har...  \n",
       "5969  Component: Topic: Children should studying har...  \n",
       "5970  Component: Topic: Children should studying har...  \n",
       "5971  Component: Topic: Children should studying har...  \n",
       "5972  Component: Topic: Children should studying har...  \n",
       "\n",
       "[5973 rows x 40 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "93aa7708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Component: Topic: Should students be taught to...\n",
       "1    Component: Topic: Should students be taught to...\n",
       "2    Component: Topic: Should students be taught to...\n",
       "3    Component: Topic: Should students be taught to...\n",
       "4    Component: Topic: Should students be taught to...\n",
       "5    Component: Topic: Should students be taught to...\n",
       "6    Component: Topic: Should students be taught to...\n",
       "7    Component: Topic: Should students be taught to...\n",
       "8    Component: Topic: Should students be taught to...\n",
       "9    Component: Topic: Should students be taught to...\n",
       "Name: prompted_representation_1, dtype: object"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prompted_representation_1'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "4bc3c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_list = df['prompted_representation_1'][2:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "016dc80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Component: Topic: Should students be taught to compete or to cooperate?, Sentence: First of all, through cooperation, children can learn about interpersonal skills which are significant in the future life of all students, First or last in essay: No, First in paragraph: Yes, Last in paragraph: No, In in introduction: No, Is in conclusion: No. Part Of Speech tags: ADP, NOUN, PUNCT, NOUN, VERB, VERB, ADP, ADJ, NOUN, DET, AUX, ADJ, ADP, DET, ADJ, NOUN, ADP, DET, NOUN. Is this component a premise, a claim or a major claim? This component is a Claim.',\n",
       " 'Component: Topic: Should students be taught to compete or to cooperate?, Sentence: What we acquired from team work is not only how to achieve the same goal with others but more importantly, how to get along with others, First or last in essay: No, First in paragraph: No, Last in paragraph: No, In in introduction: No, Is in conclusion: No. Part Of Speech tags: PRON, PRON, VERB, ADP, NOUN, NOUN, AUX, PART, ADV, ADV, PART, VERB, DET, ADJ, NOUN, ADP, NOUN, CCONJ, ADV, ADV, PUNCT, ADV, PART, AUX, ADP, ADP, NOUN. Is this component a premise, a claim or a major claim? This component is a Premise.',\n",
       " 'Component: Topic: Should students be taught to compete or to cooperate?, Sentence: During the process of cooperation, children can learn about how to listen to opinions of others, how to communicate with others, how to think comprehensively, and even how to compromise with other team members when conflicts occurred, First or last in essay: No, First in paragraph: No, Last in paragraph: No, In in introduction: No, Is in conclusion: No. Part Of Speech tags: ADP, DET, NOUN, ADP, NOUN, PUNCT, NOUN, VERB, VERB, ADP, ADV, PART, VERB, ADP, NOUN, ADP, NOUN, PUNCT, ADV, PART, VERB, ADP, NOUN, PUNCT, ADV, PART, VERB, ADV, PUNCT, CCONJ, ADV, ADV, PART, VERB, ADP, ADJ, NOUN, NOUN, ADV, NOUN, VERB. Is this component a premise, a claim or a major claim? This component is a Premise.',\n",
       " 'Component: Topic: Should students be taught to compete or to cooperate?, Sentence: All of these skills help them to get on well with other people and will benefit them for the whole life., First or last in essay: No, First in paragraph: No, Last in paragraph: Yes, In in introduction: No, Is in conclusion: No. Part Of Speech tags: DET, ADP, DET, NOUN, VERB, PRON, PART, AUX, ADP, ADV, ADP, ADJ, NOUN, CCONJ, VERB, VERB, PRON, ADP, DET, ADJ, NOUN. Is this component a premise, a claim or a major claim? This component is a Premise.',\n",
       " 'Component: Topic: Should students be taught to compete or to cooperate?, Sentence: Hence it is always said that competition makes the society more effective, First or last in essay: No, First in paragraph: No, Last in paragraph: No, In in introduction: No, Is in conclusion: No. Part Of Speech tags: NOUN, VERB, DET, NOUN, ADV, ADJ. Is this component a premise, a claim or a major claim? This component is a Claim.',\n",
       " 'Component: Topic: Should students be taught to compete or to cooperate?, Sentence: On the other hand, the significance of competition is that how to become more excellence to gain the victory, First or last in essay: No, First in paragraph: Yes, Last in paragraph: No, In in introduction: No, Is in conclusion: No. Part Of Speech tags: DET, NOUN, ADP, NOUN, AUX, SCONJ, ADV, PART, VERB, ADJ, NOUN, PART, VERB, DET, NOUN. Is this component a premise, a claim or a major claim? This component is a Premise.',\n",
       " 'Component: Topic: Should students be taught to compete or to cooperate?, Sentence: However, when we consider about the question that how to win the game, we always find that we need the cooperation, First or last in essay: No, First in paragraph: No, Last in paragraph: No, In in introduction: No, Is in conclusion: No. Part Of Speech tags: ADV, PRON, VERB, ADP, DET, NOUN, SCONJ, ADV, PART, VERB, DET, NOUN, PUNCT, PRON, ADV, VERB, SCONJ, PRON, VERB, DET, NOUN. Is this component a premise, a claim or a major claim? This component is a Premise.',\n",
       " 'Component: Topic: Should students be taught to compete or to cooperate?, Sentence: Take Olympic games which is a form of competition for instance, it is hard to imagine how an athlete could win the game without the training of his or her coach, and the help of other professional staffs such as the people who take care of his diet, and those who are in charge of the medical care, First or last in essay: No, First in paragraph: No, Last in paragraph: No, In in introduction: No, Is in conclusion: No. Part Of Speech tags: VERB, ADJ, NOUN, DET, AUX, DET, NOUN, ADP, NOUN, ADP, NOUN, PUNCT, PRON, AUX, ADJ, PART, VERB, ADV, DET, NOUN, VERB, VERB, DET, NOUN, ADP, DET, NOUN, ADP, DET, CCONJ, DET, NOUN, PUNCT, CCONJ, DET, NOUN, ADP, ADJ, ADJ, NOUN, ADJ, SCONJ, DET, NOUN, PRON, VERB, NOUN, ADP, DET, NOUN, PUNCT, CCONJ, DET, PRON, AUX, ADP, NOUN, ADP, DET, ADJ, NOUN. Is this component a premise, a claim or a major claim? This component is a Premise.']"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "8a7553d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_pe = tokenizer(texts_list, return_tensors='pt', max_length=512, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "7663338f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "5abdcf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_pe['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "14b25f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training we will need labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "b24c707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_pe['labels'] = inputs_pe.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "3cbdeff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0]])}"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "bc15ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find where the last 102 is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "03d5a6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inputs_pe['input_ids'][0] == 102).nonzero(as_tuple=True)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "ad044497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# claim = 4366, premise = 18458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "a1bf6d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inputs_pe['input_ids'][1] == 102).nonzero(as_tuple=True)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "4b7bb1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18458)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_pe['input_ids'][1][169]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "ebba451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that all at len-2 indices are either claim or premise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "bce708e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_indices_list = []\n",
    "\n",
    "for i in range(8):\n",
    "    last_idx = (inputs_pe['input_ids'][i] == 102).nonzero(as_tuple=True)[0].item()\n",
    "    last_indices_list.append(last_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "895f689b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[145, 171, 220, 150, 101, 130, 152, 288]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_indices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "ab220468",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_indices_list = [x - 2 for x in last_indices_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "75487dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[143, 169, 218, 148, 99, 128, 150, 286]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_indices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "734da0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs_pe['input_ids'][0][143].item() # correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "1b0680de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[143, 169, 218, 148, 99, 128, 150, 286]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_indices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "48ed8712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18458"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_pe['input_ids'][6][150].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "c9ea958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get a list of input ids at all these indics: they should be either claim = 4366, premise = 18458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "ba68331f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 143\n",
      "1 169\n",
      "2 218\n",
      "3 148\n",
      "4 99\n",
      "5 128\n",
      "6 150\n",
      "7 286\n"
     ]
    }
   ],
   "source": [
    "list_index_minus_2 = []\n",
    "\n",
    "for idx, val in enumerate(last_indices_list):\n",
    "    print(idx,val)\n",
    "    at_idx_minus_2 = inputs_pe['input_ids'][idx][val].item()\n",
    "    list_index_minus_2.append(at_idx_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "1bc4e0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4366, 18458, 18458, 18458, 4366, 18458, 18458, 18458]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_index_minus_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "a6fbce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "b4442e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make the above indices 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "2ea4a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, val in enumerate(last_indices_list):\n",
    "    inputs_pe['input_ids'][idx][val] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "b4c104f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check if they are 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "8f649018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 143\n",
      "1 169\n",
      "2 218\n",
      "3 148\n",
      "4 99\n",
      "5 128\n",
      "6 150\n",
      "7 286\n"
     ]
    }
   ],
   "source": [
    "unsontroi_check_list = []\n",
    "\n",
    "for idx, val in enumerate(last_indices_list):\n",
    "    print(idx,val)\n",
    "    at_idx_minus_2 = inputs_pe['input_ids'][idx][val].item()\n",
    "    unsontroi_check_list.append(at_idx_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "c0ee616e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[103, 103, 103, 103, 103, 103, 103, 103]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsontroi_check_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "0f05f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "4b378967",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeMiniDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "f9c78b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PeMiniDataset(inputs_pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "44780a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "14966fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir='out',\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "2605b9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "f9a119dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "ac2cc862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "409ab811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n",
      "/tmp/ipykernel_158/3831771474.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2, training_loss=10.344411849975586, metrics={'train_runtime': 1.0493, 'train_samples_per_second': 15.249, 'train_steps_per_second': 1.906, 'total_flos': 4211277004800.0, 'train_loss': 10.344411849975586, 'epoch': 2.0})"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "0a5fc199",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e5511f",
   "metadata": {},
   "source": [
    "### now create a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "84bfa2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11    Component: Topic: More people are migrating to...\n",
       "12    Component: Topic: More people are migrating to...\n",
       "13    Component: Topic: More people are migrating to...\n",
       "14    Component: Topic: More people are migrating to...\n",
       "15    Component: Topic: More people are migrating to...\n",
       "16    Component: Topic: More people are migrating to...\n",
       "17    Component: Topic: More people are migrating to...\n",
       "18    Component: Topic: More people are migrating to...\n",
       "Name: prompted_representation_1, dtype: object"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prompted_representation_1'][11:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "7a91923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_list_test = df['prompted_representation_1'][13:22].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "598883be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Component: Topic: More people are migrating to other countries than ever before, Sentence: Firstly, maintaining one’s cultural identity is a key important rule to help individuals emerge in the new multicultural environments, First or last in essay: No, First in paragraph: Yes, Last in paragraph: No, In in introduction: No, Is in conclusion: No. Part Of Speech tags: VERB, NUM, NUM, ADJ, NOUN, AUX, DET, ADJ, ADJ, NOUN, PART, VERB, NOUN, VERB, ADP, DET, ADJ, ADJ, NOUN. Is this component a premise, a claim or a major claim? This component is a Premise.',\n",
       " 'Component: Topic: More people are migrating to other countries than ever before, Sentence: Thus this makes it clear that sustaining the cultural values of immigrants is paramount essential., First or last in essay: No, First in paragraph: No, Last in paragraph: Yes, In in introduction: No, Is in conclusion: No. Part Of Speech tags: VERB, DET, ADJ, NOUN, ADP, NOUN, AUX, ADJ, ADJ. Is this component a premise, a claim or a major claim? This component is a Claim.',\n",
       " 'Component: Topic: More people are migrating to other countries than ever before, Sentence: Take Australia for example, immigrants from varieties of nations have a day called multicultural day where people from each country prepare their food and traditional activities for displaying in the public venues, First or last in essay: No, First in paragraph: No, Last in paragraph: No, In in introduction: No, Is in conclusion: No. Part Of Speech tags: VERB, PROPN, ADP, NOUN, PUNCT, NOUN, ADP, NOUN, ADP, NOUN, AUX, DET, NOUN, VERB, ADJ, NOUN, ADV, NOUN, ADP, DET, NOUN, VERB, DET, NOUN, CCONJ, ADJ, NOUN, ADP, VERB, ADP, DET, ADJ, NOUN. Is this component a premise, a claim or a major claim? This component is a Premise.',\n",
       " 'Component: Topic: More people are migrating to other countries than ever before, Sentence: Many Australians come this day to enjoy the shows, learn about the cultures and admire the diverse values, First or last in essay: No, First in paragraph: No, Last in paragraph: No, In in introduction: No, Is in conclusion: No. Part Of Speech tags: ADJ, PROPN, VERB, DET, NOUN, PART, VERB, DET, NOUN, PUNCT, VERB, ADP, DET, NOUN, CCONJ, VERB, DET, ADJ, NOUN. Is this component a premise, a claim or a major claim? This component is a Premise.',\n",
       " 'Component: Topic: More people are migrating to other countries than ever before, Sentence: These feedbacks, in turn, help raise one’s pride of their cultures and help people understand each other more, First or last in essay: No, First in paragraph: No, Last in paragraph: No, In in introduction: No, Is in conclusion: No. Part Of Speech tags: DET, NOUN, PUNCT, ADP, NOUN, PUNCT, VERB, VERB, NOUN, PUNCT, NOUN, ADP, DET, NOUN, CCONJ, VERB, NOUN, VERB, DET, ADJ, ADJ. Is this component a premise, a claim or a major claim? This component is a Premise.',\n",
       " 'Component: Topic: More people are migrating to other countries than ever before, Sentence: Secondly, it is crucial to keep one’s identity for they need a connection back to their country as well as teach their children their value of origin, First or last in essay: No, First in paragraph: Yes, Last in paragraph: No, In in introduction: No, Is in conclusion: No. Part Of Speech tags: PRON, AUX, ADJ, PART, VERB, PRON, NOUN, NOUN. Is this component a premise, a claim or a major claim? This component is a Premise.',\n",
       " 'Component: Topic: More people are migrating to other countries than ever before, Sentence: Secondly, it is crucial to keep one’s identity for they need a connection back to their country as well as teach their children their value of origin, First or last in essay: No, First in paragraph: No, Last in paragraph: No, In in introduction: No, Is in conclusion: No. Part Of Speech tags: PRON, VERB, DET, NOUN, ADV, ADP, DET, NOUN, ADV, ADV, SCONJ, VERB, DET, NOUN, DET, NOUN, ADP, NOUN. Is this component a premise, a claim or a major claim? This component is a Premise.',\n",
       " 'Component: Topic: More people are migrating to other countries than ever before, Sentence: Hence, it is clear that keeping the cultural traditions in the destination countries is tremendous important., First or last in essay: No, First in paragraph: No, Last in paragraph: Yes, In in introduction: No, Is in conclusion: No. Part Of Speech tags: VERB, DET, ADJ, NOUN, ADP, DET, NOUN, NOUN, AUX, ADJ, ADJ. Is this component a premise, a claim or a major claim? This component is a Claim.',\n",
       " 'Component: Topic: More people are migrating to other countries than ever before, Sentence: For instance, children immigrated to a new country will face social troubles in school with new friends, First or last in essay: No, First in paragraph: No, Last in paragraph: No, In in introduction: No, Is in conclusion: No. Part Of Speech tags: NOUN, VERB, ADP, DET, ADJ, NOUN, VERB, VERB, ADJ, NOUN, ADP, NOUN, ADP, ADJ, NOUN. Is this component a premise, a claim or a major claim? This component is a Premise.']"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "36bec583",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_pe_test = tokenizer(texts_list_test, return_tensors='pt', max_length=512, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "b12e2543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_pe_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "0efae307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 512])"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_pe_test['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "c13533a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training we will need labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac1aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing we dont?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "6f5c68e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_pe['labels'] = inputs_pe.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "de6b22fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0],\n",
       "        [ 101, 6922, 1024,  ...,    0,    0,    0]])}"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inputs_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "c3419d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find where the last 102 is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "15f02aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inputs_pe_test['input_ids'][0] == 102).nonzero(as_tuple=True)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "3d8c7663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# claim = 4366, premise = 18458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "cbeb0970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inputs_pe_test['input_ids'][1] == 102).nonzero(as_tuple=True)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "e2123696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that all at len-2 indices are either claim or premise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "2f3172b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_indices_list = []\n",
    "\n",
    "for i in range(9):\n",
    "    last_idx = (inputs_pe_test['input_ids'][i] == 102).nonzero(as_tuple=True)[0].item()\n",
    "    last_indices_list.append(last_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "e05066be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[143, 113, 188, 139, 149, 124, 149, 119, 129]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_indices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "7a01ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_indices_list = [x - 2 for x in last_indices_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "4c1de3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[141, 111, 186, 137, 147, 122, 147, 117, 127]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_indices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "42ed27b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs_pe['input_ids'][0][143].item() # correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "d84d9154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[141, 111, 186, 137, 147, 122, 147, 117, 127]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_indices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "87972ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18458"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_pe_test['input_ids'][6][147].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "c4a90601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get a list of input ids at all these indics: they should be either claim = 4366, premise = 18458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "57c2410c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 141\n",
      "1 111\n",
      "2 186\n",
      "3 137\n",
      "4 147\n",
      "5 122\n",
      "6 147\n",
      "7 117\n",
      "8 127\n"
     ]
    }
   ],
   "source": [
    "list_index_minus_2 = []\n",
    "\n",
    "for idx, val in enumerate(last_indices_list):\n",
    "    print(idx,val)\n",
    "    at_idx_minus_2 = inputs_pe_test['input_ids'][idx][val].item()\n",
    "    list_index_minus_2.append(at_idx_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "4db00f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18458, 4366, 18458, 18458, 18458, 18458, 18458, 4366, 18458]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_index_minus_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "fef2c39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "af92a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make the above indices 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "d2a89fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, val in enumerate(last_indices_list):\n",
    "    inputs_pe_test['input_ids'][idx][val] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "f7d63505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check if they are 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "53bfc049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 141\n",
      "1 111\n",
      "2 186\n",
      "3 137\n",
      "4 147\n",
      "5 122\n",
      "6 147\n",
      "7 117\n",
      "8 127\n"
     ]
    }
   ],
   "source": [
    "unsontroi_check_list = []\n",
    "\n",
    "for idx, val in enumerate(last_indices_list):\n",
    "    print(idx,val)\n",
    "    at_idx_minus_2 = inputs_pe_test['input_ids'][idx][val].item()\n",
    "    unsontroi_check_list.append(at_idx_minus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "f24ef046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[103, 103, 103, 103, 103, 103, 103, 103, 103]"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsontroi_check_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "e3342f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "b1917a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = PeMiniDataset(inputs_pe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "826a58fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "45558ce9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_158/3831771474.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([  101,  6922,  1024,  8476,  1024,  2062,  2111,  2024, 28636,  2000,\n",
       "          2060,  3032,  2084,  2412,  2077,  1010,  6251,  1024, 15847,  1010,\n",
       "          8498,  2028,  1521,  1055,  3451,  4767,  2003,  1037,  3145,  2590,\n",
       "          3627,  2000,  2393,  3633, 12636,  1999,  1996,  2047, 27135, 10058,\n",
       "          1010,  2034,  2030,  2197,  1999,  9491,  1024,  2053,  1010,  2034,\n",
       "          1999, 20423,  1024,  2748,  1010,  2197,  1999, 20423,  1024,  2053,\n",
       "          1010,  1999,  1999,  4955,  1024,  2053,  1010,  2003,  1999,  7091,\n",
       "          1024,  2053,  1012,  2112,  1997,  4613, 22073,  1024, 12034,  1010,\n",
       "         16371,  2213,  1010, 16371,  2213,  1010,  4748,  3501,  1010, 15156,\n",
       "          1010, 19554,  1010, 20010,  1010,  4748,  3501,  1010,  4748,  3501,\n",
       "          1010, 15156,  1010,  2112,  1010, 12034,  1010, 15156,  1010, 12034,\n",
       "          1010,  4748,  2361,  1010, 20010,  1010,  4748,  3501,  1010,  4748,\n",
       "          3501,  1010, 15156,  1012,  2003,  2023,  6922,  1037, 18458,  1010,\n",
       "          1037,  4366,  2030,  1037,  2350,  4366,  1029,  2023,  6922,  2003,\n",
       "          1037,   103,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test[0]['input_ids'], dataset_test[0]['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "930e496c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_158/3831771474.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "for b in test_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "c759f4cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 512])"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['input_ids'].shape # ok now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "3b66e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs = model(b['input_ids'].to(device), b['attention_mask'].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "0bdf51dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ -5.1645,  -5.2365,  -5.1280,  ...,  -4.6158,  -4.6302,  -3.2732],\n",
       "         [ -2.3828,  -2.5515,  -2.5852,  ...,  -2.3454,  -2.1379,  -1.7407],\n",
       "         [-11.5422, -11.5719, -11.7706,  ..., -10.6325,  -9.6628,  -4.9384],\n",
       "         ...,\n",
       "         [  0.8824,   0.6987,   0.6552,  ...,   0.7109,  -0.2909,  -0.5298],\n",
       "         [ -0.4448,  -0.6146,  -0.6461,  ...,  -0.6451,  -1.4625,  -1.0038],\n",
       "         [ -0.8632,  -1.0472,  -1.0868,  ...,  -1.1350,  -1.7077,  -1.5407]],\n",
       "\n",
       "        [[ -5.2503,  -5.3134,  -5.1690,  ...,  -4.7215,  -4.7150,  -3.4021],\n",
       "         [ -0.7752,  -1.0415,  -1.1343,  ...,  -0.8669,  -1.0987,  -1.0090],\n",
       "         [-12.1360, -12.2667, -12.3291,  ..., -10.9412,  -9.8416,  -5.3957],\n",
       "         ...,\n",
       "         [  1.2465,   0.9954,   1.0162,  ...,   0.7760,  -0.0563,  -0.7392],\n",
       "         [  0.0351,  -0.1904,  -0.1901,  ...,  -0.3766,  -1.0227,  -1.2554],\n",
       "         [  0.1228,  -0.0961,  -0.0951,  ...,  -0.2897,  -0.7870,  -1.3773]],\n",
       "\n",
       "        [[ -5.4005,  -5.4648,  -5.3283,  ...,  -4.8391,  -4.7753,  -3.5378],\n",
       "         [ -0.7371,  -1.0037,  -1.0385,  ...,  -0.6492,  -0.6693,  -1.0136],\n",
       "         [-11.7047, -11.8449, -11.9168,  ..., -10.5501,  -9.8096,  -5.1163],\n",
       "         ...,\n",
       "         [  1.2409,   1.0444,   1.0475,  ...,   0.9770,  -0.0266,  -0.2661],\n",
       "         [ -0.1566,  -0.3603,  -0.3409,  ...,  -0.5258,  -1.2770,  -1.0631],\n",
       "         [ -0.5369,  -0.7227,  -0.7225,  ...,  -0.9026,  -1.4477,  -1.4663]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ -5.4344,  -5.4884,  -5.3498,  ...,  -4.8620,  -4.8880,  -3.4594],\n",
       "         [ -1.0423,  -1.3299,  -1.3950,  ...,  -1.1285,  -1.2766,  -0.8558],\n",
       "         [-11.7575, -11.8486, -11.9141,  ..., -10.2899,  -9.6997,  -5.3311],\n",
       "         ...,\n",
       "         [  1.9620,   1.7369,   1.7445,  ...,   1.4653,   0.5300,  -0.0782],\n",
       "         [ -0.1207,  -0.3480,  -0.3178,  ...,  -0.5635,  -1.2965,  -0.9952],\n",
       "         [ -0.2559,  -0.4851,  -0.4678,  ...,  -0.7762,  -1.2753,  -1.3587]],\n",
       "\n",
       "        [[ -5.3356,  -5.4062,  -5.2638,  ...,  -4.7593,  -4.8430,  -3.2829],\n",
       "         [ -1.1860,  -1.4823,  -1.4731,  ...,  -0.9829,  -1.3215,  -0.7980],\n",
       "         [-11.7264, -11.9298, -11.9158,  ..., -10.1578,  -9.5846,  -4.6927],\n",
       "         ...,\n",
       "         [  1.0858,   0.8672,   0.8561,  ...,   0.6785,  -0.4032,  -0.1679],\n",
       "         [ -0.3516,  -0.5592,  -0.5433,  ...,  -0.7364,  -1.5428,  -1.1215],\n",
       "         [ -0.1902,  -0.4144,  -0.4025,  ...,  -0.6079,  -1.2165,  -1.3823]],\n",
       "\n",
       "        [[ -5.1806,  -5.2596,  -5.1322,  ...,  -4.6240,  -4.6622,  -3.1881],\n",
       "         [ -2.7105,  -2.8955,  -2.9090,  ...,  -2.5688,  -2.5369,  -1.7081],\n",
       "         [-12.2641, -12.3907, -12.4274,  ..., -10.9928,  -9.8681,  -5.3724],\n",
       "         ...,\n",
       "         [  0.7887,   0.5948,   0.5963,  ...,   0.5056,  -0.5030,  -0.4308],\n",
       "         [  0.1572,  -0.0380,  -0.0327,  ...,  -0.0815,  -0.9863,  -0.6215],\n",
       "         [ -0.6461,  -0.8569,  -0.8567,  ...,  -0.9957,  -1.5816,  -1.3534]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "a44a42f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 512, 30522])"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outputs['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "3489fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the things now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "9a7ef111",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_logit = test_outputs['logits'][1][147]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "a2d03a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30522])"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "17d22e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_logits = []\n",
    "\n",
    "for idx, val in enumerate(last_indices_list):\n",
    "    \n",
    "    desired_logit = test_outputs['logits'][idx][val]\n",
    "    desired_logits.append(desired_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "ed77702b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(desired_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "943b9c65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 1.8451,  1.5967,  1.5573,  ...,  1.5875,  0.8742, -1.4997],\n",
       "        device='cuda:0', grad_fn=<SelectBackward0>),\n",
       " tensor([-3.0427, -3.2585, -3.2682,  ..., -2.8442, -3.0653, -2.4101],\n",
       "        device='cuda:0', grad_fn=<SelectBackward0>),\n",
       " tensor([-1.4052, -1.6459, -1.5342,  ..., -0.8876, -0.6950, -4.0745],\n",
       "        device='cuda:0', grad_fn=<SelectBackward0>),\n",
       " tensor([ 1.4485,  1.1849,  1.2181,  ...,  1.1694,  0.4223, -1.2365],\n",
       "        device='cuda:0', grad_fn=<SelectBackward0>),\n",
       " tensor([ 0.4256,  0.2161,  0.2306,  ...,  0.1254, -0.5941, -0.9793],\n",
       "        device='cuda:0', grad_fn=<SelectBackward0>),\n",
       " tensor([-2.3563, -2.6447, -2.4691,  ..., -2.4676, -4.0849, -3.3429],\n",
       "        device='cuda:0', grad_fn=<SelectBackward0>),\n",
       " tensor([ 2.0210,  1.7883,  1.8001,  ...,  1.7437,  0.8756, -1.2164],\n",
       "        device='cuda:0', grad_fn=<SelectBackward0>),\n",
       " tensor([-3.7843, -3.7866, -3.5495,  ..., -4.4404, -2.3864, -1.4038],\n",
       "        device='cuda:0', grad_fn=<SelectBackward0>),\n",
       " tensor([ 1.7635,  1.5258,  1.5445,  ...,  1.5376,  0.8233, -1.3828],\n",
       "        device='cuda:0', grad_fn=<SelectBackward0>)]"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "fb5dfdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_list = []\n",
    "\n",
    "for logit in desired_logits:\n",
    "    logit_apres_argmax = torch.argmax(logit).item()\n",
    "    argmax_list.append(logit_apres_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "6a409233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18458, 8040, 2047, 18458, 1996, 4748, 18458, 1010, 18458]"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "8672a0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'premise sc new premise the ad premise, premise'"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(argmax_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710bad41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
